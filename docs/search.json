[
  {
    "objectID": "tools-reproducibility.html",
    "href": "tools-reproducibility.html",
    "title": "Reproducility",
    "section": "",
    "text": "In this part of Session 1, we will discuss the importance of reproducibility in statistical programming, and tools available in R to promote reproducible research.\nWe can make the statistical analysis components of our scientific research more reproducible using a variety of tools in R.\n\n\nOne challenge in scientific research is organization. Keeping track of data, code, sources of information, connections between data sets and images, connections between lab equipment and the data they produce, and even basic file organization. We can’t tackle all of these issues in R, but we can address some of them.\nThe first area we can focus on is starting with a project oriented workflow.\nFirst, create a folder where everything related to one project will be stored. In this case, let’s consider a “project” to be a single scientific question of interest. Every document related to this question of interest, from lab notes to plots to code for statistical analyses, manuscript drafs, and references will be stored in this one folder. The folder should be created in a backed-up location on your computer.\nNext, give the folder a meaningful name. This will be unique to everone’s line of work, but you should consider devising a system that you will use for all of your projects. For example, in my collaborative work I always name my project folders with PILastName-FellowLastName-TwoToThreeWordDescription. In this way I always know what pattern to look for when I’m trying to locate a specific project folder in the future.\nLet’s say I’m doing a project for this class with an investigator named Jane Doe with a fellow named Bob Clark about breast cancer outcomes, I may create a project folder named “Doe-Clark-breast-cancer-outcomes” under my “mmedr” folder on my home network drive.\n\n\n\nThen, create an RStudio project in this location. An RStudio project is an easy way to divide your work into multiple contexts, each with their own working directory and source documents.\nTo create an RStudio project in an existing directory, in RStudio go to File &gt; New Project.\n\n\n\nSelect “Existing directory” from the pop-up box.\n\n\n\nThen use “Browse” to navigate to the desired folder, and select “Create Project”.\n\n\n\nYour RStudio session will then automatically switch to your new R project.\nYou will notice two things.\n\nThere is a new .Rproj file in your project folder with the same name as the folder.\n\n\n\n\n\nNow you have a fresh RStudio session, with the name of the project indicated in the top right corner.\n\n\n\n\n\n\n\nNow every time you want to work on an analysis for this project, you will first open the RStudio project.\nYou can do this in one of several ways.\n\nOn Posit Workbench or your personal computer, in RStudio go to File &gt; Open Project\n\n\n\n\n\nOn Posit Workbench or your personal computer, in RStudio click on the arrow next to the project name in the top right corner and either select “Open Project” or choose from the list of recently opened project names.\n\n\n\n\n\nOn your personal computer, double click on the R project file in your project folder, which will open a new RStudio session.\n\n\n\n\nBenefits of working inside an RStudio project include:\n\nStarting a fresh R session every time the project is opened\nThe current working directory is set to the project directory\nPreviously open R scrips are restored at project startup\nOther RStudio settings are restored\nMultiple RStudio sessions can be open at one time, running independently in different RStudio projects\n\nIt is beneficial to create a standard set of sub-folders using standard naming conventions across projects. This will depend on the type of materials you typically have, but here is an example of my persona structure:\n\n\n\n\ncode: contains all of my R code files\ndata: contains all of my datasets\nmanuscript: contains all manuscript drafts\nmeeting-notes: contains any notes from meetings\nreferences: contains PDFs of references as well as any reference manager files\n\nThen I will name documents in standard ways and managing versions over time by appending the date in yyyy-mm-dd format so that they sort appropriately. I use caution to name files in standard ways using all lowercase letters, dashes between words, and letters or numbers to keep files in order if they need to be used in a certain order. File and folder names with spaces are not readable by all computers, and should be avoided.\n\n\n\nWhile use of an RStudio project does automatically set the working directory to the project directory, the relative file paths will still not be completely portable. For example, if I were to move the entire project folder “Doe-Clark-breast-cancer-outcomes” to a different location on my computer, any file paths that were relative to the previous location would be broken.\nFor example, the location of my project folder is: /home/zabore2/mmedr/Doe-Clark-breast-Cancer-Outcomes\nUnder that project folder, I have a folder called “data”. I have copied “breastcancer.csv” into this sub-folder.\nTo read in the data in the RStudio project, use:\n\nlibrary(readr)\ndf &lt;- read_csv(\"./data/breastcancer.csv\")\n\nThis is a relative filepath to the full filepath “/home/zabore2/mmedr/Doe-Clark-breast-cancer-outcomes/data/breastcancer.csv”. The code file I’m working from is in a parallel sub-folder named “code”, so I have to go up one level to the main project folder (“.”) then back down into the data folder (“/data”) and then reference the file name (“/breastcancer.csv”). This is a nice short relative file path, but if I were to move this project off my home directory and onto a shared network drive, for example, any such relative filepaths would then be broken. Also, coding conventions are not the same across different operating systems, so these relative paths used in Linux will not work on Windows, for example.\nTo avoid this, we can take advantage of the {here} package.\nFirst, install and load the {here} package.\n\ninstall.packages(\"here\") # Already installed on Posit Workbench\nlibrary(here)\n\nWhen you run library(here) in your RStudio project, you will automatically see the location where “here” starts in the console:\n\n\n\nAnd you can now refer to the same relative filepath relative to the main project folder, separating as many levels of sub-folder names as needed by commas, as follows:\n\ndf &lt;- read_csv(here(\"data\", \"breastcancer.csv\"))\n\nNow this code would work both across computers with different operating systems, and also if the project folder is moved to any other location.\nThis avoids issues of reproducibility related to file paths.\n\n\n\n\n\n\nSession 1, Exercise 4\n\n\n\n\n\n\nCreate a project folder for our fake project under your “mmedr” folder.\nCreate an RStudio project in this folder location\nCreate sub-folders named “code” and “data”\nCopy the breastcancer.csv file into the “code” folder\nCreate a new R script called “session1-exercise4.R” saved to the code folder\nIn the R script, load the {here} package and use it to read in the breastcancer.csv data"
  },
  {
    "objectID": "tools-reproducibility.html#r-projects",
    "href": "tools-reproducibility.html#r-projects",
    "title": "Reproducility",
    "section": "",
    "text": "One challenge in scientific research is organization. Keeping track of data, code, sources of information, connections between data sets and images, connections between lab equipment and the data they produce, and even basic file organization. We can’t tackle all of these issues in R, but we can address some of them.\nThe first area we can focus on is starting with a project oriented workflow.\nFirst, create a folder where everything related to one project will be stored. In this case, let’s consider a “project” to be a single scientific question of interest. Every document related to this question of interest, from lab notes to plots to code for statistical analyses, manuscript drafs, and references will be stored in this one folder. The folder should be created in a backed-up location on your computer.\nNext, give the folder a meaningful name. This will be unique to everone’s line of work, but you should consider devising a system that you will use for all of your projects. For example, in my collaborative work I always name my project folders with PILastName-FellowLastName-TwoToThreeWordDescription. In this way I always know what pattern to look for when I’m trying to locate a specific project folder in the future.\nLet’s say I’m doing a project for this class with an investigator named Jane Doe with a fellow named Bob Clark about breast cancer outcomes, I may create a project folder named “Doe-Clark-breast-cancer-outcomes” under my “mmedr” folder on my home network drive.\n\n\n\nThen, create an RStudio project in this location. An RStudio project is an easy way to divide your work into multiple contexts, each with their own working directory and source documents.\nTo create an RStudio project in an existing directory, in RStudio go to File &gt; New Project.\n\n\n\nSelect “Existing directory” from the pop-up box.\n\n\n\nThen use “Browse” to navigate to the desired folder, and select “Create Project”.\n\n\n\nYour RStudio session will then automatically switch to your new R project.\nYou will notice two things.\n\nThere is a new .Rproj file in your project folder with the same name as the folder.\n\n\n\n\n\nNow you have a fresh RStudio session, with the name of the project indicated in the top right corner."
  },
  {
    "objectID": "tools-reproducibility.html#project-workflow-and-organization",
    "href": "tools-reproducibility.html#project-workflow-and-organization",
    "title": "Reproducility",
    "section": "",
    "text": "Now every time you want to work on an analysis for this project, you will first open the RStudio project.\nYou can do this in one of several ways.\n\nOn Posit Workbench or your personal computer, in RStudio go to File &gt; Open Project\n\n\n\n\n\nOn Posit Workbench or your personal computer, in RStudio click on the arrow next to the project name in the top right corner and either select “Open Project” or choose from the list of recently opened project names.\n\n\n\n\n\nOn your personal computer, double click on the R project file in your project folder, which will open a new RStudio session.\n\n\n\n\nBenefits of working inside an RStudio project include:\n\nStarting a fresh R session every time the project is opened\nThe current working directory is set to the project directory\nPreviously open R scrips are restored at project startup\nOther RStudio settings are restored\nMultiple RStudio sessions can be open at one time, running independently in different RStudio projects\n\nIt is beneficial to create a standard set of sub-folders using standard naming conventions across projects. This will depend on the type of materials you typically have, but here is an example of my persona structure:\n\n\n\n\ncode: contains all of my R code files\ndata: contains all of my datasets\nmanuscript: contains all manuscript drafts\nmeeting-notes: contains any notes from meetings\nreferences: contains PDFs of references as well as any reference manager files\n\nThen I will name documents in standard ways and managing versions over time by appending the date in yyyy-mm-dd format so that they sort appropriately. I use caution to name files in standard ways using all lowercase letters, dashes between words, and letters or numbers to keep files in order if they need to be used in a certain order. File and folder names with spaces are not readable by all computers, and should be avoided."
  },
  {
    "objectID": "tools-reproducibility.html#here-package",
    "href": "tools-reproducibility.html#here-package",
    "title": "Reproducility",
    "section": "",
    "text": "While use of an RStudio project does automatically set the working directory to the project directory, the relative file paths will still not be completely portable. For example, if I were to move the entire project folder “Doe-Clark-breast-cancer-outcomes” to a different location on my computer, any file paths that were relative to the previous location would be broken.\nFor example, the location of my project folder is: /home/zabore2/mmedr/Doe-Clark-breast-Cancer-Outcomes\nUnder that project folder, I have a folder called “data”. I have copied “breastcancer.csv” into this sub-folder.\nTo read in the data in the RStudio project, use:\n\nlibrary(readr)\ndf &lt;- read_csv(\"./data/breastcancer.csv\")\n\nThis is a relative filepath to the full filepath “/home/zabore2/mmedr/Doe-Clark-breast-cancer-outcomes/data/breastcancer.csv”. The code file I’m working from is in a parallel sub-folder named “code”, so I have to go up one level to the main project folder (“.”) then back down into the data folder (“/data”) and then reference the file name (“/breastcancer.csv”). This is a nice short relative file path, but if I were to move this project off my home directory and onto a shared network drive, for example, any such relative filepaths would then be broken. Also, coding conventions are not the same across different operating systems, so these relative paths used in Linux will not work on Windows, for example.\nTo avoid this, we can take advantage of the {here} package.\nFirst, install and load the {here} package.\n\ninstall.packages(\"here\") # Already installed on Posit Workbench\nlibrary(here)\n\nWhen you run library(here) in your RStudio project, you will automatically see the location where “here” starts in the console:\n\n\n\nAnd you can now refer to the same relative filepath relative to the main project folder, separating as many levels of sub-folder names as needed by commas, as follows:\n\ndf &lt;- read_csv(here(\"data\", \"breastcancer.csv\"))\n\nNow this code would work both across computers with different operating systems, and also if the project folder is moved to any other location.\nThis avoids issues of reproducibility related to file paths.\n\n\n\n\n\n\nSession 1, Exercise 4\n\n\n\n\n\n\nCreate a project folder for our fake project under your “mmedr” folder.\nCreate an RStudio project in this folder location\nCreate sub-folders named “code” and “data”\nCopy the breastcancer.csv file into the “code” folder\nCreate a new R script called “session1-exercise4.R” saved to the code folder\nIn the R script, load the {here} package and use it to read in the breastcancer.csv data"
  },
  {
    "objectID": "tools-introduction.html",
    "href": "tools-introduction.html",
    "title": "Introduction to the tools",
    "section": "",
    "text": "In the first part of Session 1, we will introduce the tools used in this course. We will primarily be working in Posit Workbench, but it is important to know how to install and use the tools on your own as well for future use.\n\n\n\n\n\n\nLearning to program\n\n\n\nIf this is your first time learning to program, you might find it overwhelming at first. That is okay, and to be expected. Programming is best learned by doing, doing repeatedly, and looking up how to do. Keep going, ask questions, and refer often to the resources provided in this course.\nStop and ask questions anytime! I am gearing this material to new learners of R but as an advanced user myself it is possible I can overlook something that I need to explain in more detail. Please stop me and ask if anything is unclear!\nSome of the topics covered here will be more or less useful to each of you, depending on the type of work you do and how much and what type of data are involved. But all of it will help you have a strong foundation even if the specific topics here are not directly applicable in your field.\n\n\nR and RStudio are two separate things, and to use both you will need to install two programs onto your personal computer.\n\n\n\n\n\n\nR is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\n\n\nInstalling R\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\nSelect the appropriate operating system 4a. Windows: Then click “base”, then click “Download R-x.y.z for Windows” where x.y.z corresponds to the current version of R, then double click the .exe file that downloads and follow the prompts 4b. Mac: Then click the option corresponding to your Mac model, then double click the .pkg file that downloads and follow the prompts\n\n\n\n\n\n\n\n\n\n\nRStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\n\n\nInstalling RStudio\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download - double click on it and follow the prompts\n\n\n\n\n\n\n\n\n\n\nWe will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\n\n\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\n\nSelect “New Session”\n\n\n\n\n\nSelect “RStudio Pro” then click “Start Session”\n\n\n\n\n\nYou will have some version of the below appear. Note that it will not be identical to this as I have changed many options over time for my personal preferences.\n\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout. I can help you customize as well if there are things you prefer, just ask!\n\n\n\nRstudio panes:\n\nText editor (i.e. R script) - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will disply\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\nUsing the text editor in RStudio:\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R Script\nTo save the file go to: File &gt; Save\n\n\n\n\n\n\n\nSession 1, Exercise 1\n\n\n\n\n\n\nLogin to Posit Workbench and start a new RStudio session.\nGo to File &gt; New File &gt; R Script to open a new, blank R script\nSave the file to a new folder on your home directory called “mmedr” with the name “session1-exercises.R”\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 1 Solution"
  },
  {
    "objectID": "tools-introduction.html#r",
    "href": "tools-introduction.html#r",
    "title": "Introduction to the tools",
    "section": "",
    "text": "R is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\n\n\nInstalling R\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\nSelect the appropriate operating system 4a. Windows: Then click “base”, then click “Download R-x.y.z for Windows” where x.y.z corresponds to the current version of R, then double click the .exe file that downloads and follow the prompts 4b. Mac: Then click the option corresponding to your Mac model, then double click the .pkg file that downloads and follow the prompts"
  },
  {
    "objectID": "tools-introduction.html#rstudio",
    "href": "tools-introduction.html#rstudio",
    "title": "Introduction to the tools",
    "section": "",
    "text": "RStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\n\n\nInstalling RStudio\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download - double click on it and follow the prompts"
  },
  {
    "objectID": "tools-introduction.html#posit-workbench",
    "href": "tools-introduction.html#posit-workbench",
    "title": "Introduction to the tools",
    "section": "",
    "text": "We will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\n\n\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\n\nSelect “New Session”\n\n\n\n\n\nSelect “RStudio Pro” then click “Start Session”\n\n\n\n\n\nYou will have some version of the below appear. Note that it will not be identical to this as I have changed many options over time for my personal preferences.\n\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout. I can help you customize as well if there are things you prefer, just ask!"
  },
  {
    "objectID": "tools-introduction.html#using-rstudio",
    "href": "tools-introduction.html#using-rstudio",
    "title": "Introduction to the tools",
    "section": "",
    "text": "Rstudio panes:\n\nText editor (i.e. R script) - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will disply\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\nUsing the text editor in RStudio:\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R Script\nTo save the file go to: File &gt; Save\n\n\n\n\n\n\n\nSession 1, Exercise 1\n\n\n\n\n\n\nLogin to Posit Workbench and start a new RStudio session.\nGo to File &gt; New File &gt; R Script to open a new, blank R script\nSave the file to a new folder on your home directory called “mmedr” with the name “session1-exercises.R”\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 1 Solution"
  },
  {
    "objectID": "tools-basic-programming.html",
    "href": "tools-basic-programming.html",
    "title": "Basic programming",
    "section": "",
    "text": "In this session, we will learn the basics of programming in R. This will lay the foundation for more advanced topics to come.\n\n\nUse the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns the value on the right, to the object on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\nOnce the object is assigned, the assignment step will be evaluated but it will not print to the console\nPrint to the console by typing the object name alone\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nTo assign a character variable, wrap it in single or double quotes:\n\ny &lt;- \"cat\"\ny\n\n[1] \"cat\"\n\n\n\n\n\nTo send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight multiple lines of code and use one of the previous options\n\n\n\n\n\n\n\nSession 2, Exercise 1\n\n\n\n\n\n\nOpen RStudio Pro on Posit Workbench\nCreate a new R script named “session2-exercises” and save it to the “mmedr” folder on your home directory that was created in Session 1\nCreate an object called “age” and assign it the numeric value of your age\nCreate an object called “name” and assign it the character value of your name\nExecute the code\nPrint the object assignments to the console\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 1 Solution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\nb &lt;- seq(from = 0, to = 100, by = 10)\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order. The above three assignments to b yield the same results.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nSo the following produce the same results:\n\nb &lt;- seq(from = 0, to = 100, by = 10)\nb &lt;- seq(0, 100, 10)\nb &lt;- seq(by = 10, to = 100, from = 0)\n\n\n\n\nGet help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n?mean\n\nstarting httpd help server ... done\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the help file, it can be particularly useful to scroll to the bottom and read and try the exercises.\n\n\n\n\n\n\n\n\nSession 2, Exercise 2\n\n\n\n\n\n\nLook up the help file for the “log” function\nCalculate the natural log of 1\nCalculate log base 10 of 5\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 2 Solution\n\n\n\n\n\n\n#1. \n?log\n\n#2. \nlog(1)\n\n[1] 0\n\n#3.\nlog10(5)\n\n[1] 0.69897\n\n# OR #\nlog(5, base = 10)\n\n[1] 0.69897\n\n# OR #\nlog(base = 10, x = 5)\n\n[1] 0.69897\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can write comments in your R code by starting a line with “#”. It is recommended to write a lot of verbal comments about what your R code is doing so that if you need to come back to it later, you will know what it was doing and why.\nFor example:\n\n# This R code file will demonstrate how to assign a value (on the right) to an object (on the left) using the \"&lt;-\" operator\n\n# Assign the numeric value 5 to the object x\nx &lt;- 5\n\n# Assign the character value a to the object y\ny &lt;- \"a\"\n\n\n\n\n\n\nBefore we go on, we need to learn about the pipe operator.\nWe will use the pipe operator to string multiple functions together seamlessly.\nThere are two forms of the pipe operator in R:\n\nThe “native” pipe operator “|&gt;”\nThe pipe operator from the {magrittr} package “%&gt;%\n\nThey perform (almost) identically, but one is built in to base R and the other requires you to load a package.\nGo to Tools &gt; Global Options &gt; Code &gt; Editing and tick the box for “Use native pipe operator” to enable this in RStudio.\n\n\n\nYou can insert the pipe operator through the keyboard shortcut ctrl + shift + m.\nFor example, if we want generate 100 random numbers from the exponential distribution, take the log transformation, and then get the mean, we could nest the functions as follows:\n\nset.seed(123) # needed to make random number generation reproducible\nmean(log(rexp(100)))\n\n[1] -0.4802932\n\n\nOr we can connect them with the pipe operator:\n\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  log() |&gt; \n  mean()\n\n[1] -0.4802932\n\n\nThe left hand side is passed as the first argument of the function on the right hand side. This creates code that is very readable and concise, expecially if you arrange your code vertically rather than horizontally, and it is also easy to comment out various parts if needed.\n\n# Horizontal pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt; rexp() |&gt;  log() |&gt;  mean()\n\n[1] -0.4802932\n\n\ne.g. What if I change my mind and don’t want the log transformation anymore?\nIn the vertical setup this is easy:\n\n# Vertical pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  # log() |&gt; \n  mean()\n\n[1] 1.045719\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe keyboard shortcut ctrl + shift + c will insert a # (comment) at the beginning of the code line.\n\n\nWe’ll be using the pipe operator throughout the remaining R sessions in this course.\n\n\n\nThe == operator tests equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nThis will be useful later when we subset data.\n\n\n\nR has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest.\nTo use best practices from last class, create an R project for use in this course. Create it in the existing “mmedr” folder on your home directory.\nLoad the “breastcancer” data that we saved as a .csv to the “mmedr” folder on our home drive last class, and assign it to the object “df”.\nClean the names using the {janitor} package.\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\nFor example, to calculate the mean of the variable age_at_diagnosis_years in the dataframe df:\n\nmean(df$age_at_diagnosis_years)\n\n[1] 57.2952\n\n\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(df[[\"age_at_diagnosis_years\"]])\n\n[1] 57.2952\n\n\n\n\n\n\n\n\nSession 2, Exercise 3\n\n\n\n\n\nUse the table() function to create a table of the values in “grade_3_vs_1_or_2” in the breastcancer data.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 3 Solution\n\n\n\n\n\n\ntable(df$grade_3_vs_1_or_2)\n\n\n   0    1 \n1606 1394 \n\n\n\n\n\n\n\n\nSometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with radiation therapy (i.e. rt = 1):\n\ndf_sub &lt;- df[df$rt == 1, ]\nnrow(df_sub)\n\n[1] 1772\n\n\nWe see that the new data subset has 1772 rows instead of the 3000 in the original dataset.\nAnd now there are only values of 1 for the variable “rt”:\n\ntable(df_sub$rt)\n\n\n   1 \n1772 \n\n\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with radiation therapy AND had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 & df$grade_3_vs_1_or_2 == 1, ]\nnrow(df_sub)\n\n[1] 912\n\n\nAnd we see that the new data subset has 912 rows instead of the 3000 in the original dataset.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with radiation therapy OR had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 | df$grade_3_vs_1_or_2 == 1, ]\nnrow(df_sub)\n\n[1] 2254\n\n\nAnd we see that our new data subset has 2254 rows instead of the 3000 in the original dataset.\nWe can also create a subset of our data based on columns, for example limiting to radiation therapy:\n\ndf_sub &lt;- df[ , c(\"rt\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the radiation column among patients with grade 3 disease:\n\ndf_sub &lt;- df[df$grade_3_vs_1_or_2 == 1, c(\"rt\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age_at_diagnosis_years in the dataframe df, but only among those who were treated with radiation therapy:\n\nmean(df$age_at_diagnosis_years[df$rt == 1])\n\n[1] 55.08356\n\n\nThis avoids creating additional datasets that may not be needed again.\n\n\n\n\n\n\nSession 2, Exercise 4\n\n\n\n\n\nSay we are only interested in the affect of radiation therapy in older adults. Create a subset of the breastcancer data in patients &gt;=65 years old, and then look at a table of rt among the older subset.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 4 Solution\n\n\n\n\n\n\ndf_sub &lt;- df[df$age_at_diagnosis_years &gt;= 65, ]\ntable(df_sub$rt)\n\n\n  0   1 \n468 405"
  },
  {
    "objectID": "tools-basic-programming.html#assigning-objects",
    "href": "tools-basic-programming.html#assigning-objects",
    "title": "Basic programming",
    "section": "",
    "text": "Use the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns the value on the right, to the object on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\nOnce the object is assigned, the assignment step will be evaluated but it will not print to the console\nPrint to the console by typing the object name alone\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nTo assign a character variable, wrap it in single or double quotes:\n\ny &lt;- \"cat\"\ny\n\n[1] \"cat\""
  },
  {
    "objectID": "tools-basic-programming.html#sending-code-to-the-console",
    "href": "tools-basic-programming.html#sending-code-to-the-console",
    "title": "Basic programming",
    "section": "",
    "text": "To send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight multiple lines of code and use one of the previous options\n\n\n\n\n\n\n\nSession 2, Exercise 1\n\n\n\n\n\n\nOpen RStudio Pro on Posit Workbench\nCreate a new R script named “session2-exercises” and save it to the “mmedr” folder on your home directory that was created in Session 1\nCreate an object called “age” and assign it the numeric value of your age\nCreate an object called “name” and assign it the character value of your name\nExecute the code\nPrint the object assignments to the console\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 1 Solution"
  },
  {
    "objectID": "tools-basic-programming.html#functions",
    "href": "tools-basic-programming.html#functions",
    "title": "Basic programming",
    "section": "",
    "text": "Functions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\nb &lt;- seq(from = 0, to = 100, by = 10)\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order. The above three assignments to b yield the same results.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nSo the following produce the same results:\n\nb &lt;- seq(from = 0, to = 100, by = 10)\nb &lt;- seq(0, 100, 10)\nb &lt;- seq(by = 10, to = 100, from = 0)"
  },
  {
    "objectID": "tools-basic-programming.html#getting-help",
    "href": "tools-basic-programming.html#getting-help",
    "title": "Basic programming",
    "section": "",
    "text": "Get help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n?mean\n\nstarting httpd help server ... done\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the help file, it can be particularly useful to scroll to the bottom and read and try the exercises.\n\n\n\n\n\n\n\n\nSession 2, Exercise 2\n\n\n\n\n\n\nLook up the help file for the “log” function\nCalculate the natural log of 1\nCalculate log base 10 of 5\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 2 Solution\n\n\n\n\n\n\n#1. \n?log\n\n#2. \nlog(1)\n\n[1] 0\n\n#3.\nlog10(5)\n\n[1] 0.69897\n\n# OR #\nlog(5, base = 10)\n\n[1] 0.69897\n\n# OR #\nlog(base = 10, x = 5)\n\n[1] 0.69897\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can write comments in your R code by starting a line with “#”. It is recommended to write a lot of verbal comments about what your R code is doing so that if you need to come back to it later, you will know what it was doing and why.\nFor example:\n\n# This R code file will demonstrate how to assign a value (on the right) to an object (on the left) using the \"&lt;-\" operator\n\n# Assign the numeric value 5 to the object x\nx &lt;- 5\n\n# Assign the character value a to the object y\ny &lt;- \"a\""
  },
  {
    "objectID": "tools-basic-programming.html#pipe-operator",
    "href": "tools-basic-programming.html#pipe-operator",
    "title": "Basic programming",
    "section": "",
    "text": "Before we go on, we need to learn about the pipe operator.\nWe will use the pipe operator to string multiple functions together seamlessly.\nThere are two forms of the pipe operator in R:\n\nThe “native” pipe operator “|&gt;”\nThe pipe operator from the {magrittr} package “%&gt;%\n\nThey perform (almost) identically, but one is built in to base R and the other requires you to load a package.\nGo to Tools &gt; Global Options &gt; Code &gt; Editing and tick the box for “Use native pipe operator” to enable this in RStudio.\n\n\n\nYou can insert the pipe operator through the keyboard shortcut ctrl + shift + m.\nFor example, if we want generate 100 random numbers from the exponential distribution, take the log transformation, and then get the mean, we could nest the functions as follows:\n\nset.seed(123) # needed to make random number generation reproducible\nmean(log(rexp(100)))\n\n[1] -0.4802932\n\n\nOr we can connect them with the pipe operator:\n\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  log() |&gt; \n  mean()\n\n[1] -0.4802932\n\n\nThe left hand side is passed as the first argument of the function on the right hand side. This creates code that is very readable and concise, expecially if you arrange your code vertically rather than horizontally, and it is also easy to comment out various parts if needed.\n\n# Horizontal pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt; rexp() |&gt;  log() |&gt;  mean()\n\n[1] -0.4802932\n\n\ne.g. What if I change my mind and don’t want the log transformation anymore?\nIn the vertical setup this is easy:\n\n# Vertical pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  # log() |&gt; \n  mean()\n\n[1] 1.045719\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe keyboard shortcut ctrl + shift + c will insert a # (comment) at the beginning of the code line.\n\n\nWe’ll be using the pipe operator throughout the remaining R sessions in this course."
  },
  {
    "objectID": "tools-basic-programming.html#testing-for-equality",
    "href": "tools-basic-programming.html#testing-for-equality",
    "title": "Basic programming",
    "section": "",
    "text": "The == operator tests equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nThis will be useful later when we subset data."
  },
  {
    "objectID": "tools-basic-programming.html#indexing",
    "href": "tools-basic-programming.html#indexing",
    "title": "Basic programming",
    "section": "",
    "text": "R has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest.\nTo use best practices from last class, create an R project for use in this course. Create it in the existing “mmedr” folder on your home directory.\nLoad the “breastcancer” data that we saved as a .csv to the “mmedr” folder on our home drive last class, and assign it to the object “df”.\nClean the names using the {janitor} package.\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\nFor example, to calculate the mean of the variable age_at_diagnosis_years in the dataframe df:\n\nmean(df$age_at_diagnosis_years)\n\n[1] 57.2952\n\n\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(df[[\"age_at_diagnosis_years\"]])\n\n[1] 57.2952\n\n\n\n\n\n\n\n\nSession 2, Exercise 3\n\n\n\n\n\nUse the table() function to create a table of the values in “grade_3_vs_1_or_2” in the breastcancer data.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 3 Solution\n\n\n\n\n\n\ntable(df$grade_3_vs_1_or_2)\n\n\n   0    1 \n1606 1394"
  },
  {
    "objectID": "tools-basic-programming.html#subsets",
    "href": "tools-basic-programming.html#subsets",
    "title": "Basic programming",
    "section": "",
    "text": "Sometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with radiation therapy (i.e. rt = 1):\n\ndf_sub &lt;- df[df$rt == 1, ]\nnrow(df_sub)\n\n[1] 1772\n\n\nWe see that the new data subset has 1772 rows instead of the 3000 in the original dataset.\nAnd now there are only values of 1 for the variable “rt”:\n\ntable(df_sub$rt)\n\n\n   1 \n1772 \n\n\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with radiation therapy AND had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 & df$grade_3_vs_1_or_2 == 1, ]\nnrow(df_sub)\n\n[1] 912\n\n\nAnd we see that the new data subset has 912 rows instead of the 3000 in the original dataset.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with radiation therapy OR had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 | df$grade_3_vs_1_or_2 == 1, ]\nnrow(df_sub)\n\n[1] 2254\n\n\nAnd we see that our new data subset has 2254 rows instead of the 3000 in the original dataset.\nWe can also create a subset of our data based on columns, for example limiting to radiation therapy:\n\ndf_sub &lt;- df[ , c(\"rt\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the radiation column among patients with grade 3 disease:\n\ndf_sub &lt;- df[df$grade_3_vs_1_or_2 == 1, c(\"rt\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age_at_diagnosis_years in the dataframe df, but only among those who were treated with radiation therapy:\n\nmean(df$age_at_diagnosis_years[df$rt == 1])\n\n[1] 55.08356\n\n\nThis avoids creating additional datasets that may not be needed again.\n\n\n\n\n\n\nSession 2, Exercise 4\n\n\n\n\n\nSay we are only interested in the affect of radiation therapy in older adults. Create a subset of the breastcancer data in patients &gt;=65 years old, and then look at a table of rt among the older subset.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 4 Solution\n\n\n\n\n\n\ndf_sub &lt;- df[df$age_at_diagnosis_years &gt;= 65, ]\ntable(df_sub$rt)\n\n\n  0   1 \n468 405"
  },
  {
    "objectID": "bio-epi-visualization.html",
    "href": "bio-epi-visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "In this session, we will review the basics of R and generating descriptive statistics in R, which were introduced in the Tools course. Then we will learn about data visualization, including creating scatterplots, bar charts, histograms, line charts, and boxplots. We’ll discuss plot customization, faceting, and saving plots. Both univariate and bivariable plotting will be covered.\nPlotting features are available in base R, but a very popular package for plotting in R is the {ggplot2} package, which will be the focus in this course.\n\n\n\n\ninstall.packages(\"ggplot2\")\n\n\nlibrary(ggplot2)\n\n\n\nScatterplots display the joint distribution of two continuous variables. For example, what if we wanted to see a plot of “marker” by “age”. Put age on the x-axis and marker on the y-axis.\nThe first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age, y = marker))\n\nThen the scatterplot is created by adding a layer with geom_point() using the + operator:\n\nggplot(data = mycsv, aes(x = age, y = marker)) + \n  geom_point()\n\n\n\n\n\n\n\n\nLook for increasing or decreasing trends, or clusters of points.\n\n\n\nWe can also look at the association between two continuous variables using a line chart.\nThe first layer of the plot specifies the dataset along with the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age, y = marker))\n\nThen the line chart is created by adding a layer with geom_line() using the + operator.\n\nggplot(data = mycsv, aes(x = age, y = marker)) + \n  geom_line()\n\n\n\n\n\n\n\n\nThere is no discernible pattern in this example, but we would look for increasing or decreasing trends in the line.\n\n\n\nA bar chart can be used to visualize the distribution of a categorical variable.\nThe first layer of the plot specifies the dataset and the x-axis variable:\n\nggplot(data = mycsv, aes(x = grade))\n\nThen the bar chart is created by adding a layer with geom_bar() using the + operator:\n\nggplot(data = mycsv, aes(x = grade)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe height of the bar is the number of observations in that category.\n\n\n\nIt is common to want to describe a continuous variable using a histogram, particularly to examine whether the distribution appears approximately normal.\nLet’s look at a histogram of marker. The first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis variable:\n\nggplot(data = mycsv, aes(x = marker))\n\nCreate the histogram by adding a layer with geom_histogram() using the + operator:\n\nggplot(data = mycsv, aes(x = marker)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote that we received a message along with our output, regarding the number of bins being used in our histogram. This is prompting you to examine whether the default of 30 bins is appropriate for your given sample size and distribution\nIn this case, we will specify a smaller number of bins for the histogram using the bins = argument to geom_histogram():\n\nggplot(data = mycsv, aes(x = marker)) + \n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\n\nWe find that the variable “marker” from the trial dataset has a positively skewed distribution.\n\n\n\nBoxplots are another common way of examining continuous variables. The continuous variable is on the y-axis, and there is no variable on the x-axis:\n\nggplot(data = mycsv, aes(y = marker))\n\nAnd the boxplot is created by adding a layer with geom_boxplot() using the + operator:\n\nggplot(data = mycsv, aes(y = marker)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe top and bottom of the box are the 25th and 75th quantiles, the center line is the median, and the whiskers extend to 1.5xIQR.\nWe may also want to make a boxplot according to a categorical variables. Say we are interested in the distribution of marker according to disease grade. We can add an argument to the x-axis of the first layer aesthetics to get separate boxes by grade:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nThere are many customizations available.\nFor example, we can change the x-axis and y-axis labels:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\"\n  )\n\n\n\n\n\n\n\n\nWe can add titles:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\",\n    title = \"Boxplot of marker level by disease grade\"\n  )\n\n\n\n\n\n\n\n\nWe can set axis limits:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 5))\n\n\n\n\n\n\n\n\nAnd we can change the style of the plot using theme elements:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 5)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nThere are many other customizations available, see the ggplot2 website for details and for a helpful cheatsheet of plotting options.\n\n\n\nWhat if it was of interest to see the distribution of marker according to disease grade?\nAdd a layer to our histogram using facet_grid() to get panels for each level of the disease grade variable “grade”.\nNote that by default the y-axis and x-axis limits are fixed across all plots, so we can directly compare the distributions. It is possible to control this with the scales argument to facet_grid(), see ?facet_grid for details.\n\nggplot(data = mycsv, aes(x = marker)) + \n  geom_histogram(bins = 10) +\n  facet_grid(cols = vars(grade))\n\n\n\n\n\n\n\n\n\n\n\nWe will often want to save plots to an external file to insert into a later document. There are several options:\n\nUse the interactive plot window to export your created plot.\nUse code to save your plot to an external location. There is a function called ggsave() specifically for saving results of ggplot(). By default it will save the last created plot, or you can save your plot to an object and specify it directly using the plot argument to ggsave(). You will specify the file format by including an extension, here “.png” on your filename. ]\n\n\n\nCreate your plot. Click on “Export” then select the option… 1. “Copy to Clipboard”. This will open a pop-up window where you could rescale the plot, if desired, and then click “Copy Plot” to copy the plot to your clipboard so that you can paste it into any external document. 2. “Save as Image…”. Here you can change the directory location where you want to save the plot to the same location where you have your code and data files for this class saved so far. You can select from a variety of file formats. Save it as “my-histogram” in PNG format. You can then insert this file into other documents as needed. 3. “Save as PDF…” and follow the same instructions as in B to save a .pdf version of your image.\n\n\n\n\np &lt;- ggplot(data = mycsv, aes(y = marker)) + \n  geom_boxplot() + \n  facet_grid(cols = vars(grade))\n    \nggsave(filename = \"H:/MMED/MMED501/plots/my-boxplot.png\", plot = p)\n\nAdjust the width and height using the width and/or height arguments to the ggsave() function"
  },
  {
    "objectID": "bio-epi-visualization.html#scatterplot",
    "href": "bio-epi-visualization.html#scatterplot",
    "title": "Visualization",
    "section": "",
    "text": "Scatterplots display the joint distribution of two continuous variables. For example, what if we wanted to see a plot of “marker” by “age”. Put age on the x-axis and marker on the y-axis.\nThe first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age, y = marker))\n\nThen the scatterplot is created by adding a layer with geom_point() using the + operator:\n\nggplot(data = mycsv, aes(x = age, y = marker)) + \n  geom_point()\n\n\n\n\n\n\n\n\nLook for increasing or decreasing trends, or clusters of points."
  },
  {
    "objectID": "bio-epi-visualization.html#line-chart",
    "href": "bio-epi-visualization.html#line-chart",
    "title": "Visualization",
    "section": "",
    "text": "We can also look at the association between two continuous variables using a line chart.\nThe first layer of the plot specifies the dataset along with the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age, y = marker))\n\nThen the line chart is created by adding a layer with geom_line() using the + operator.\n\nggplot(data = mycsv, aes(x = age, y = marker)) + \n  geom_line()\n\n\n\n\n\n\n\n\nThere is no discernible pattern in this example, but we would look for increasing or decreasing trends in the line."
  },
  {
    "objectID": "bio-epi-visualization.html#bar-charts",
    "href": "bio-epi-visualization.html#bar-charts",
    "title": "Visualization",
    "section": "",
    "text": "A bar chart can be used to visualize the distribution of a categorical variable.\nThe first layer of the plot specifies the dataset and the x-axis variable:\n\nggplot(data = mycsv, aes(x = grade))\n\nThen the bar chart is created by adding a layer with geom_bar() using the + operator:\n\nggplot(data = mycsv, aes(x = grade)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe height of the bar is the number of observations in that category."
  },
  {
    "objectID": "bio-epi-visualization.html#histogram",
    "href": "bio-epi-visualization.html#histogram",
    "title": "Visualization",
    "section": "",
    "text": "It is common to want to describe a continuous variable using a histogram, particularly to examine whether the distribution appears approximately normal.\nLet’s look at a histogram of marker. The first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis variable:\n\nggplot(data = mycsv, aes(x = marker))\n\nCreate the histogram by adding a layer with geom_histogram() using the + operator:\n\nggplot(data = mycsv, aes(x = marker)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote that we received a message along with our output, regarding the number of bins being used in our histogram. This is prompting you to examine whether the default of 30 bins is appropriate for your given sample size and distribution\nIn this case, we will specify a smaller number of bins for the histogram using the bins = argument to geom_histogram():\n\nggplot(data = mycsv, aes(x = marker)) + \n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\n\nWe find that the variable “marker” from the trial dataset has a positively skewed distribution."
  },
  {
    "objectID": "bio-epi-visualization.html#boxplot",
    "href": "bio-epi-visualization.html#boxplot",
    "title": "Visualization",
    "section": "",
    "text": "Boxplots are another common way of examining continuous variables. The continuous variable is on the y-axis, and there is no variable on the x-axis:\n\nggplot(data = mycsv, aes(y = marker))\n\nAnd the boxplot is created by adding a layer with geom_boxplot() using the + operator:\n\nggplot(data = mycsv, aes(y = marker)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe top and bottom of the box are the 25th and 75th quantiles, the center line is the median, and the whiskers extend to 1.5xIQR.\nWe may also want to make a boxplot according to a categorical variables. Say we are interested in the distribution of marker according to disease grade. We can add an argument to the x-axis of the first layer aesthetics to get separate boxes by grade:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot()"
  },
  {
    "objectID": "bio-epi-visualization.html#customization",
    "href": "bio-epi-visualization.html#customization",
    "title": "Visualization",
    "section": "",
    "text": "There are many customizations available.\nFor example, we can change the x-axis and y-axis labels:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\"\n  )\n\n\n\n\n\n\n\n\nWe can add titles:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\",\n    title = \"Boxplot of marker level by disease grade\"\n  )\n\n\n\n\n\n\n\n\nWe can set axis limits:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 5))\n\n\n\n\n\n\n\n\nAnd we can change the style of the plot using theme elements:\n\nggplot(data = mycsv, aes(y = marker, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Marker level (ng/mL)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 5)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nThere are many other customizations available, see the ggplot2 website for details and for a helpful cheatsheet of plotting options."
  },
  {
    "objectID": "bio-epi-visualization.html#faceting",
    "href": "bio-epi-visualization.html#faceting",
    "title": "Visualization",
    "section": "",
    "text": "What if it was of interest to see the distribution of marker according to disease grade?\nAdd a layer to our histogram using facet_grid() to get panels for each level of the disease grade variable “grade”.\nNote that by default the y-axis and x-axis limits are fixed across all plots, so we can directly compare the distributions. It is possible to control this with the scales argument to facet_grid(), see ?facet_grid for details.\n\nggplot(data = mycsv, aes(x = marker)) + \n  geom_histogram(bins = 10) +\n  facet_grid(cols = vars(grade))"
  },
  {
    "objectID": "bio-epi-visualization.html#saving-plots",
    "href": "bio-epi-visualization.html#saving-plots",
    "title": "Visualization",
    "section": "",
    "text": "We will often want to save plots to an external file to insert into a later document. There are several options:\n\nUse the interactive plot window to export your created plot.\nUse code to save your plot to an external location. There is a function called ggsave() specifically for saving results of ggplot(). By default it will save the last created plot, or you can save your plot to an object and specify it directly using the plot argument to ggsave(). You will specify the file format by including an extension, here “.png” on your filename. ]\n\n\n\nCreate your plot. Click on “Export” then select the option… 1. “Copy to Clipboard”. This will open a pop-up window where you could rescale the plot, if desired, and then click “Copy Plot” to copy the plot to your clipboard so that you can paste it into any external document. 2. “Save as Image…”. Here you can change the directory location where you want to save the plot to the same location where you have your code and data files for this class saved so far. You can select from a variety of file formats. Save it as “my-histogram” in PNG format. You can then insert this file into other documents as needed. 3. “Save as PDF…” and follow the same instructions as in B to save a .pdf version of your image.\n\n\n\n\np &lt;- ggplot(data = mycsv, aes(y = marker)) + \n  geom_boxplot() + \n  facet_grid(cols = vars(grade))\n    \nggsave(filename = \"H:/MMED/MMED501/plots/my-boxplot.png\", plot = p)\n\nAdjust the width and height using the width and/or height arguments to the ggsave() function"
  },
  {
    "objectID": "bio-epi-refresher.html",
    "href": "bio-epi-refresher.html",
    "title": "Refresher of the Tools course material",
    "section": "",
    "text": "In this session, we will review the basics of R and generating descriptive statistics in R, which were introduced in the Tools course. Then we will learn about data visualization, including creating scatterplots, bar charts, histograms, line charts, and boxplots. We’ll discuss plot customization, faceting, and saving plots. Both univariate and bivariable plotting will be covered.\n\n\nFirst, we’ll review the basics of R and R programming.\n\n\n\n\n\n\nR is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\n\n\n\n\n\n\n\n\nRStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download and provide simple instructions to follow\n\n\n\n\n\n\n\n\nWe will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\nWhen you first open RStudio you will see a number of panes:\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout.\nPanes:\n\nText editor - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will disply\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\n\n\n\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R script\nTo save the file go to: File &gt; Save\n\n\n\n\nNavigate to https://lri-r07.lerner.ccf.org/auth-sign-in, log in, and run some example code.\nDemonstrate how to:\n\nCreate a new R script\nAdd some code to it\nRun the code\nView help files\nSave the R script\n\n\nx &lt;- c(1, 2, 3, 4)\nmean(x)\nhist(rnorm(100))\n?rnorm\n\n\n\n\nTo send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight all three lines of code and use one of the previous options\n\n\n\n\nGet help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n\n\nAfter we have run all three lines of code, we see the results of our mean computation in the Console pane.\nAnd we see the resulting histogram in the Plots pane.\n\n\n\n\n\n\n\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nGitHub is a common repository for packages that are in development.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nThen, install the GitHub package of interest using install_github(\"username/repository\"). For example, to install the emo repository from the GitHub username hadley, use:\n\nlibrary(remotes)\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {GenomicFeatures} package using the install function:\n\nBiocManager::install(\"GenomicFeatures\")\n\nInstallation is the first step. Only needs to be done once.\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)\n\n\n\n\nThe most common data format we work with are data from Excel. The example trial dataset is available in the {gtsummary} package in R.\n\nInstall and load the “gtsummary” package\nPreview the trial data by simply typing the name of the dataset:\n\n\ninstall.packages(\"gtsummary\")\n\n\nlibrary(gtsummary)\ntrial\n\n# A tibble: 200 × 8\n   trt      age marker stage grade response death ttdeath\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 Drug A    23  0.16  T1    II           0     0    24  \n 2 Drug B     9  1.11  T2    I            1     0    24  \n 3 Drug A    31  0.277 T1    II           0     0    24  \n 4 Drug A    NA  2.07  T3    III          1     1    17.6\n 5 Drug A    51  2.77  T4    III          1     1    16.4\n 6 Drug B    39  0.613 T4    I            0     1    15.6\n 7 Drug A    37  0.354 T1    II           0     0    24  \n 8 Drug A    32  1.74  T1    I            0     1    18.4\n 9 Drug A    31  0.144 T1    II           0     0    24  \n10 Drug B    34  0.205 T3    I            0     1    10.5\n# ℹ 190 more rows\n\n\nThe help page for the trial data can be accessed by running:\n\n?trial\n\nAnd we see the variables and their definitions:\n\n\n\nI have saved this data file out to Excel so that we can practice loading it in R. Go to the course website to download the file named “trial-Excel.xlsx”. Save it somewhere you can find it again.\n\n\n\nThe most common data format we work with are data from Excel.\nData should be:\n\nOne dataset per file\nA single row of column headers across the top\nSimple column names are better - they will get transformed into variable names by R\nTypically one row per patient/sample is ideal\n\nWe will look at options to:\n\nRead in Excel files with {readxl}\nRead in Excel files by converting to .csv first\nRead in other file formats\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package:\n\ninstall.packages(\"readxl\")\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\n  \"~/MMED/MMED501/data/trial-Excel.xlsx\"\n  )\n\nNote that R treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\nAlso note that on the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and select “CSV (Comma delimited)” from the “Save as type” drop down and save the file to the same location as “trial-csv.csv”\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- \n  read.csv(\n    \"~/MMED/MMED501/data/trial-csv.csv\"\n    ) \n\nNote that this is the approach I always use myself and will form the basis of all of my examples\nMany other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places\n\n\n\n\nUse the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns values on the right, to objects on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nFunctions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\nb &lt;- seq(from = 0, to = 100, by = 10)\nb &lt;- seq(0, 100, 10)\nb &lt;- seq(by = 10, to = 100, from = 0)\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order. The above three assignments to b yield the same results.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nR is case sensitive:\n\ni.e. age is not the same as Age.\nVariable names with spaces are problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in backticks: `Patient Age`\nOne option is to use the clean_names() function from the {janitor} package to convert all variable names to snake case (or alternatives):\n\n\n\ninstall.packages(\"janitor\")\njanitor::clean_names(df)\n\nThe == operator tests equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nWe’ll need this later when we subset data.\nR has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest\nFor example, to calculate the mean of the variable age in the dataframe mycsv:\n\nmean(mycsv$age, na.rm = TRUE)\n\n[1] 47.2381\n\n\nNote that we need to add the argument na.rm = TRUE to remove missing values from the calculation of the mean, otherwise NA will be returned if missing values are present\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(mycsv[[\"age\"]], na.rm = TRUE)\n\n[1] 47.2381\n\n\nSometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with Drug A:\n\ndf_sub &lt;- mycsv[mycsv$trt == \"Drug A\", ]\nnrow(df_sub)\n\n[1] 98\n\n\nWe see that the new data subset has 98 rows.\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with Drug A AND are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$trt == \"Drug A\" & mycsv$age &gt; 45, ]\nnrow(df_sub)\n\n[1] 55\n\n\nAnd we see that the new data subset has 55 rows.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with Drug A OR are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$trt == \"Drug A\" | mycsv$age &gt; 45, ]\nnrow(df_sub)\n\n[1] 157\n\n\nAnd we see that our new datasubset has 157 rows.\nWe can also create a subset of our data based on columns, for example limiting to trt:\n\ndf_sub &lt;- mycsv[ , c(\"trt\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the trt column among patients with age greater than 45:\n\ndf_sub &lt;- mycsv[mycsv$age &gt; 45, c(\"trt\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age in the dataframe mycsv, but only among those who were treated with Drug A:\n\nmean(mycsv$age[mycsv$trt == \"Drug A\"], na.rm = TRUE)\n\n[1] 47.01099\n\n\nThis avoids creating additional datasets that may not be needed again.\n\n\n\n\nNext, we’ll review descriptive statistics in R. There are many ways to generate this type of descriptive statistics in R. I will demonstrate one way and if you end up using R a lot you will find what works well for you and the type of data you use.\nWe will be using some functions from the {janitor} package, so make sure you have that installed.\n\ninstall.packages(\"janitor\")\n\n\nlibrary(janitor)\n\nWe can also create very nice tables by also using the {gt} package.\n\ninstall.packages(\"gt\")\n\n\nlibrary(gt)\n\n\n\nFirst, we need to learn about the pipe operator, which we will use to string multiple functions together seamlessly.\nFor example, if we want to take the log transformation of the marker variable and then get the mean, we could nest the two functions as follows:\n\nmean(log(mycsv$marker), na.rm = TRUE)\n\n[1] -0.707878\n\n\nOr we can connect them with the pipe operator:\n\nmycsv$marker |&gt; \n  log() |&gt; \n  mean(na.rm = TRUE)\n\n[1] -0.707878\n\n\nThe left hand side is passed as the first argument to the function on the right hand side.\nYou can use the native pipe operator through the keyboard shortcut ctrl + shift + m.\nThis creates code that is very readable and concise, and easy to comment out various parts if needed.\nWe’ll be using this throughout the R sessions in this course.\n\n\n\nMake sure your variable of interest is in its own column in your dataframe, then use the tabyl() function from {janitor}:\n\nmycsv |&gt; \n  tabyl(trt) |&gt; \n  adorn_pct_formatting()\n\n    trt   n percent\n Drug A  98   49.0%\n Drug B 102   51.0%\n\n\nAnd we get a frequency table for the trt variable, with the percentages formatted using the adorn_pct_formatting() function.\n\n\n\nLet’s create a table with trt on the rows and response on the columns. The most basic table is created as:\n\nmycsv |&gt; \n  tabyl(trt, response)\n\n    trt  0  1 NA_\n Drug A 67 28   3\n Drug B 65 33   4\n\n\nThen we can use the {gt} package and it’s associated features to customize our two-way contingency table. See the {gt} package website for details.\nLet’s label the row variable and column variable, and add a title:\n\nmycsv |&gt; \n  tabyl(trt, response) |&gt; \n  gt(\n    rowname_col = \"trt\" \n  ) |&gt; \n  tab_spanner(          \n    columns = 2:4,\n    label = \"Response?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Treatment\" \n  ) |&gt; \n  tab_header(           \n    title = \"Response according to treatment group\"\n  )\n\n\n\n\n\n\n\nResponse according to treatment group\n\n\nTreatment\nResponse?\n\n\n0\n1\nNA_\n\n\n\n\nDrug A\n67\n28\n3\n\n\nDrug B\n65\n33\n4\n\n\n\n\n\n\n\nAlternatively, we could display percentages in our table:\n\nmycsv |&gt; \n  tabyl(trt, response) |&gt; \n  adorn_percentages(denominator = \"all\") |&gt; \n  gt() |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:4,\n    label = \"Response?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Treatment\" \n  ) |&gt; \n  tab_header(           \n    title = \"Response according to treatment group\"\n  )\n\n\n\n\n\n\n\nResponse according to treatment group\n\n\ntrt\nResponse?\n\n\n0\n1\nNA_\n\n\n\n\nDrug A\n33.5%\n14.0%\n1.5%\n\n\nDrug B\n32.5%\n16.5%\n2.0%\n\n\n\n\n\n\n\n\n\n\nWe will use the summarize() function from the {dplyr} package to compute summary statistics.\n\ninstall.packages(\"dplyr\")\n\n\nlibrary(dplyr)\n\nLet’s compute the mean and standard deviation of age and marker:\n\nmycsv |&gt; \n  summarize(\n    avg_age = mean(age, na.rm = TRUE),\n    sd_age = sd(age, na.rm = TRUE),\n    avg_marker = mean(marker, na.rm = TRUE),\n    sd_marker = sd(marker, na.rm = TRUE)\n  )\n\n  avg_age   sd_age avg_marker sd_marker\n1 47.2381 14.31193  0.9159895 0.8592891\n\n\n\n\n\nAnd we can easily extend this code to generate summary statistics by group by using the group_by() function from the {dplyr} package.\nLet’s get the same summary table for age and marker, but by trt:\n\nmycsv |&gt; \n  group_by(trt) |&gt; \n  summarize(\n    avg_age = mean(age, na.rm = TRUE),\n    sd_age = sd(age, na.rm = TRUE),\n    avg_marker = mean(marker, na.rm = TRUE),\n    sd_marker = sd(marker, na.rm = TRUE)\n  )\n\n# A tibble: 2 × 5\n  trt    avg_age sd_age avg_marker sd_marker\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 Drug A    47.0   14.7      1.02      0.885\n2 Drug B    47.4   14.0      0.821     0.828"
  },
  {
    "objectID": "bio-epi-refresher.html#r-basics",
    "href": "bio-epi-refresher.html#r-basics",
    "title": "Refresher of the Tools course material",
    "section": "",
    "text": "First, we’ll review the basics of R and R programming.\n\n\n\n\n\n\nR is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\n\n\n\n\n\n\n\n\nRStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download and provide simple instructions to follow\n\n\n\n\n\n\n\n\nWe will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\nWhen you first open RStudio you will see a number of panes:\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout.\nPanes:\n\nText editor - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will disply\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\n\n\n\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R script\nTo save the file go to: File &gt; Save\n\n\n\n\nNavigate to https://lri-r07.lerner.ccf.org/auth-sign-in, log in, and run some example code.\nDemonstrate how to:\n\nCreate a new R script\nAdd some code to it\nRun the code\nView help files\nSave the R script\n\n\nx &lt;- c(1, 2, 3, 4)\nmean(x)\nhist(rnorm(100))\n?rnorm\n\n\n\n\nTo send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight all three lines of code and use one of the previous options\n\n\n\n\nGet help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n\n\nAfter we have run all three lines of code, we see the results of our mean computation in the Console pane.\nAnd we see the resulting histogram in the Plots pane.\n\n\n\n\n\n\n\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nGitHub is a common repository for packages that are in development.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nThen, install the GitHub package of interest using install_github(\"username/repository\"). For example, to install the emo repository from the GitHub username hadley, use:\n\nlibrary(remotes)\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {GenomicFeatures} package using the install function:\n\nBiocManager::install(\"GenomicFeatures\")\n\nInstallation is the first step. Only needs to be done once.\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)\n\n\n\n\nThe most common data format we work with are data from Excel. The example trial dataset is available in the {gtsummary} package in R.\n\nInstall and load the “gtsummary” package\nPreview the trial data by simply typing the name of the dataset:\n\n\ninstall.packages(\"gtsummary\")\n\n\nlibrary(gtsummary)\ntrial\n\n# A tibble: 200 × 8\n   trt      age marker stage grade response death ttdeath\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 Drug A    23  0.16  T1    II           0     0    24  \n 2 Drug B     9  1.11  T2    I            1     0    24  \n 3 Drug A    31  0.277 T1    II           0     0    24  \n 4 Drug A    NA  2.07  T3    III          1     1    17.6\n 5 Drug A    51  2.77  T4    III          1     1    16.4\n 6 Drug B    39  0.613 T4    I            0     1    15.6\n 7 Drug A    37  0.354 T1    II           0     0    24  \n 8 Drug A    32  1.74  T1    I            0     1    18.4\n 9 Drug A    31  0.144 T1    II           0     0    24  \n10 Drug B    34  0.205 T3    I            0     1    10.5\n# ℹ 190 more rows\n\n\nThe help page for the trial data can be accessed by running:\n\n?trial\n\nAnd we see the variables and their definitions:\n\n\n\nI have saved this data file out to Excel so that we can practice loading it in R. Go to the course website to download the file named “trial-Excel.xlsx”. Save it somewhere you can find it again.\n\n\n\nThe most common data format we work with are data from Excel.\nData should be:\n\nOne dataset per file\nA single row of column headers across the top\nSimple column names are better - they will get transformed into variable names by R\nTypically one row per patient/sample is ideal\n\nWe will look at options to:\n\nRead in Excel files with {readxl}\nRead in Excel files by converting to .csv first\nRead in other file formats\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package:\n\ninstall.packages(\"readxl\")\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\n  \"~/MMED/MMED501/data/trial-Excel.xlsx\"\n  )\n\nNote that R treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\nAlso note that on the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and select “CSV (Comma delimited)” from the “Save as type” drop down and save the file to the same location as “trial-csv.csv”\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- \n  read.csv(\n    \"~/MMED/MMED501/data/trial-csv.csv\"\n    ) \n\nNote that this is the approach I always use myself and will form the basis of all of my examples\nMany other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places\n\n\n\n\nUse the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns values on the right, to objects on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nFunctions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\nb &lt;- seq(from = 0, to = 100, by = 10)\nb &lt;- seq(0, 100, 10)\nb &lt;- seq(by = 10, to = 100, from = 0)\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order. The above three assignments to b yield the same results.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nR is case sensitive:\n\ni.e. age is not the same as Age.\nVariable names with spaces are problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in backticks: `Patient Age`\nOne option is to use the clean_names() function from the {janitor} package to convert all variable names to snake case (or alternatives):\n\n\n\ninstall.packages(\"janitor\")\njanitor::clean_names(df)\n\nThe == operator tests equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nWe’ll need this later when we subset data.\nR has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest\nFor example, to calculate the mean of the variable age in the dataframe mycsv:\n\nmean(mycsv$age, na.rm = TRUE)\n\n[1] 47.2381\n\n\nNote that we need to add the argument na.rm = TRUE to remove missing values from the calculation of the mean, otherwise NA will be returned if missing values are present\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(mycsv[[\"age\"]], na.rm = TRUE)\n\n[1] 47.2381\n\n\nSometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with Drug A:\n\ndf_sub &lt;- mycsv[mycsv$trt == \"Drug A\", ]\nnrow(df_sub)\n\n[1] 98\n\n\nWe see that the new data subset has 98 rows.\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with Drug A AND are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$trt == \"Drug A\" & mycsv$age &gt; 45, ]\nnrow(df_sub)\n\n[1] 55\n\n\nAnd we see that the new data subset has 55 rows.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with Drug A OR are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$trt == \"Drug A\" | mycsv$age &gt; 45, ]\nnrow(df_sub)\n\n[1] 157\n\n\nAnd we see that our new datasubset has 157 rows.\nWe can also create a subset of our data based on columns, for example limiting to trt:\n\ndf_sub &lt;- mycsv[ , c(\"trt\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the trt column among patients with age greater than 45:\n\ndf_sub &lt;- mycsv[mycsv$age &gt; 45, c(\"trt\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age in the dataframe mycsv, but only among those who were treated with Drug A:\n\nmean(mycsv$age[mycsv$trt == \"Drug A\"], na.rm = TRUE)\n\n[1] 47.01099\n\n\nThis avoids creating additional datasets that may not be needed again."
  },
  {
    "objectID": "bio-epi-refresher.html#descriptive-statistics",
    "href": "bio-epi-refresher.html#descriptive-statistics",
    "title": "Refresher of the Tools course material",
    "section": "",
    "text": "Next, we’ll review descriptive statistics in R. There are many ways to generate this type of descriptive statistics in R. I will demonstrate one way and if you end up using R a lot you will find what works well for you and the type of data you use.\nWe will be using some functions from the {janitor} package, so make sure you have that installed.\n\ninstall.packages(\"janitor\")\n\n\nlibrary(janitor)\n\nWe can also create very nice tables by also using the {gt} package.\n\ninstall.packages(\"gt\")\n\n\nlibrary(gt)\n\n\n\nFirst, we need to learn about the pipe operator, which we will use to string multiple functions together seamlessly.\nFor example, if we want to take the log transformation of the marker variable and then get the mean, we could nest the two functions as follows:\n\nmean(log(mycsv$marker), na.rm = TRUE)\n\n[1] -0.707878\n\n\nOr we can connect them with the pipe operator:\n\nmycsv$marker |&gt; \n  log() |&gt; \n  mean(na.rm = TRUE)\n\n[1] -0.707878\n\n\nThe left hand side is passed as the first argument to the function on the right hand side.\nYou can use the native pipe operator through the keyboard shortcut ctrl + shift + m.\nThis creates code that is very readable and concise, and easy to comment out various parts if needed.\nWe’ll be using this throughout the R sessions in this course.\n\n\n\nMake sure your variable of interest is in its own column in your dataframe, then use the tabyl() function from {janitor}:\n\nmycsv |&gt; \n  tabyl(trt) |&gt; \n  adorn_pct_formatting()\n\n    trt   n percent\n Drug A  98   49.0%\n Drug B 102   51.0%\n\n\nAnd we get a frequency table for the trt variable, with the percentages formatted using the adorn_pct_formatting() function.\n\n\n\nLet’s create a table with trt on the rows and response on the columns. The most basic table is created as:\n\nmycsv |&gt; \n  tabyl(trt, response)\n\n    trt  0  1 NA_\n Drug A 67 28   3\n Drug B 65 33   4\n\n\nThen we can use the {gt} package and it’s associated features to customize our two-way contingency table. See the {gt} package website for details.\nLet’s label the row variable and column variable, and add a title:\n\nmycsv |&gt; \n  tabyl(trt, response) |&gt; \n  gt(\n    rowname_col = \"trt\" \n  ) |&gt; \n  tab_spanner(          \n    columns = 2:4,\n    label = \"Response?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Treatment\" \n  ) |&gt; \n  tab_header(           \n    title = \"Response according to treatment group\"\n  )\n\n\n\n\n\n\n\nResponse according to treatment group\n\n\nTreatment\nResponse?\n\n\n0\n1\nNA_\n\n\n\n\nDrug A\n67\n28\n3\n\n\nDrug B\n65\n33\n4\n\n\n\n\n\n\n\nAlternatively, we could display percentages in our table:\n\nmycsv |&gt; \n  tabyl(trt, response) |&gt; \n  adorn_percentages(denominator = \"all\") |&gt; \n  gt() |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:4,\n    label = \"Response?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Treatment\" \n  ) |&gt; \n  tab_header(           \n    title = \"Response according to treatment group\"\n  )\n\n\n\n\n\n\n\nResponse according to treatment group\n\n\ntrt\nResponse?\n\n\n0\n1\nNA_\n\n\n\n\nDrug A\n33.5%\n14.0%\n1.5%\n\n\nDrug B\n32.5%\n16.5%\n2.0%\n\n\n\n\n\n\n\n\n\n\nWe will use the summarize() function from the {dplyr} package to compute summary statistics.\n\ninstall.packages(\"dplyr\")\n\n\nlibrary(dplyr)\n\nLet’s compute the mean and standard deviation of age and marker:\n\nmycsv |&gt; \n  summarize(\n    avg_age = mean(age, na.rm = TRUE),\n    sd_age = sd(age, na.rm = TRUE),\n    avg_marker = mean(marker, na.rm = TRUE),\n    sd_marker = sd(marker, na.rm = TRUE)\n  )\n\n  avg_age   sd_age avg_marker sd_marker\n1 47.2381 14.31193  0.9159895 0.8592891\n\n\n\n\n\nAnd we can easily extend this code to generate summary statistics by group by using the group_by() function from the {dplyr} package.\nLet’s get the same summary table for age and marker, but by trt:\n\nmycsv |&gt; \n  group_by(trt) |&gt; \n  summarize(\n    avg_age = mean(age, na.rm = TRUE),\n    sd_age = sd(age, na.rm = TRUE),\n    avg_marker = mean(marker, na.rm = TRUE),\n    sd_marker = sd(marker, na.rm = TRUE)\n  )\n\n# A tibble: 2 × 5\n  trt    avg_age sd_age avg_marker sd_marker\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 Drug A    47.0   14.7      1.02      0.885\n2 Drug B    47.4   14.0      0.821     0.828"
  },
  {
    "objectID": "bio-epi-advanced.html",
    "href": "bio-epi-advanced.html",
    "title": "Advanced programming",
    "section": "",
    "text": "In this session, we will introduce methods to adjust p-values to account for multiple testing, learn advanced programming techniques including for loops and writing custom functions, and cover basic statistical tests to conduct hypothesis testing for different combinations of continuous, categorical, and paired data.\n\n\nWe have previously discussed the role of functions in R, and have seen examples of built-in R functions, such as mean() and p.adjust().\nBut sometimes we’ll want to do something that isn’t included in a built-in R function, or that simplifies use of existing functions.\nUser-defined functions are created using the function() function.\nBasic usage is:\n\nfunction(arguments) expression\n\nWhere arguments are arguments you supply to the function and expression is the expression you want to evaluate.\nFor more complicated procedures, you can wrap multiple expressions in curly brackets, and can also specify what value to return using the return() function:\n\nfunction(arguments) {\n  expression1\n  expression2\n  return(value)\n  }\n\nFor example, I always want to show NA values when I look at a contingency table, which means I have to type in the useNA = \"ifany\" arguement every time I use the table() function, since the default in that function is to exclude missing values.\nTo streamline things, I can create a custom function that includes this option:\n\ntabna &lt;- function(x) table(x, useNA = 'ifany')\n\nNow instead of typing:\n\nlibrary(gtsummary)\n\ntable(trial$response, useNA = 'ifany')\n\n\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nI can type:\n\ntabna(trial$response)\n\nx\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nThis gets particularly useful for long or complex procedures, but is also really useful for short procedures that will be repeated many times - I often use this function 10+ times in a day.\nTry writing a custom function based on the mean() function but including the option to remove NAs from the calculation.\n\n\n\nOften we will want to repeat a set of operations several times, and we can do so using a loop.\nThere are three main types of loops in R:\n\nfor loop\nwhile loop\nrepeat loop\n\nWe will focus on the for loop today.\nHere is a basic example using the print() function to repeatedly print a value:\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nHere are the steps of the execution:\n\nThe value of i is set to 1\nThe value of i is printed to the console (first iteration complete)\nThe value of i is set to 2 (the for loop loops back to the beginning)\nThe value of i is printed to the console\n\nAnd so on until we reach the last value of i, and the process is complete.\nSay you have a biomarker in your dataset but you know the machine that generated the data has a lower limit of detection of 0.2. You could choose to impute half the detection limit for any values that fall below 0.2 as follows:\n\ntrial$marker_corrected &lt;- trial$marker\n\nfor(i in 1:nrow(trial)) {\n  if (is.na(trial$marker[i])) {\n    trial$marker_corrected[i] &lt;- NA\n  } else if (trial$marker[i] &lt; 0.2) {\n    trial$marker_corrected[i] &lt;- 0.1\n  }\n}\n\nAnd we can see that our new variable has the value 0.1 for all cases where marker was &lt;0.2:\n\ntrial[trial$marker &lt; 0.2, c(\"marker\", \"marker_corrected\")]\n\n# A tibble: 54 × 2\n   marker marker_corrected\n    &lt;dbl&gt;            &lt;dbl&gt;\n 1  0.16               0.1\n 2  0.144              0.1\n 3  0.06               0.1\n 4  0.128              0.1\n 5  0.157              0.1\n 6  0.066              0.1\n 7  0.096              0.1\n 8  0.105              0.1\n 9  0.043              0.1\n10  0.105              0.1\n# ℹ 44 more rows"
  },
  {
    "objectID": "bio-epi-advanced.html#custom-functions",
    "href": "bio-epi-advanced.html#custom-functions",
    "title": "Advanced programming",
    "section": "",
    "text": "We have previously discussed the role of functions in R, and have seen examples of built-in R functions, such as mean() and p.adjust().\nBut sometimes we’ll want to do something that isn’t included in a built-in R function, or that simplifies use of existing functions.\nUser-defined functions are created using the function() function.\nBasic usage is:\n\nfunction(arguments) expression\n\nWhere arguments are arguments you supply to the function and expression is the expression you want to evaluate.\nFor more complicated procedures, you can wrap multiple expressions in curly brackets, and can also specify what value to return using the return() function:\n\nfunction(arguments) {\n  expression1\n  expression2\n  return(value)\n  }\n\nFor example, I always want to show NA values when I look at a contingency table, which means I have to type in the useNA = \"ifany\" arguement every time I use the table() function, since the default in that function is to exclude missing values.\nTo streamline things, I can create a custom function that includes this option:\n\ntabna &lt;- function(x) table(x, useNA = 'ifany')\n\nNow instead of typing:\n\nlibrary(gtsummary)\n\ntable(trial$response, useNA = 'ifany')\n\n\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nI can type:\n\ntabna(trial$response)\n\nx\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nThis gets particularly useful for long or complex procedures, but is also really useful for short procedures that will be repeated many times - I often use this function 10+ times in a day.\nTry writing a custom function based on the mean() function but including the option to remove NAs from the calculation."
  },
  {
    "objectID": "bio-epi-advanced.html#loops",
    "href": "bio-epi-advanced.html#loops",
    "title": "Advanced programming",
    "section": "",
    "text": "Often we will want to repeat a set of operations several times, and we can do so using a loop.\nThere are three main types of loops in R:\n\nfor loop\nwhile loop\nrepeat loop\n\nWe will focus on the for loop today.\nHere is a basic example using the print() function to repeatedly print a value:\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nHere are the steps of the execution:\n\nThe value of i is set to 1\nThe value of i is printed to the console (first iteration complete)\nThe value of i is set to 2 (the for loop loops back to the beginning)\nThe value of i is printed to the console\n\nAnd so on until we reach the last value of i, and the process is complete.\nSay you have a biomarker in your dataset but you know the machine that generated the data has a lower limit of detection of 0.2. You could choose to impute half the detection limit for any values that fall below 0.2 as follows:\n\ntrial$marker_corrected &lt;- trial$marker\n\nfor(i in 1:nrow(trial)) {\n  if (is.na(trial$marker[i])) {\n    trial$marker_corrected[i] &lt;- NA\n  } else if (trial$marker[i] &lt; 0.2) {\n    trial$marker_corrected[i] &lt;- 0.1\n  }\n}\n\nAnd we can see that our new variable has the value 0.1 for all cases where marker was &lt;0.2:\n\ntrial[trial$marker &lt; 0.2, c(\"marker\", \"marker_corrected\")]\n\n# A tibble: 54 × 2\n   marker marker_corrected\n    &lt;dbl&gt;            &lt;dbl&gt;\n 1  0.16               0.1\n 2  0.144              0.1\n 3  0.06               0.1\n 4  0.128              0.1\n 5  0.157              0.1\n 6  0.066              0.1\n 7  0.096              0.1\n 8  0.105              0.1\n 9  0.043              0.1\n10  0.105              0.1\n# ℹ 44 more rows"
  },
  {
    "objectID": "bio-epi-multiple-testing.html",
    "href": "bio-epi-multiple-testing.html",
    "title": "Adjustment for multiple comparisons",
    "section": "",
    "text": "Adjustment for multiple comparisons\nIn this session, we will introduce methods to adjust p-values to account for multiple testing, learn advanced programming techniques including for loops and writing custom functions, and cover basic statistical tests to conduct hypothesis testing for different combinations of continuous, categorical, and paired data.\nThe problem is referred to as multiple comparisons, multiple testing, or multiplicity, but they all mean the same thing.\nWhat do we mean by multiple comparisons, and what is the issue?\nWhen multiple statistical tests are conducted simultaneously, type I errors become more likely. Therefore, our standard type I error rate of 0.05 that is used to determine whether p-values are significant or not is no longer correct, because the type I error has been inflated due to the multiple testing.\nMultiple comparisons affects both p-values and confidence intervals.\nPrior to significance testing we need to identify a more strict p-value threshold or, alternatively, directly adjust our p-values.\nA number of corrections for multiple comparisons can be implemented with the R function p.adjust().\nConsider the setting where we have p-values for the association between 10 different gene mutations and treatment response:\n\nlibrary(tibble)\nlibrary(gt)\n\nptab &lt;-\n  tibble(\n  Gene = paste0(\"gene\", seq(1:10)),\n  `p-value` = c(0.001, 0.245, 0.784, 0.034, 0.004, 0.123, 0.089, 0.063, 0.228, \n                0.802)\n  ) \n\nptab |&gt; \n  gt() |&gt; \n  tab_header(\"Table of p-values for association with treatment response\")\n\n\n\n\n\n\n\nTable of p-values for association with treatment response\n\n\nGene\np-value\n\n\n\n\ngene1\n0.001\n\n\ngene2\n0.245\n\n\ngene3\n0.784\n\n\ngene4\n0.034\n\n\ngene5\n0.004\n\n\ngene6\n0.123\n\n\ngene7\n0.089\n\n\ngene8\n0.063\n\n\ngene9\n0.228\n\n\ngene10\n0.802\n\n\n\n\n\n\n\nFirst, adjust these for multiple testing using the false-discovery rate approach. Pass the vector of p-values to p.adjust() and specify method = \"fdr\":\n\np.adjust(\n  p = c(0.001, 0.245, 0.784, 0.034, 0.004, 0.123, 0.089, 0.063, 0.228, 0.802),\n  method = \"fdr\"\n)\n\n [1] 0.0100000 0.3062500 0.8020000 0.1133333 0.0200000 0.2050000 0.1780000\n [8] 0.1575000 0.3062500 0.8020000\n\n\nGet back a vector of the adjusted p-values, listed in the same order as the originally provided p-values.\nThe false-discovery rate is the expected proportion of false positives among all significant tests, and is an appropriate method to use when a study is viewed as exploratory and significant results will be followed up in an independent study.\nAlternatively, we could adjust the p-values for multiple testing using the family-wise error approach. Some options include the Bonferroni correction (most conservative, i.e. most difficult to achieve significance) (method = \"bonferroni\") and the Holm-Bonferroni correction (method = \"holm\").\n\np.adjust(\n  p = c(0.001, 0.245, 0.784, 0.034, 0.004, 0.123, 0.089, 0.063, 0.228, 0.802),\n  method = \"bonferroni\"\n)\n\n [1] 0.01 1.00 1.00 0.34 0.04 1.00 0.89 0.63 1.00 1.00\n\n\nAnd we see that using the Bonferroni method, the adjusted p-values are larger than when using the FDR method. The familywise error rate is the probability of making a type I error among a specified group (“family”) of tests.\nAfter adjusting the p-values, we can compare them to the standard 0.05 level of significance.\nWe can place the FDR-adjusted p-values into our table by directly applying the p.adjust() function to our column of p-values as follows:\n\nlibrary(dplyr)\n\nptab |&gt; \n  mutate(\n    `q-value` = p.adjust(`p-value`, method = \"fdr\")\n  ) |&gt; \n  gt() |&gt; \n  fmt_number(columns = `q-value`, decimals = 3) |&gt; \n  tab_header(\"Table of adjusted p-values for association with treatment response\")\n\n\n\n\n\n\n\nTable of adjusted p-values for association with treatment response\n\n\nGene\np-value\nq-value\n\n\n\n\ngene1\n0.001\n0.010\n\n\ngene2\n0.245\n0.306\n\n\ngene3\n0.784\n0.802\n\n\ngene4\n0.034\n0.113\n\n\ngene5\n0.004\n0.020\n\n\ngene6\n0.123\n0.205\n\n\ngene7\n0.089\n0.178\n\n\ngene8\n0.063\n0.158\n\n\ngene9\n0.228\n0.306\n\n\ngene10\n0.802\n0.802\n\n\n\n\n\n\n\nNote that “q-value” is a common term for p-values that have been adjusted for multiple comparisons."
  },
  {
    "objectID": "bio-epi-statistical-tests.html",
    "href": "bio-epi-statistical-tests.html",
    "title": "Statistical tests",
    "section": "",
    "text": "In this session, we will introduce methods to adjust p-values to account for multiple testing, learn advanced programming techniques including for loops and writing custom functions, and cover basic statistical tests to conduct hypothesis testing for different combinations of continuous, categorical, and paired data.\n\n\nThere are two main tests for associations between two categorical variables: the chi-squared test and Fisher’s exact test.\nConduct these tests in R using the following functions:\n\nchisq.test()\nfisher.test()\n\nConduct a chi-squared test of the null hypothesis that there is no association between treatment and response versus the alternative hypothesis that there is an association between treatment and response.\n\nlibrary(gtsummary)\n\nchisq.test(x = trial$trt, y = trial$response)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  trial$trt and trial$response\nX-squared = 0.22329, df = 1, p-value = 0.6365\n\n\nThe chi-squared test statistic is 0.22329 with associated p-value 0.6365.\nDo not reject the null hypothesis since the p-value is greater than the traditional threshold for significance of 0.05.\nConduct a Fisher’s exact test (an alternative to the chi-squared test when any expected cell count is &lt;5):\n\nfisher.test(x = trial$trt, y = trial$response)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  trial$trt and trial$response\np-value = 0.5403\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6326222 2.3394994\nsample estimates:\nodds ratio \n  1.213605 \n\n\nThe p-value is 0.5403.\nDo not reject the null hypothesis of no association between treatment and response since the p-value is greater than the traditional threshold for significance of 0.05.\n\n\n\nThe most common statistical tests for the association between a continuous and a categorical variable are the non-parametric Kruskal-Wallis test and the parametric t-test.\nConduct these tests in R using the following functions:\n\nkruskal.test() (see also wilcox.test())\nt.test()\n\nNote that the Kruskal-Wallis test is also known as the Wilcoxon rank-sum test in the special case of a 2-level categorical variable.\n“Non-parametric” means that there is no parametric distribution assumption made on the continuous variable - i.e. the continuous variable does not need to be normally distributed.\nConduct a Kruskal-Wallis test to test the null hypothesis of no association between marker status and response versus the alternative hypothesis that there is an association between marker status and response.\n\nkruskal.test(marker ~ response, data = trial)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  marker by response\nKruskal-Wallis chi-squared = 2.727, df = 1, p-value = 0.09866\n\n\nSince “response” is a 2-level categorical variable, the Wilcoxon rank-sum test (without continuity correction) produces the same result:\n\nwilcox.test(marker ~ response, correct = FALSE, data = trial)\n\n\n    Wilcoxon rank sum test\n\ndata:  marker by response\nW = 3043, p-value = 0.09866\nalternative hypothesis: true location shift is not equal to 0\n\n\nWith a p-value of 0.099, do not reject the null hypothesis at the 0.05 significance level.\n“Parametric” means that the test assumes a parametric distirbution - in the case of the t-test, it relies on the assumption that the continuous variable is normally distributed.\nIf appropriate given the distribution of the continuous variable, conduct a t-test:\n\nt.test(marker ~ response, data = trial)\n\n\n    Welch Two Sample t-test\n\ndata:  marker by response\nt = -1.5851, df = 96.232, p-value = 0.1162\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.51378857  0.05753795\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8425238       1.0706491 \n\n\nThe p-value differs but the conclusion is the same: do not reject the null hypothesis that there is no association between marker and response.\nHowever, in this example the data are right-skewed so a t-test is not appropriate.\n\nlibrary(ggplot2)\n\nggplot(data = trial, aes(x = marker)) +\n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n\nTips:\n\nFor the preceding two tests we used the formula option to supply the information for the test\nA formula in R looks like LHS ~ RHS where the left-hand side (“LHS”) is typically an outcome variable or dependent variable and the right-hand side (“RHS”) is the independent variable.\nFor multivariable regression, you can specify formulas in the format Y ~ X1 + X2 + X3... when there is more than one independent variable.\nYou must also supply the name of the dataset to the data = argument so that R knows where to look to find the specified variables.\nSee the help files for alternative ways to supply the information for each test\n\nWhat if our categorical variables has more than 2 levels, but we want to do a parametric test? Then we will use ANOVA. ANOVA tests the null hypothesis of no association between marker and grade, which has more than two levels so a t-test is not appropriate, and relies on the assumption that the continuous variable is normally distributed.\n\nlm_mod &lt;- lm(marker ~ grade, data = trial)\nanova(lm_mod)\n\nAnalysis of Variance Table\n\nResponse: marker\n           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \ngrade       2   5.385 2.69264  3.7529 0.02523 *\nResiduals 187 134.168 0.71748                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnd here we would reject the null hypothesis of no association between marker and grade, at the 0.05 level.\n\n\n\nNext we consider the setting where we have paired data. Paired data are any data where a continuous variable is matched in a meaningful way between the two groups. Examples:\n\nPre vs post drug/surgery/test/etc on a single subject\nMeasurements on two eyes within subject\nSibling or spousal pairs\n\nWe will use the example data from the help page found by running ?wilcox.test. These are measurements of a continuous depression scale on 9 patients taken at the first (x) and second (y) visits after inititiation of a certain therapy. We want to test the null hypothesis that there is no difference in depression scale values between these two times.\n\nx &lt;- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)\ny &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)\n\nThe Wilcoxon signed-rank test is a non-parametric test for the association between paired continuous data. Note that this is the same function we used for the Wilcoxon rank-sum test previously, with non-paired data, only now we add the paired = TRUE argument.\n\nwilcox.test(x, y, paired = TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  x and y\nV = 40, p-value = 0.03906\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe reject the null hypothesis at the 0.05 level.\nFor demonstration purposes we also try the paired t-test, which requires data to be normally distributed, to test the null hypothesis that there is no difference in depression scale values between these two times. Again, note that this is the same function we used for the standard t-test previously, only now we have added the paired = TRUE argument.\n\nt.test(x, y, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  x and y\nt = 3.0354, df = 8, p-value = 0.01618\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1037787 0.7599991\nsample estimates:\nmean difference \n      0.4318889 \n\n\nAnd again we reject the null hypothesis at the 0.05 level."
  },
  {
    "objectID": "bio-epi-statistical-tests.html#two-categorical-variables",
    "href": "bio-epi-statistical-tests.html#two-categorical-variables",
    "title": "Statistical tests",
    "section": "",
    "text": "There are two main tests for associations between two categorical variables: the chi-squared test and Fisher’s exact test.\nConduct these tests in R using the following functions:\n\nchisq.test()\nfisher.test()\n\nConduct a chi-squared test of the null hypothesis that there is no association between treatment and response versus the alternative hypothesis that there is an association between treatment and response.\n\nlibrary(gtsummary)\n\nchisq.test(x = trial$trt, y = trial$response)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  trial$trt and trial$response\nX-squared = 0.22329, df = 1, p-value = 0.6365\n\n\nThe chi-squared test statistic is 0.22329 with associated p-value 0.6365.\nDo not reject the null hypothesis since the p-value is greater than the traditional threshold for significance of 0.05.\nConduct a Fisher’s exact test (an alternative to the chi-squared test when any expected cell count is &lt;5):\n\nfisher.test(x = trial$trt, y = trial$response)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  trial$trt and trial$response\np-value = 0.5403\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6326222 2.3394994\nsample estimates:\nodds ratio \n  1.213605 \n\n\nThe p-value is 0.5403.\nDo not reject the null hypothesis of no association between treatment and response since the p-value is greater than the traditional threshold for significance of 0.05."
  },
  {
    "objectID": "bio-epi-statistical-tests.html#one-continuous-one-categorical",
    "href": "bio-epi-statistical-tests.html#one-continuous-one-categorical",
    "title": "Statistical tests",
    "section": "",
    "text": "The most common statistical tests for the association between a continuous and a categorical variable are the non-parametric Kruskal-Wallis test and the parametric t-test.\nConduct these tests in R using the following functions:\n\nkruskal.test() (see also wilcox.test())\nt.test()\n\nNote that the Kruskal-Wallis test is also known as the Wilcoxon rank-sum test in the special case of a 2-level categorical variable.\n“Non-parametric” means that there is no parametric distribution assumption made on the continuous variable - i.e. the continuous variable does not need to be normally distributed.\nConduct a Kruskal-Wallis test to test the null hypothesis of no association between marker status and response versus the alternative hypothesis that there is an association between marker status and response.\n\nkruskal.test(marker ~ response, data = trial)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  marker by response\nKruskal-Wallis chi-squared = 2.727, df = 1, p-value = 0.09866\n\n\nSince “response” is a 2-level categorical variable, the Wilcoxon rank-sum test (without continuity correction) produces the same result:\n\nwilcox.test(marker ~ response, correct = FALSE, data = trial)\n\n\n    Wilcoxon rank sum test\n\ndata:  marker by response\nW = 3043, p-value = 0.09866\nalternative hypothesis: true location shift is not equal to 0\n\n\nWith a p-value of 0.099, do not reject the null hypothesis at the 0.05 significance level.\n“Parametric” means that the test assumes a parametric distirbution - in the case of the t-test, it relies on the assumption that the continuous variable is normally distributed.\nIf appropriate given the distribution of the continuous variable, conduct a t-test:\n\nt.test(marker ~ response, data = trial)\n\n\n    Welch Two Sample t-test\n\ndata:  marker by response\nt = -1.5851, df = 96.232, p-value = 0.1162\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.51378857  0.05753795\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8425238       1.0706491 \n\n\nThe p-value differs but the conclusion is the same: do not reject the null hypothesis that there is no association between marker and response.\nHowever, in this example the data are right-skewed so a t-test is not appropriate.\n\nlibrary(ggplot2)\n\nggplot(data = trial, aes(x = marker)) +\n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n\nTips:\n\nFor the preceding two tests we used the formula option to supply the information for the test\nA formula in R looks like LHS ~ RHS where the left-hand side (“LHS”) is typically an outcome variable or dependent variable and the right-hand side (“RHS”) is the independent variable.\nFor multivariable regression, you can specify formulas in the format Y ~ X1 + X2 + X3... when there is more than one independent variable.\nYou must also supply the name of the dataset to the data = argument so that R knows where to look to find the specified variables.\nSee the help files for alternative ways to supply the information for each test\n\nWhat if our categorical variables has more than 2 levels, but we want to do a parametric test? Then we will use ANOVA. ANOVA tests the null hypothesis of no association between marker and grade, which has more than two levels so a t-test is not appropriate, and relies on the assumption that the continuous variable is normally distributed.\n\nlm_mod &lt;- lm(marker ~ grade, data = trial)\nanova(lm_mod)\n\nAnalysis of Variance Table\n\nResponse: marker\n           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \ngrade       2   5.385 2.69264  3.7529 0.02523 *\nResiduals 187 134.168 0.71748                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnd here we would reject the null hypothesis of no association between marker and grade, at the 0.05 level."
  },
  {
    "objectID": "bio-epi-statistical-tests.html#paired-data",
    "href": "bio-epi-statistical-tests.html#paired-data",
    "title": "Statistical tests",
    "section": "",
    "text": "Next we consider the setting where we have paired data. Paired data are any data where a continuous variable is matched in a meaningful way between the two groups. Examples:\n\nPre vs post drug/surgery/test/etc on a single subject\nMeasurements on two eyes within subject\nSibling or spousal pairs\n\nWe will use the example data from the help page found by running ?wilcox.test. These are measurements of a continuous depression scale on 9 patients taken at the first (x) and second (y) visits after inititiation of a certain therapy. We want to test the null hypothesis that there is no difference in depression scale values between these two times.\n\nx &lt;- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)\ny &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)\n\nThe Wilcoxon signed-rank test is a non-parametric test for the association between paired continuous data. Note that this is the same function we used for the Wilcoxon rank-sum test previously, with non-paired data, only now we add the paired = TRUE argument.\n\nwilcox.test(x, y, paired = TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  x and y\nV = 40, p-value = 0.03906\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe reject the null hypothesis at the 0.05 level.\nFor demonstration purposes we also try the paired t-test, which requires data to be normally distributed, to test the null hypothesis that there is no difference in depression scale values between these two times. Again, note that this is the same function we used for the standard t-test previously, only now we have added the paired = TRUE argument.\n\nt.test(x, y, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  x and y\nt = 3.0354, df = 8, p-value = 0.01618\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1037787 0.7599991\nsample estimates:\nmean difference \n      0.4318889 \n\n\nAnd again we reject the null hypothesis at the 0.05 level."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R For Molecular Medicine",
    "section": "",
    "text": "This website hosts R teaching materials for the Cleveland Clinic Molecular Medicine PhD program. The material will be split across 5 1-hour sessions as part of the Tools course, followed by 2 2-hour sessions as part of the Biostatistics and Epidemiology course."
  },
  {
    "objectID": "index.html#tools-course",
    "href": "index.html#tools-course",
    "title": "R For Molecular Medicine",
    "section": "Tools course",
    "text": "Tools course\n\nSession 1\n\nIntroduction to the tools\n\nR\nRStudio\nPosit Workbench\n\nInstalling and loading R packages\n\nCRAN\nGithub\nBioconductor\n\nLoading data\n\n.xlsx\n.csv\nOther formats\nVariable names (janitor)\n\nReproducibility\n\nRStudio projects\nProject workflow and organization\n{here} package\n\n\n\n\nSession 2\n\nBasic programming\n\nAssigning objects\nSending code to the console\nFunctions\nGetting help\nThe pipe operator\nTesting for equality\nIndexing\nSubsets\n\n\n\n\nSession 3\n\nManipulate dataframes\n\nIndexing operators - extract rows/columns\nAccessing variables in datasets\nSubsetting data\nRename columns\nAdd columns\nGroup a continuous variable\nRecategorize a categorical variable\nSort by row\nReshape (wide to long, long to wide)\n\n\n\n\nSession 4\n\nDescriptive statistics\n\nOne-way frequency table\nTwo-way contingency table\nSummary statistics\nSummary statistics by group\n\n\n\n\nSession 5\n\nPut it all together"
  },
  {
    "objectID": "index.html#biostatistics-and-epidemiology",
    "href": "index.html#biostatistics-and-epidemiology",
    "title": "R For Molecular Medicine",
    "section": "Biostatistics and Epidemiology",
    "text": "Biostatistics and Epidemiology\n\nSession 1\n\nRefresher of the Tools course material\n\nR basics\nDescriptive statistics\n\nVisualization\n\nScatterplot\nBar chart\nHistogram\nLine chart\nBoxplot\nCustomization\nFaceting\nSaving plots\n\n\n\n\nSession 2\n\nAdjustment for multiple comparisons\nAdvanced programming\n\nWriting custom functions\nFor loops/apply/map\n\nStatistical tests\n\nFisher’s exact test\nChi-squared test\nWilcoxon rank sum test/Kruskal-Wallis test\nT-test\nANOVA\nWilcoxon signed rank test\nPaired t-test"
  },
  {
    "objectID": "tools-install-packages.html",
    "href": "tools-install-packages.html",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "In the next part of Session 1, we will learn how to install and load R packages.\n\n\n\n\n\n\n\n\nR package\n\n\n\nAn R package is a collection of code, data, documentation, and tests.\nR packages are developed by the community.\nR packages add functionality to what comes in base R.\nTo use R packages, there are two steps:\n\nInstall\nLoad\n\n\n\n\n\n\nWe will cover the second step first, because it is the same for all methods of installing packages and we will reference this in covering some of the methods of installation.\nInstallation is the first step. Only needs to be done once. (Though needs to be repeated if you get a new version of R)\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)\n\n\n\n\nThere are three main repositories for R packages: CRAN, GitHub, and Bioconductor\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nThis package has comprehensive functionality for survival analyses.\n\n\n\nGitHub is a common repository for packages that are still in development, or have not developed thoroughly enough to be accepted onto CRAN.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nNext load the {remotes} package using a call to library():\n\nlibrary(remotes)\n\nThen install the GitHub package of interest using install_github(\"username/repository\"), where “username” is the name of the GitHub user and “repository” is the name of the repository under the user’s account. For example, to install the emo repository from the GitHub user with username hadley, use:\n\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nThis package will let you put emojis in your documents 😄\n\n\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {ggtree} package with the install function, using either the library::function() syntax:\n\nBiocManager::install(\"ggtree\")\n\nOr using a call to library() followed by a separate call to install():\n\nlibrary(BiocManager)\ninstall(\"ggtree\")\n\nThis package is designed for visualization and annotation of phylogentic trees.\n\n\n\n\n\n\nTip\n\n\n\nWhen using Posit Workbench, many commonly used packages have already been installed for the current version of R by the system administrator.\nAlways start by trying to load a package of interest first to see if it is available.\n\n\n\n\n\n\n\n\nTip\n\n\n\nR scripts are used for programming and saved with other project-related documents for reproducibility purposes.\nIt is important to include statements to load the packages used in any analysis in the R script.\nHowever, I do not think it is necessary to include statements to install the packages in the R script. I personally type these statements directly into the console since they do not need to be run every time and therefore are not part of the reproducibility pipeline.\n\n\n\n\n\n\n\n\nSession 1, Exercise 2\n\n\n\n\n\n\nOpen the R script we created earlier named “session1-exercies.R”\nLoad packages we will need in the rest of today’s session, including: janitor, here, readr, readxl\n\nNote that these packages are already available on the Posit Workbench servers. If you are using RStudio on your personal computer instead, you will need to install them if you have not done so already.\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 2 Solution\n\n\n\n\n\nIf using Posit Workbench where the packages are already installed:\n\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)\n\nIf using a personal computer where you have not previousling installed these packages:\n\ninstall.packages(\"janitor\")\ninstall.packages(\"here\")\ninstall.packages(\"readr\")\ninstall.packages(\"readxl\")\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)"
  },
  {
    "objectID": "tools-install-packages.html#what-is-an-r-package",
    "href": "tools-install-packages.html#what-is-an-r-package",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "R package\n\n\n\nAn R package is a collection of code, data, documentation, and tests.\nR packages are developed by the community.\nR packages add functionality to what comes in base R.\nTo use R packages, there are two steps:\n\nInstall\nLoad"
  },
  {
    "objectID": "tools-install-packages.html#loading-r-packages",
    "href": "tools-install-packages.html#loading-r-packages",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "We will cover the second step first, because it is the same for all methods of installing packages and we will reference this in covering some of the methods of installation.\nInstallation is the first step. Only needs to be done once. (Though needs to be repeated if you get a new version of R)\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)"
  },
  {
    "objectID": "tools-install-packages.html#installing-r-packages",
    "href": "tools-install-packages.html#installing-r-packages",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "There are three main repositories for R packages: CRAN, GitHub, and Bioconductor\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nThis package has comprehensive functionality for survival analyses.\n\n\n\nGitHub is a common repository for packages that are still in development, or have not developed thoroughly enough to be accepted onto CRAN.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nNext load the {remotes} package using a call to library():\n\nlibrary(remotes)\n\nThen install the GitHub package of interest using install_github(\"username/repository\"), where “username” is the name of the GitHub user and “repository” is the name of the repository under the user’s account. For example, to install the emo repository from the GitHub user with username hadley, use:\n\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nThis package will let you put emojis in your documents 😄\n\n\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {ggtree} package with the install function, using either the library::function() syntax:\n\nBiocManager::install(\"ggtree\")\n\nOr using a call to library() followed by a separate call to install():\n\nlibrary(BiocManager)\ninstall(\"ggtree\")\n\nThis package is designed for visualization and annotation of phylogentic trees.\n\n\n\n\n\n\nTip\n\n\n\nWhen using Posit Workbench, many commonly used packages have already been installed for the current version of R by the system administrator.\nAlways start by trying to load a package of interest first to see if it is available.\n\n\n\n\n\n\n\n\nTip\n\n\n\nR scripts are used for programming and saved with other project-related documents for reproducibility purposes.\nIt is important to include statements to load the packages used in any analysis in the R script.\nHowever, I do not think it is necessary to include statements to install the packages in the R script. I personally type these statements directly into the console since they do not need to be run every time and therefore are not part of the reproducibility pipeline.\n\n\n\n\n\n\n\n\nSession 1, Exercise 2\n\n\n\n\n\n\nOpen the R script we created earlier named “session1-exercies.R”\nLoad packages we will need in the rest of today’s session, including: janitor, here, readr, readxl\n\nNote that these packages are already available on the Posit Workbench servers. If you are using RStudio on your personal computer instead, you will need to install them if you have not done so already.\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 2 Solution\n\n\n\n\n\nIf using Posit Workbench where the packages are already installed:\n\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)\n\nIf using a personal computer where you have not previousling installed these packages:\n\ninstall.packages(\"janitor\")\ninstall.packages(\"here\")\ninstall.packages(\"readr\")\ninstall.packages(\"readxl\")\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)"
  },
  {
    "objectID": "tools-loading-data.html",
    "href": "tools-loading-data.html",
    "title": "Loading data",
    "section": "",
    "text": "In this part of Session 1, we will learn how to load external data into R.\nMany R packages come with data bundled into them. These datasets are available for use as soon as the package is loaded.\nHowever, we often need to load external data that we’ve generated in our lab or in a clinical study, a situation addressed in this lesson.\n\n\n\n\n\n\nFormatting data for use in R\n\n\n\nIf you are creating your own datasets for future analysis in R, or advising someone else about how best to do so, here are some tips:\n\nOne row per patient/subject\nColumn with a unique identifier for each subject (i.e. a patient ID)\n\nOR, if you have longitudinal or other repeated measures data, have another column identifying the repeat instance and then there can be multiple rows per patient for each repeat instance\n\nOne row of column labels (i.e. avoid a second row of headers where some cells are merged, etc)\nOne measurement with one column name in each column (i.e. avoid separating multiple pieces of data by commas, semicolons, etc within a cell)\nSimple variable names for each column - avoid long names and special characters\n\n\n\n\n\nThe dataset used in this course is stored in this folder. We need to download it from GitHub onto our personal computers.\n\nNavigate to the above location and left click on breastcancer.xlsx.\nFor a .xlsx file like this, you won’t see a preview of the data. Now right click on “Raw” and then select “Save link as…”\n\n\n\n\n\nNavigate to the “mmedr” folder we created earlier on your home directory, and save the file there as “breastcancer.xlsx”.\n\n\n\n\nThe most common data format we work with are data from Excel. We will learn three ways to load Excel datasets into R, and then will introduce some options for alternative file types.\nWe will look at options to:\n\nRead in Excel files with {readxl}\nRead in Excel files by converting to .csv first\nRead in Excel files by converting to .csv first and using the {readr} package\n\n\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readxl\") # Already installed on Posit Workbench\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\"~/folder/filename.xlsx\")\n\n\n\n\n\n\n\nTip\n\n\n\nR treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\n\n\n\n\n\n\n\n\nTip\n\n\n\nOn the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\n\n\n\n\n\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and navigate to the folder where you want to save the data, if you are not already there\nSelect “CSV (Comma delimited)” from the “Save as type” drop down and save the file with the desired name\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- read.csv(\"~/folder/filename.csv\") \n\n\n\n\nUsing the same approach as above to first save the Excel file into .csv format, we can alternatively use the read_csv() function from the {readr} package to read in the data, instead of read.csv().\nFirst, install the {readr} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readr\") # Already installed on Posit Workbench\nlibrary(readr)\n\nThen read in the data using the reade_csv() function with the appropriate filepath and create and object called “mycsv2”\n\nmycsv2 &lt;- read_csv(\"~/folder/filename.csv\") \n\n\n\n\n\n\n\nTip\n\n\n\nThe read.csv() function reads a file into a data.frame object whereas the read_csv() function reads a file into a tibble object.\nThe tibble objects have some advantages over data.frame objects such as faster loading and ability to handle non-standard column names.\nNote that the third approach is the one I use, and will form the basis of my examples in the rest of this course.\n\n\n\n\n\n\nMany other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places\n\n\n\n\n\n\n\n\n\n\nR is case sensitive\n\n\n\n\ni.e. age is not the same as Age.\n\n\n\n\nVariable names with spaces and special characters can be problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in all code using backticks: `Patient Age`\nOne alternative is to use the clean_names() function from the {janitor} package to convert all variable names to a standard format, such as snake case\n\n\nFirst, install the {janitor} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"janitor\") # Already installed on Posit Workbench\nlibrary(janitor)\n\nThen use the clean_names() function to convert all variable names to snake case (default):\n\nmycsv2 &lt;- clean_names(mycsv2)\n\n\n\n\n\n\n\nSession 1, Exercise 3\n\n\n\n\n\n\nSave the “breastcancer.xlsx” file to .csv format\nUse the third method presented in this section to load the breastcancer data using the read_csv() function from the {readr} package, to an object called “df”\nRun names(df) to see the original variable names\nUse the clean_names() function from the janitor package to convert the column names to snake case\nAgain run names(df) to see the original variable names\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 3 Solution\n\n\n\n\n\nGo to File &gt; Save as. Navigate to the “mmedr” folder on your home directory. Select “CSV” from the drop down. Save as “breastcancer.csv”\n\n\n\nThen read the data into R:\n\nlibrary(readr)\ndf &lt;- read_csv(\"~/mmedr/breastcancer.csv\")\n\n\n\nRows: 3000 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (13): Time, Event, RT, Age at diagnosis (years), Tumo size (cm), Grade -...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou will see that you get a message printed out with some details about the file you read in.\nLet’s look at the names when we first read it in the data, using the names() function:\n\nnames(df)\n\n [1] \"Time\"                      \"Event\"                    \n [3] \"RT\"                        \"Age at diagnosis (years)\" \n [5] \"Tumo size (cm)\"            \"Grade - 3 vs 1 or 2\"      \n [7] \"N LN pos - 3 vs 1 or 2\"    \"Nodal ratio\"              \n [9] \"LVI\"                       \"ER or PR pos\"             \n[11] \"HER2 pos\"                  \"Quadrant - inner vs other\"\n[13] \"Optimal systemic therapy\" \n\n\nWe see these names contain a mix of uppercase and lowercase, spaces, and special characters. They would be hard to work with in R code.\nNow standardize the names:\n\nlibrary(janitor)\ndf &lt;- clean_names(df)\n\nAnd look again at the variable names:\n\nnames(df)\n\n [1] \"time\"                     \"event\"                   \n [3] \"rt\"                       \"age_at_diagnosis_years\"  \n [5] \"tumo_size_cm\"             \"grade_3_vs_1_or_2\"       \n [7] \"n_ln_pos_3_vs_1_or_2\"     \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_other\" \n[13] \"optimal_systemic_therapy\"\n\n\nNow we see that the variable names are all lowercase, with “_” (underscore) in place of any spaces and special characters have been removed."
  },
  {
    "objectID": "tools-loading-data.html#dataset-for-use-in-this-class",
    "href": "tools-loading-data.html#dataset-for-use-in-this-class",
    "title": "Loading data",
    "section": "",
    "text": "The dataset used in this course is stored in this folder. We need to download it from GitHub onto our personal computers.\n\nNavigate to the above location and left click on breastcancer.xlsx.\nFor a .xlsx file like this, you won’t see a preview of the data. Now right click on “Raw” and then select “Save link as…”\n\n\n\n\n\nNavigate to the “mmedr” folder we created earlier on your home directory, and save the file there as “breastcancer.xlsx”."
  },
  {
    "objectID": "tools-loading-data.html#loading-excel-data",
    "href": "tools-loading-data.html#loading-excel-data",
    "title": "Loading data",
    "section": "",
    "text": "The most common data format we work with are data from Excel. We will learn three ways to load Excel datasets into R, and then will introduce some options for alternative file types.\nWe will look at options to:\n\nRead in Excel files with {readxl}\nRead in Excel files by converting to .csv first\nRead in Excel files by converting to .csv first and using the {readr} package\n\n\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readxl\") # Already installed on Posit Workbench\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\"~/folder/filename.xlsx\")\n\n\n\n\n\n\n\nTip\n\n\n\nR treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\n\n\n\n\n\n\n\n\nTip\n\n\n\nOn the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\n\n\n\n\n\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and navigate to the folder where you want to save the data, if you are not already there\nSelect “CSV (Comma delimited)” from the “Save as type” drop down and save the file with the desired name\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- read.csv(\"~/folder/filename.csv\") \n\n\n\n\nUsing the same approach as above to first save the Excel file into .csv format, we can alternatively use the read_csv() function from the {readr} package to read in the data, instead of read.csv().\nFirst, install the {readr} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readr\") # Already installed on Posit Workbench\nlibrary(readr)\n\nThen read in the data using the reade_csv() function with the appropriate filepath and create and object called “mycsv2”\n\nmycsv2 &lt;- read_csv(\"~/folder/filename.csv\") \n\n\n\n\n\n\n\nTip\n\n\n\nThe read.csv() function reads a file into a data.frame object whereas the read_csv() function reads a file into a tibble object.\nThe tibble objects have some advantages over data.frame objects such as faster loading and ability to handle non-standard column names.\nNote that the third approach is the one I use, and will form the basis of my examples in the rest of this course."
  },
  {
    "objectID": "tools-loading-data.html#loading-other-file-formats",
    "href": "tools-loading-data.html#loading-other-file-formats",
    "title": "Loading data",
    "section": "",
    "text": "Many other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places"
  },
  {
    "objectID": "tools-loading-data.html#variable-names-with-the-janitor-package",
    "href": "tools-loading-data.html#variable-names-with-the-janitor-package",
    "title": "Loading data",
    "section": "",
    "text": "R is case sensitive\n\n\n\n\ni.e. age is not the same as Age.\n\n\n\n\nVariable names with spaces and special characters can be problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in all code using backticks: `Patient Age`\nOne alternative is to use the clean_names() function from the {janitor} package to convert all variable names to a standard format, such as snake case\n\n\nFirst, install the {janitor} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"janitor\") # Already installed on Posit Workbench\nlibrary(janitor)\n\nThen use the clean_names() function to convert all variable names to snake case (default):\n\nmycsv2 &lt;- clean_names(mycsv2)\n\n\n\n\n\n\n\nSession 1, Exercise 3\n\n\n\n\n\n\nSave the “breastcancer.xlsx” file to .csv format\nUse the third method presented in this section to load the breastcancer data using the read_csv() function from the {readr} package, to an object called “df”\nRun names(df) to see the original variable names\nUse the clean_names() function from the janitor package to convert the column names to snake case\nAgain run names(df) to see the original variable names\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 3 Solution\n\n\n\n\n\nGo to File &gt; Save as. Navigate to the “mmedr” folder on your home directory. Select “CSV” from the drop down. Save as “breastcancer.csv”\n\n\n\nThen read the data into R:\n\nlibrary(readr)\ndf &lt;- read_csv(\"~/mmedr/breastcancer.csv\")\n\n\n\nRows: 3000 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (13): Time, Event, RT, Age at diagnosis (years), Tumo size (cm), Grade -...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou will see that you get a message printed out with some details about the file you read in.\nLet’s look at the names when we first read it in the data, using the names() function:\n\nnames(df)\n\n [1] \"Time\"                      \"Event\"                    \n [3] \"RT\"                        \"Age at diagnosis (years)\" \n [5] \"Tumo size (cm)\"            \"Grade - 3 vs 1 or 2\"      \n [7] \"N LN pos - 3 vs 1 or 2\"    \"Nodal ratio\"              \n [9] \"LVI\"                       \"ER or PR pos\"             \n[11] \"HER2 pos\"                  \"Quadrant - inner vs other\"\n[13] \"Optimal systemic therapy\" \n\n\nWe see these names contain a mix of uppercase and lowercase, spaces, and special characters. They would be hard to work with in R code.\nNow standardize the names:\n\nlibrary(janitor)\ndf &lt;- clean_names(df)\n\nAnd look again at the variable names:\n\nnames(df)\n\n [1] \"time\"                     \"event\"                   \n [3] \"rt\"                       \"age_at_diagnosis_years\"  \n [5] \"tumo_size_cm\"             \"grade_3_vs_1_or_2\"       \n [7] \"n_ln_pos_3_vs_1_or_2\"     \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_other\" \n[13] \"optimal_systemic_therapy\"\n\n\nNow we see that the variable names are all lowercase, with “_” (underscore) in place of any spaces and special characters have been removed."
  }
]