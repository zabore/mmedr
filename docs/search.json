[
  {
    "objectID": "tools-review-practice.html",
    "href": "tools-review-practice.html",
    "title": "Review and practice",
    "section": "",
    "text": "This session will be an interactive practice session, giving you a chance to review what we have learned this week and ask questions as needed.\nLet’s pretend we are working on a project with our principal investigator, Carolyn Ball, and another project staff in the lab Alexandra Davies. The project is to describe characteristics of a population of patients with breast cancer.\n\n\n\nCreate a new project folder inside the “mmedr” folder we’ve been using for this class so far. Give it a descriptive name related to the project at hand.\nInside the project folder, create a sub-folder called “data” and copy the breastcancer.csv data file there.\nCreate an RStudio project inside the project folder, and open it.\nOpen a new R script inside the Rstudio project, and save it to the project folder with a descriptive name\n\n\n\n\n\n\n\nNote\n\n\n\nThis part of the practice session reviews topics covered in Reproducibility, including RStudio projects and a project oriented workflow.\n\n\n\n\n\n\nLoad (after installing, if needed) the readr, here, janitor, and dplyr packages in your newly saved R script\nRead in the datafile breastcancer.csv to an object\nStandardize the column names of the breastcancer data\n\n\n\n\n\n\n\nNote\n\n\n\nThis part of the practice session reviews topics covered in Installing and loading R packages, Loading data, and Reproducibility.\n\n\n\n\n\n\nCreate a new variable dichotomizing age_dx_yrs at 60 (i.e. a group for &lt;=60 and a group for &gt;60)\nCreate a new variable called “triple_negative” that is 1 if both er_or_pr_pos is 0 and her_pos is 0, and 0 otherwise. Please use caution here because there are some missing values in both of the variables that go into this calculation, so you need to think about how they should be handled\nLimit the dataset to patients who received optimal systemic therapy (i.e. optimal_systemic_therapy is 1)\nOnly keep the variable rt, and the two new variables you created above (whatever you called them) in the dataset\n\n\n\n\n\n\n\nNote\n\n\n\nThis part of the practice session reviews topics covered in Manipulate dataframes\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFor an extra challenge, try to string all of the above steps together in a single step using the pipe operator"
  },
  {
    "objectID": "tools-review-practice.html#part-1",
    "href": "tools-review-practice.html#part-1",
    "title": "Review and practice",
    "section": "",
    "text": "Create a new project folder inside the “mmedr” folder we’ve been using for this class so far. Give it a descriptive name related to the project at hand.\nInside the project folder, create a sub-folder called “data” and copy the breastcancer.csv data file there.\nCreate an RStudio project inside the project folder, and open it.\nOpen a new R script inside the Rstudio project, and save it to the project folder with a descriptive name\n\n\n\n\n\n\n\nNote\n\n\n\nThis part of the practice session reviews topics covered in Reproducibility, including RStudio projects and a project oriented workflow."
  },
  {
    "objectID": "tools-review-practice.html#part-2",
    "href": "tools-review-practice.html#part-2",
    "title": "Review and practice",
    "section": "",
    "text": "Load (after installing, if needed) the readr, here, janitor, and dplyr packages in your newly saved R script\nRead in the datafile breastcancer.csv to an object\nStandardize the column names of the breastcancer data\n\n\n\n\n\n\n\nNote\n\n\n\nThis part of the practice session reviews topics covered in Installing and loading R packages, Loading data, and Reproducibility."
  },
  {
    "objectID": "tools-review-practice.html#part-3",
    "href": "tools-review-practice.html#part-3",
    "title": "Review and practice",
    "section": "",
    "text": "Create a new variable dichotomizing age_dx_yrs at 60 (i.e. a group for &lt;=60 and a group for &gt;60)\nCreate a new variable called “triple_negative” that is 1 if both er_or_pr_pos is 0 and her_pos is 0, and 0 otherwise. Please use caution here because there are some missing values in both of the variables that go into this calculation, so you need to think about how they should be handled\nLimit the dataset to patients who received optimal systemic therapy (i.e. optimal_systemic_therapy is 1)\nOnly keep the variable rt, and the two new variables you created above (whatever you called them) in the dataset\n\n\n\n\n\n\n\nNote\n\n\n\nThis part of the practice session reviews topics covered in Manipulate dataframes\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFor an extra challenge, try to string all of the above steps together in a single step using the pipe operator"
  },
  {
    "objectID": "tools-manipulate-dataframes.html",
    "href": "tools-manipulate-dataframes.html",
    "title": "Manipulate dataframes",
    "section": "",
    "text": "In this session we will delve further into the topic of manipulating dataframes. The dataframe is the most common format of data with which most of us will work, with data arranged in a 2-dimensional format of rows and columns that can be displayed as a table. We were introduced to some basics of dataframe manipulation in the basic programming session, such as subsetting.\n\n\nAll of the manipulations you may want to do with a dataframe are possible with base R, but there are some packages that can make dataframe manipulation easier while also making our code more readable.\nThe {dplyr} package is a package specifically designed for data manipulation, and we will focus on learning functions from this and other related packages in this course.\nLet’s take a look at a few things we learned at the end of the basic programming session, and see how we could do things differently using the {dplyr} package.\nFirst, read in the breastcancer data for use in this session, and use the clean_names() function from the {janitor} package to standardize the column names to snake case.\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\nIn the basic progamming session we learned how to subset dataframes using single brackets ([]), and to subset by either rows or columns.\nRecall that we can create a subset of our data based on the values in a row, such as limiting to patients who were treated with radiation therapy (i.e. rt value of 1):\n\ndf_sub &lt;- df[df$rt == 1, ]\n\nOr we can create a subset of our data based on columns, for example limiting to only the column containing age at diagnosis:\n\ndf_sub &lt;- df[ , c(\"age_dx_yrs\")]\n\nUsing the {dplyr} package, we can similarly subset based on rows using the filter() function and based on columns using the select() function.\nFirst, install (if needed) and load the {dplyr} package:\n\ninstall.packages(\"dplyr\") # Already installed on Posit Workbench\n\n\nlibrary(dplyr)\n\nWe can similarly create a subset of the rows of patients who were treated with radiation therapy as:\n\ndf_sub &lt;-\n  df |&gt; \n  filter(rt == 1)\n\nAnd we can similarly create a subset of the column of age at diagnosis as:\n\ndf_sub &lt;-\n  df |&gt; \n  select(age_dx_yrs)\n\nRecall that the pipe operator passes what is on the LHS as the first argument to the function on the RHS. So the first argument to the select() function should be a dataframe, and we are passing our dataframe “df” to it.\nYou’ll notice that functions from the {dplyr} package work naturally with the pipe operator (|&gt;). Using the pipe operator, it is also natural to program vertically rather than horizontally, making the code more readable.\n\n\n\nSometimes we may wish to rename a column in a dataframe. Perhaps the name from the original data file was too long or cumbersome, or not descriptive enough.\nFor example, perhaps the variable name “event” in our breastcancer data is not descriptive enough, and we would like to rename it as “recurrence” to indicate that the event it contains information about is a disease recurrence.\nWe can use the rename() function from the {dplyr} package to do this.\n\ndf_new &lt;- \n  df |&gt; \n  rename(recurrence = event)\n\nThe rename function takes the form rename(new_name = old_name) where old_name is the current name of the column in the data frame and new_name is the desired name of the column in the data frame.\nWe can make sure this worked as expected by checking the names of our new dataframe df_new using the names() function, and we see that the second column is now named “recurrence” instead of “event”:\n\nnames(df_new)\n\n [1] \"time\"                     \"recurrence\"              \n [3] \"rt\"                       \"age_dx_yrs\"              \n [5] \"tumor_size_cm\"            \"grade\"                   \n [7] \"n_ln_pos_3_vs_1or2\"       \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_upper\" \n[13] \"optimal_systemic_therapy\"\n\n\nWe can also rename multiple columns at once, separated by commas:\n\ndf_new &lt;- \n  df |&gt; \n  rename(recurrence = event, grade_categories = grade)\n\nnames(df_new)\n\n [1] \"time\"                     \"recurrence\"              \n [3] \"rt\"                       \"age_dx_yrs\"              \n [5] \"tumor_size_cm\"            \"grade_categories\"        \n [7] \"n_ln_pos_3_vs_1or2\"       \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_upper\" \n[13] \"optimal_systemic_therapy\"\n\n\n\n\n\nSometimes we will want to add columns to our dataframe. Typically we’ll want to do this because we are calculating something new based on an existing variable in our dataframe.\nFor example, we may be interested in the log of nodal ratio in our breastcancer data, since we know that nodal ratio is not a normally distributed variable.\nWe can add a new calculated column to a dataframe using the mutate() function from the {dplyr} package:\n\ndf_new &lt;-\n  df |&gt; \n  mutate(\n    log_nodal_ratio = log(nodal_ratio)\n  )\n\nThe first argument to mutate() is the name of the dataframe, which comes from the LHS of the previous pipe (i.e. “df”). The second argument contains the name of the new variable, then an equal sign (“=”), then the value to be assigned to the new variable. In this case the value we are assigning to the new variable “log_nodal_ratio” is the natural log (log()) of the current column “nodal_ratio”.\nNow we can see the first few values of these two columns as:\n\ndf_new |&gt; \n  select(nodal_ratio, log_nodal_ratio)\n\n# A tibble: 3,000 × 2\n   nodal_ratio log_nodal_ratio\n         &lt;dbl&gt;           &lt;dbl&gt;\n 1       0.159          -1.84 \n 2       0.157          -1.85 \n 3       0.190          -1.66 \n 4       0.377          -0.975\n 5       0.608          -0.498\n 6       0.291          -1.23 \n 7       0.497          -0.698\n 8       0.466          -0.764\n 9       0.209          -1.56 \n10       0.423          -0.859\n# ℹ 2,990 more rows\n\n\nWe can also add multiple new columns, separated by commas, for example the log of nodal_ratio and also the square of tumor_size_cm:\n\ndf_new &lt;-\n  df |&gt; \n  mutate(\n    log_nodal_ratio = log(nodal_ratio),\n    tumor_size_cm_squared = tumor_size_cm^2\n  )\n\ndf_new |&gt; \n  select(nodal_ratio, log_nodal_ratio, tumor_size_cm, tumor_size_cm_squared)\n\n# A tibble: 3,000 × 4\n   nodal_ratio log_nodal_ratio tumor_size_cm tumor_size_cm_squared\n         &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;                 &lt;dbl&gt;\n 1       0.159          -1.84          3.57                 12.7  \n 2       0.157          -1.85          1.43                  2.05 \n 3       0.190          -1.66         NA                    NA    \n 4       0.377          -0.975         3.49                 12.2  \n 5       0.608          -0.498         1.97                  3.89 \n 6       0.291          -1.23          0.696                 0.484\n 7       0.497          -0.698         2.93                  8.56 \n 8       0.466          -0.764         1.10                  1.22 \n 9       0.209          -1.56          1.25                  1.55 \n10       0.423          -0.859         3.12                  9.73 \n# ℹ 2,990 more rows\n\n\n\n\n\n\n\n\nSession 3, Exercise 1\n\n\n\n\n\n\nOpen your mmedr R project\nLoad the breastcancer data using the {readr} and {here} packages, and use the clean_names() function from the {janitor} package to standardize the names\nCreate a new variable called “rt_optimal” that is 1 if the patient received both rt (1) and optimal_systemic_therapy (1), 2 if the patient received rt (1) and did not receive optimal_systemic_therapy (0), 3 if the patient did not recieve rt (0) and received optimal_systemic_therapy (1), and 4 if the patient did not receive rt (0) and did not receive optimal_systemic_therapy, using the case_when() function from the {dplyr} package\nRename the variable “rt” as “radiation_therapy” using the rename() function from the {dplyr} package\n\n\n\n\n\n\n\n\n\n\nSession 3, Exercise 1 Solution\n\n\n\n\n\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\nlibrary(dplyr)\n\n\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\n\ndf2 &lt;- \n  df |&gt; \n  mutate(\n    rt_optimal = case_when(\n      rt == 1 & optimal_systemic_therapy == 1 ~ 1,\n      rt == 1 & optimal_systemic_therapy == 0 ~ 2,\n      rt == 0 & optimal_systemic_therapy == 1 ~ 3,\n      rt == 0 & optimal_systemic_therapy == 0 ~ 4\n    )\n  ) |&gt; \n  rename(radiation_therapy = rt)\n\n\n\n\n\n\n\nWe just saw how to add a new column by performing a simple mathematical function on an existing column, but we can also use the mutate() function to add a new variable that categorizes a continuous variable by combining it with the case_when() function.\nLet’s say, for example, that we want to add a new variable for age categories, called age_cat to our data, which categorizes age as &lt;50 versus 50-65 versus &gt;=65.\nWe can do this by:\n\ndf_new &lt;-\n  df |&gt; \n  mutate(\n    age_cat = case_when(\n      age_dx_yrs &lt; 50 ~ \"&lt;50\",\n      age_dx_yrs &gt;= 50 & age_dx_yrs &lt;= 65 ~ \"50-65\",\n      age_dx_yrs &gt; 65 ~ \"&gt;65\"\n    )\n  )\n\nInside the function case_when() we have a sequence of two-sided formulas, where the LHS determines which values of the existing variable (in this case “age_dx_yrs”) match the case, and the RHS provides the replacement value for the new variable (in this case “age_cat”). The two sides of the formula are separated by the “~” symbol.\nWe can see the result of this new categorical age variable by passing it to the table() function:\n\ntable(df_new$age_cat)\n\n\n  &lt;50   &gt;65 50-65 \n  891   873  1236 \n\n\n\n\n\nSimilarly, we can use the mutate() function together with case_when() to recategorize an already categorical variable. Say we want to combine grades I and II to compare against grade III from the existing variable “grade”:\n\ndf_new &lt;- \n  df |&gt; \n  mutate(\n    grade_bin = case_when(\n      grade %in% c(\"I\", \"II\") ~ \"I/II\",\n      grade == \"III\" ~ \"III\"\n    )\n  )\n\ntable(df_new$grade_bin)\n\n\nI/II  III \n1672 1328 \n\n\n\n\n\n\n\n\nTip\n\n\n\nThe “%in%” operator is used to test for “vector membership”, meaning whether the value on the LHS is a member of anything in the vector on the RHS.\n\n\n\n\n\n\n\n\nSession 3, Exercise 2\n\n\n\n\n\nIn the breastcancer data we already loaded, group tumor_size_cm into three groups: &lt;=1.5, &gt;1.5 and &lt;=3, &gt;3, in a new variable named “tumor_size_cat”.\n\n\n\n\n\n\n\n\n\nSession 3, Exercise 2 Solution\n\n\n\n\n\n\ndf3 &lt;- \n  df |&gt; \n  mutate(\n    tumor_size_cat = case_when(\n      tumor_size_cm &lt;= 1.5 ~ \"&lt;=1.5cm\",\n      tumor_size_cm &gt; 1.5 & tumor_size_cm &lt;= 3 ~ \"&gt;1.5cm and &lt;=3cm\",\n      tumor_size_cm &gt; 3 ~ \"&gt;3cm\"\n    )\n  )\n\n\n\n\n\n\n\nThere may be times when we want to sort our dataframe according to a value in a row. For example, maybe we want to sort our dataframe from youngest to oldest age. We can do this using the arrange() function from the {dplyr} package:\n\ndf_new &lt;-\n  df |&gt; \n  arrange(age_dx_yrs)\n\ndf_new |&gt; \n  select(age_dx_yrs)\n\n# A tibble: 3,000 × 1\n   age_dx_yrs\n        &lt;dbl&gt;\n 1       18.2\n 2       19.6\n 3       19.9\n 4       20.1\n 5       21.0\n 6       21.3\n 7       21.3\n 8       22.0\n 9       22.1\n10       22.3\n# ℹ 2,990 more rows\n\n\nAnd we can see that the dataframe is now arranged from youngest to oldest age at diagnosis.\nWe can also sort by multiple variables, separated by commas. For example, maybe we want to sort by age at diagnosis within levels of radiation therapy:\n\ndf_new &lt;-\n  df |&gt; \n  arrange(rt, age_dx_yrs)"
  },
  {
    "objectID": "tools-manipulate-dataframes.html#the-dplyr-package",
    "href": "tools-manipulate-dataframes.html#the-dplyr-package",
    "title": "Manipulate dataframes",
    "section": "",
    "text": "All of the manipulations you may want to do with a dataframe are possible with base R, but there are some packages that can make dataframe manipulation easier while also making our code more readable.\nThe {dplyr} package is a package specifically designed for data manipulation, and we will focus on learning functions from this and other related packages in this course.\nLet’s take a look at a few things we learned at the end of the basic programming session, and see how we could do things differently using the {dplyr} package.\nFirst, read in the breastcancer data for use in this session, and use the clean_names() function from the {janitor} package to standardize the column names to snake case.\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\nIn the basic progamming session we learned how to subset dataframes using single brackets ([]), and to subset by either rows or columns.\nRecall that we can create a subset of our data based on the values in a row, such as limiting to patients who were treated with radiation therapy (i.e. rt value of 1):\n\ndf_sub &lt;- df[df$rt == 1, ]\n\nOr we can create a subset of our data based on columns, for example limiting to only the column containing age at diagnosis:\n\ndf_sub &lt;- df[ , c(\"age_dx_yrs\")]\n\nUsing the {dplyr} package, we can similarly subset based on rows using the filter() function and based on columns using the select() function.\nFirst, install (if needed) and load the {dplyr} package:\n\ninstall.packages(\"dplyr\") # Already installed on Posit Workbench\n\n\nlibrary(dplyr)\n\nWe can similarly create a subset of the rows of patients who were treated with radiation therapy as:\n\ndf_sub &lt;-\n  df |&gt; \n  filter(rt == 1)\n\nAnd we can similarly create a subset of the column of age at diagnosis as:\n\ndf_sub &lt;-\n  df |&gt; \n  select(age_dx_yrs)\n\nRecall that the pipe operator passes what is on the LHS as the first argument to the function on the RHS. So the first argument to the select() function should be a dataframe, and we are passing our dataframe “df” to it.\nYou’ll notice that functions from the {dplyr} package work naturally with the pipe operator (|&gt;). Using the pipe operator, it is also natural to program vertically rather than horizontally, making the code more readable."
  },
  {
    "objectID": "tools-manipulate-dataframes.html#rename-columns",
    "href": "tools-manipulate-dataframes.html#rename-columns",
    "title": "Manipulate dataframes",
    "section": "",
    "text": "Sometimes we may wish to rename a column in a dataframe. Perhaps the name from the original data file was too long or cumbersome, or not descriptive enough.\nFor example, perhaps the variable name “event” in our breastcancer data is not descriptive enough, and we would like to rename it as “recurrence” to indicate that the event it contains information about is a disease recurrence.\nWe can use the rename() function from the {dplyr} package to do this.\n\ndf_new &lt;- \n  df |&gt; \n  rename(recurrence = event)\n\nThe rename function takes the form rename(new_name = old_name) where old_name is the current name of the column in the data frame and new_name is the desired name of the column in the data frame.\nWe can make sure this worked as expected by checking the names of our new dataframe df_new using the names() function, and we see that the second column is now named “recurrence” instead of “event”:\n\nnames(df_new)\n\n [1] \"time\"                     \"recurrence\"              \n [3] \"rt\"                       \"age_dx_yrs\"              \n [5] \"tumor_size_cm\"            \"grade\"                   \n [7] \"n_ln_pos_3_vs_1or2\"       \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_upper\" \n[13] \"optimal_systemic_therapy\"\n\n\nWe can also rename multiple columns at once, separated by commas:\n\ndf_new &lt;- \n  df |&gt; \n  rename(recurrence = event, grade_categories = grade)\n\nnames(df_new)\n\n [1] \"time\"                     \"recurrence\"              \n [3] \"rt\"                       \"age_dx_yrs\"              \n [5] \"tumor_size_cm\"            \"grade_categories\"        \n [7] \"n_ln_pos_3_vs_1or2\"       \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_upper\" \n[13] \"optimal_systemic_therapy\""
  },
  {
    "objectID": "tools-manipulate-dataframes.html#add-columns",
    "href": "tools-manipulate-dataframes.html#add-columns",
    "title": "Manipulate dataframes",
    "section": "",
    "text": "Sometimes we will want to add columns to our dataframe. Typically we’ll want to do this because we are calculating something new based on an existing variable in our dataframe.\nFor example, we may be interested in the log of nodal ratio in our breastcancer data, since we know that nodal ratio is not a normally distributed variable.\nWe can add a new calculated column to a dataframe using the mutate() function from the {dplyr} package:\n\ndf_new &lt;-\n  df |&gt; \n  mutate(\n    log_nodal_ratio = log(nodal_ratio)\n  )\n\nThe first argument to mutate() is the name of the dataframe, which comes from the LHS of the previous pipe (i.e. “df”). The second argument contains the name of the new variable, then an equal sign (“=”), then the value to be assigned to the new variable. In this case the value we are assigning to the new variable “log_nodal_ratio” is the natural log (log()) of the current column “nodal_ratio”.\nNow we can see the first few values of these two columns as:\n\ndf_new |&gt; \n  select(nodal_ratio, log_nodal_ratio)\n\n# A tibble: 3,000 × 2\n   nodal_ratio log_nodal_ratio\n         &lt;dbl&gt;           &lt;dbl&gt;\n 1       0.159          -1.84 \n 2       0.157          -1.85 \n 3       0.190          -1.66 \n 4       0.377          -0.975\n 5       0.608          -0.498\n 6       0.291          -1.23 \n 7       0.497          -0.698\n 8       0.466          -0.764\n 9       0.209          -1.56 \n10       0.423          -0.859\n# ℹ 2,990 more rows\n\n\nWe can also add multiple new columns, separated by commas, for example the log of nodal_ratio and also the square of tumor_size_cm:\n\ndf_new &lt;-\n  df |&gt; \n  mutate(\n    log_nodal_ratio = log(nodal_ratio),\n    tumor_size_cm_squared = tumor_size_cm^2\n  )\n\ndf_new |&gt; \n  select(nodal_ratio, log_nodal_ratio, tumor_size_cm, tumor_size_cm_squared)\n\n# A tibble: 3,000 × 4\n   nodal_ratio log_nodal_ratio tumor_size_cm tumor_size_cm_squared\n         &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;                 &lt;dbl&gt;\n 1       0.159          -1.84          3.57                 12.7  \n 2       0.157          -1.85          1.43                  2.05 \n 3       0.190          -1.66         NA                    NA    \n 4       0.377          -0.975         3.49                 12.2  \n 5       0.608          -0.498         1.97                  3.89 \n 6       0.291          -1.23          0.696                 0.484\n 7       0.497          -0.698         2.93                  8.56 \n 8       0.466          -0.764         1.10                  1.22 \n 9       0.209          -1.56          1.25                  1.55 \n10       0.423          -0.859         3.12                  9.73 \n# ℹ 2,990 more rows\n\n\n\n\n\n\n\n\nSession 3, Exercise 1\n\n\n\n\n\n\nOpen your mmedr R project\nLoad the breastcancer data using the {readr} and {here} packages, and use the clean_names() function from the {janitor} package to standardize the names\nCreate a new variable called “rt_optimal” that is 1 if the patient received both rt (1) and optimal_systemic_therapy (1), 2 if the patient received rt (1) and did not receive optimal_systemic_therapy (0), 3 if the patient did not recieve rt (0) and received optimal_systemic_therapy (1), and 4 if the patient did not receive rt (0) and did not receive optimal_systemic_therapy, using the case_when() function from the {dplyr} package\nRename the variable “rt” as “radiation_therapy” using the rename() function from the {dplyr} package\n\n\n\n\n\n\n\n\n\n\nSession 3, Exercise 1 Solution\n\n\n\n\n\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\nlibrary(dplyr)\n\n\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\n\ndf2 &lt;- \n  df |&gt; \n  mutate(\n    rt_optimal = case_when(\n      rt == 1 & optimal_systemic_therapy == 1 ~ 1,\n      rt == 1 & optimal_systemic_therapy == 0 ~ 2,\n      rt == 0 & optimal_systemic_therapy == 1 ~ 3,\n      rt == 0 & optimal_systemic_therapy == 0 ~ 4\n    )\n  ) |&gt; \n  rename(radiation_therapy = rt)"
  },
  {
    "objectID": "tools-manipulate-dataframes.html#group-a-continuous-variable",
    "href": "tools-manipulate-dataframes.html#group-a-continuous-variable",
    "title": "Manipulate dataframes",
    "section": "",
    "text": "We just saw how to add a new column by performing a simple mathematical function on an existing column, but we can also use the mutate() function to add a new variable that categorizes a continuous variable by combining it with the case_when() function.\nLet’s say, for example, that we want to add a new variable for age categories, called age_cat to our data, which categorizes age as &lt;50 versus 50-65 versus &gt;=65.\nWe can do this by:\n\ndf_new &lt;-\n  df |&gt; \n  mutate(\n    age_cat = case_when(\n      age_dx_yrs &lt; 50 ~ \"&lt;50\",\n      age_dx_yrs &gt;= 50 & age_dx_yrs &lt;= 65 ~ \"50-65\",\n      age_dx_yrs &gt; 65 ~ \"&gt;65\"\n    )\n  )\n\nInside the function case_when() we have a sequence of two-sided formulas, where the LHS determines which values of the existing variable (in this case “age_dx_yrs”) match the case, and the RHS provides the replacement value for the new variable (in this case “age_cat”). The two sides of the formula are separated by the “~” symbol.\nWe can see the result of this new categorical age variable by passing it to the table() function:\n\ntable(df_new$age_cat)\n\n\n  &lt;50   &gt;65 50-65 \n  891   873  1236"
  },
  {
    "objectID": "tools-manipulate-dataframes.html#recategorize-a-categorical-variable",
    "href": "tools-manipulate-dataframes.html#recategorize-a-categorical-variable",
    "title": "Manipulate dataframes",
    "section": "",
    "text": "Similarly, we can use the mutate() function together with case_when() to recategorize an already categorical variable. Say we want to combine grades I and II to compare against grade III from the existing variable “grade”:\n\ndf_new &lt;- \n  df |&gt; \n  mutate(\n    grade_bin = case_when(\n      grade %in% c(\"I\", \"II\") ~ \"I/II\",\n      grade == \"III\" ~ \"III\"\n    )\n  )\n\ntable(df_new$grade_bin)\n\n\nI/II  III \n1672 1328 \n\n\n\n\n\n\n\n\nTip\n\n\n\nThe “%in%” operator is used to test for “vector membership”, meaning whether the value on the LHS is a member of anything in the vector on the RHS.\n\n\n\n\n\n\n\n\nSession 3, Exercise 2\n\n\n\n\n\nIn the breastcancer data we already loaded, group tumor_size_cm into three groups: &lt;=1.5, &gt;1.5 and &lt;=3, &gt;3, in a new variable named “tumor_size_cat”.\n\n\n\n\n\n\n\n\n\nSession 3, Exercise 2 Solution\n\n\n\n\n\n\ndf3 &lt;- \n  df |&gt; \n  mutate(\n    tumor_size_cat = case_when(\n      tumor_size_cm &lt;= 1.5 ~ \"&lt;=1.5cm\",\n      tumor_size_cm &gt; 1.5 & tumor_size_cm &lt;= 3 ~ \"&gt;1.5cm and &lt;=3cm\",\n      tumor_size_cm &gt; 3 ~ \"&gt;3cm\"\n    )\n  )"
  },
  {
    "objectID": "tools-manipulate-dataframes.html#sort-by-row",
    "href": "tools-manipulate-dataframes.html#sort-by-row",
    "title": "Manipulate dataframes",
    "section": "",
    "text": "There may be times when we want to sort our dataframe according to a value in a row. For example, maybe we want to sort our dataframe from youngest to oldest age. We can do this using the arrange() function from the {dplyr} package:\n\ndf_new &lt;-\n  df |&gt; \n  arrange(age_dx_yrs)\n\ndf_new |&gt; \n  select(age_dx_yrs)\n\n# A tibble: 3,000 × 1\n   age_dx_yrs\n        &lt;dbl&gt;\n 1       18.2\n 2       19.6\n 3       19.9\n 4       20.1\n 5       21.0\n 6       21.3\n 7       21.3\n 8       22.0\n 9       22.1\n10       22.3\n# ℹ 2,990 more rows\n\n\nAnd we can see that the dataframe is now arranged from youngest to oldest age at diagnosis.\nWe can also sort by multiple variables, separated by commas. For example, maybe we want to sort by age at diagnosis within levels of radiation therapy:\n\ndf_new &lt;-\n  df |&gt; \n  arrange(rt, age_dx_yrs)"
  },
  {
    "objectID": "tools-introduction.html",
    "href": "tools-introduction.html",
    "title": "Introduction to the tools",
    "section": "",
    "text": "In the first part of Session 1, we will introduce the tools used in this course. We will primarily be working in Posit Workbench, but it is important to know how to install and use the tools on your own as well for future use.\n\n\n\n\n\n\nLearning to program\n\n\n\nIf this is your first time learning to program, you might find it overwhelming at first. That is okay, and to be expected. Programming is best learned by doing, doing repeatedly, and looking up how to do. Keep going, ask questions, and refer often to the resources provided in this course.\nStop and ask questions anytime! I am gearing this material to new learners of R but as an advanced user myself it is possible I can overlook something that I need to explain in more detail. Please stop me and ask if anything is unclear!\nSome of the topics covered here will be more or less useful to each of you, depending on the type of work you do and how much and what type of data are involved. But all of it will help you have a strong foundation even if the specific topics here are not directly applicable in your field.\n\n\nR and RStudio are two separate things, and to use both you will need to install two programs onto your personal computer.\n\n\n\n\n\n\nR is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\n\n\nInstalling R\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\nSelect the appropriate operating system\nWindows: Then click “base”, then click “Download R-x.y.z for Windows” where x.y.z corresponds to the current version of R, then double click the .exe file that downloads and follow the prompts. Mac: Then click the option corresponding to your Mac model, then double click the .pkg file that downloads and follow the prompts\n\n\n\n\n\n\n\n\n\n\nRStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\n\n\nInstalling RStudio\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download - double click on it and follow the prompts\n\n\n\n\n\n\n\n\n\n\nWe will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\n\n\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\n\nSelect “New Session”\n\n\n\n\n\nSelect “RStudio Pro” then click “Start Session”\n\n\n\n\n\nYou will have some version of the below appear. Note that it will not be identical to this as I have changed many options over time for my personal preferences.\n\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout. I can help you customize as well if there are things you prefer, just ask!\n\n\n\nType “putty” into the search bar on your computer and open the PuTTY application\nType “lri-r00.lerner.ccf.org” in the Host Name field. The rest of the defaults should be okay.\n\n\n\n\n\nClick “Open”.\nAt the prompt that says “login as:” type your username and hit Enter\nType your current password and hit Enter\nType “yppasswd” and hit Enter\nFollow the prompts, which will ask you for:\n\nYour old password\nYour new password\nYour new password again to confirm\n\n\n\n\n\n\n\n\n\nRstudio panes:\n\nText editor (i.e. R script) - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will display\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\nUsing the text editor in RStudio:\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R Script\nTo save the file go to: File &gt; Save\n\n\n\nTo send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight multiple lines of code and use one of the previous options\n\n\n\n\n\n\n\nSession 1, Exercise 1\n\n\n\n\n\n\nLogin to Posit Workbench and start a new RStudio session.\nGo to File &gt; New File &gt; R Script to open a new, blank R script\nSave the file to a new folder on your home directory called “mmedr” with the name “session1-exercises.R”\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 1 Solution"
  },
  {
    "objectID": "tools-introduction.html#r",
    "href": "tools-introduction.html#r",
    "title": "Introduction to the tools",
    "section": "",
    "text": "R is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\n\n\nInstalling R\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\nSelect the appropriate operating system\nWindows: Then click “base”, then click “Download R-x.y.z for Windows” where x.y.z corresponds to the current version of R, then double click the .exe file that downloads and follow the prompts. Mac: Then click the option corresponding to your Mac model, then double click the .pkg file that downloads and follow the prompts"
  },
  {
    "objectID": "tools-introduction.html#rstudio",
    "href": "tools-introduction.html#rstudio",
    "title": "Introduction to the tools",
    "section": "",
    "text": "RStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\n\n\nInstalling RStudio\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download - double click on it and follow the prompts"
  },
  {
    "objectID": "tools-introduction.html#posit-workbench",
    "href": "tools-introduction.html#posit-workbench",
    "title": "Introduction to the tools",
    "section": "",
    "text": "We will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\n\n\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\n\nSelect “New Session”\n\n\n\n\n\nSelect “RStudio Pro” then click “Start Session”\n\n\n\n\n\nYou will have some version of the below appear. Note that it will not be identical to this as I have changed many options over time for my personal preferences.\n\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout. I can help you customize as well if there are things you prefer, just ask!\n\n\n\nType “putty” into the search bar on your computer and open the PuTTY application\nType “lri-r00.lerner.ccf.org” in the Host Name field. The rest of the defaults should be okay.\n\n\n\n\n\nClick “Open”.\nAt the prompt that says “login as:” type your username and hit Enter\nType your current password and hit Enter\nType “yppasswd” and hit Enter\nFollow the prompts, which will ask you for:\n\nYour old password\nYour new password\nYour new password again to confirm"
  },
  {
    "objectID": "tools-introduction.html#using-rstudio",
    "href": "tools-introduction.html#using-rstudio",
    "title": "Introduction to the tools",
    "section": "",
    "text": "Rstudio panes:\n\nText editor (i.e. R script) - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will display\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\nUsing the text editor in RStudio:\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R Script\nTo save the file go to: File &gt; Save\n\n\n\nTo send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight multiple lines of code and use one of the previous options\n\n\n\n\n\n\n\nSession 1, Exercise 1\n\n\n\n\n\n\nLogin to Posit Workbench and start a new RStudio session.\nGo to File &gt; New File &gt; R Script to open a new, blank R script\nSave the file to a new folder on your home directory called “mmedr” with the name “session1-exercises.R”\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 1 Solution"
  },
  {
    "objectID": "tools-basic-programming.html",
    "href": "tools-basic-programming.html",
    "title": "Basic programming",
    "section": "",
    "text": "In this session, we will learn the basics of programming in R. This will lay the foundation for more advanced topics to come.\n\n\nUse the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns the value on the right, to the object on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\nOnce the object is assigned, the assignment step will be evaluated but it will not print to the console\nPrint to the console by typing the object name alone\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nTo assign a character variable, wrap it in single or double quotes:\n\ny &lt;- \"cat\"\ny\n\n[1] \"cat\"\n\n\n\n\n\n\n\n\nSession 2, Exercise 1\n\n\n\n\n\n\nOpen RStudio Pro on Posit Workbench\nCreate a new R script named “session2-exercises” and save it to the “mmedr” folder on your home directory that was created in Session 1\nCreate an object called “age” and assign it the numeric value of your age\nCreate an object called “name” and assign it the character value of your first name\nExecute the code\nPrint the object assignments to the console\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 1 Solution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\na\n\n[1] 1 2 3 4\n\nb &lt;- seq(from = 0, to = 100, by = 10)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nSo the following produce the same results:\n\nb &lt;- seq(from = 0, to = 100, by = 10)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\nb &lt;- seq(0, 100, 10)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\nb &lt;- seq(by = 10, to = 100, from = 0)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\n\n\n\n\nGet help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n?mean\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the help file, it can be particularly useful to scroll to the bottom and read and try the exercises.\n\n\n\n\n\n\n\n\nSession 2, Exercise 2\n\n\n\n\n\n\nLook up the help file for the “log” function\nCalculate the natural log of 1\nCalculate log base 10 of 5\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 2 Solution\n\n\n\n\n\n\n#1. \n?log\n\n\n#2. \nlog(1)\n\n[1] 0\n\n#3.\nlog10(5)\n\n[1] 0.69897\n\n# OR #\nlog(5, base = 10)\n\n[1] 0.69897\n\n# OR #\nlog(base = 10, x = 5)\n\n[1] 0.69897\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can write comments in your R code by starting a line with “#”. It is recommended to write a lot of verbal comments about what your R code is doing so that if you need to come back to it later, you will know what it was doing and why.\nFor example:\n\n# This R code file will demonstrate how to assign a value (on the right) to an object (on the left) using the \"&lt;-\" operator\n\n# Assign the numeric value 5 to the object x\nx &lt;- 5\n\n# Assign the character value a to the object y\ny &lt;- \"a\"\n\n\n\n\n\n\nBefore we go on, we need to learn about the pipe operator.\nWe will use the pipe operator to string multiple functions together seamlessly.\nThere are two forms of the pipe operator in R:\n\nThe “native” pipe operator “|&gt;”\nThe pipe operator from the {magrittr} package “%&gt;%”\n\nThey perform (almost) identically, but one is built in to base R and the other requires you to load a package.\nGo to Tools &gt; Global Options &gt; Code &gt; Editing and tick the box for “Use native pipe operator” to enable this in RStudio.\n\n\n\nYou can insert the pipe operator through the keyboard shortcut ctrl + shift + m.\nFor example, if we want generate 100 random numbers from the exponential distribution, take the log transformation, and then get the mean, we could nest the functions as follows:\n\nset.seed(123) # needed to make random number generation reproducible\nmean(log(rexp(100)))\n\n[1] -0.4802932\n\n\nOr we can connect them with the pipe operator:\n\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  log() |&gt; \n  mean()\n\n[1] -0.4802932\n\n\nThe value on the left hand side of the pipe operator is passed as the first argument to the function on the right hand side of the pipe operator.\nThis creates code that is very readable and concise, especially if you arrange your code vertically rather than horizontally.\nIt is also easy to comment out various parts if needed.\n\n# Horizontal pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt; rexp() |&gt;  log() |&gt;  mean()\n\n[1] -0.4802932\n\n\nWhat if I quickly want to see what the results would look like without the log transformation, but I don’t want to permanently delete that part of the code?\nI can comment that part out, and in the vertical setup this is easy:\n\n# Vertical pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  # log() |&gt; \n  mean()\n\n[1] 1.045719\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe keyboard shortcut ctrl + shift + c will insert a # (comment) at the beginning of the code line.\n\n\nWe’ll be using the pipe operator throughout the remaining R sessions in this course.\n\n\n\nThe == operator tests for equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nThis will be useful later when we subset data.\n\n\n\nR has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest.\nTo use best practices from last class, create an R project for use in this course. Create it in the existing “mmedr” folder on your home directory.\nLoad the “breastcancer” data that we saved as a .csv to the “mmedr” folder on our home drive last class, and assign it to the object “df”.\nClean the names using the {janitor} package.\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\nFor example, to calculate the mean of the variable age_dx_yrs in the dataframe df:\n\nmean(df$age_dx_yrs)\n\n[1] 57.2952\n\n\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(df[[\"age_dx_yrs\"]])\n\n[1] 57.2952\n\n\n\n\n\n\n\n\nSession 2, Exercise 3\n\n\n\n\n\nUse the table() function to create a table of the values in “grade” in the breastcancer data.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 3 Solution\n\n\n\n\n\n\ntable(df$grade)\n\n\n   I   II  III \n 362 1310 1328 \n\n\n\n\n\n\n\n\nSometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with radiation therapy (i.e. rt has the value 1):\n\ndf_sub &lt;- df[df$rt == 1, ]\nnrow(df_sub)\n\n[1] 1772\n\n\nWe see that the new data subset has 1772 rows instead of the 3000 in the original dataset.\nAnd now there are only values of 1 for the variable “rt”:\n\ntable(df_sub$rt)\n\n\n   1 \n1772 \n\n\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with radiation therapy AND had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 & df$grade == \"III\", ]\nnrow(df_sub)\n\n[1] 851\n\n\nAnd we see that the new data subset has 851 rows instead of the 3000 in the original dataset.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with radiation therapy OR had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 | df$grade == \"III\", ]\nnrow(df_sub)\n\n[1] 2249\n\n\nAnd we see that our new data subset has 2249 rows instead of the 3000 in the original dataset.\nWe can also create a subset of our data based on columns, for example limiting to radiation therapy:\n\ndf_sub &lt;- df[ , c(\"rt\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the radiation column among patients with grade 3 disease:\n\ndf_sub &lt;- df[df$grade == \"III\", c(\"rt\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age_dx_yrs in the dataframe df, but only among those who were treated with radiation therapy:\n\nmean(df$age_dx_yrs[df$rt == 1])\n\n[1] 55.08356\n\n\nThis avoids creating additional datasets that may not be needed again.\n\n\n\n\n\n\nSession 2, Exercise 4\n\n\n\n\n\nSay we are only interested in the affect of radiation therapy in older adults. Create a subset of the breastcancer data in patients &gt;=65 years old, and then look at a table of rt among the older subset.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 4 Solution\n\n\n\n\n\n\ndf_sub &lt;- df[df$age_dx_yrs &gt;= 65, ]\ntable(df_sub$rt)\n\n\n  0   1 \n468 405"
  },
  {
    "objectID": "tools-basic-programming.html#assigning-objects",
    "href": "tools-basic-programming.html#assigning-objects",
    "title": "Basic programming",
    "section": "",
    "text": "Use the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns the value on the right, to the object on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\nOnce the object is assigned, the assignment step will be evaluated but it will not print to the console\nPrint to the console by typing the object name alone\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nTo assign a character variable, wrap it in single or double quotes:\n\ny &lt;- \"cat\"\ny\n\n[1] \"cat\"\n\n\n\n\n\n\n\n\nSession 2, Exercise 1\n\n\n\n\n\n\nOpen RStudio Pro on Posit Workbench\nCreate a new R script named “session2-exercises” and save it to the “mmedr” folder on your home directory that was created in Session 1\nCreate an object called “age” and assign it the numeric value of your age\nCreate an object called “name” and assign it the character value of your first name\nExecute the code\nPrint the object assignments to the console\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 1 Solution"
  },
  {
    "objectID": "tools-basic-programming.html#functions",
    "href": "tools-basic-programming.html#functions",
    "title": "Basic programming",
    "section": "",
    "text": "Functions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\na\n\n[1] 1 2 3 4\n\nb &lt;- seq(from = 0, to = 100, by = 10)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nSo the following produce the same results:\n\nb &lt;- seq(from = 0, to = 100, by = 10)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\nb &lt;- seq(0, 100, 10)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\nb &lt;- seq(by = 10, to = 100, from = 0)\nb\n\n [1]   0  10  20  30  40  50  60  70  80  90 100"
  },
  {
    "objectID": "tools-basic-programming.html#getting-help",
    "href": "tools-basic-programming.html#getting-help",
    "title": "Basic programming",
    "section": "",
    "text": "Get help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n?mean\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the help file, it can be particularly useful to scroll to the bottom and read and try the exercises.\n\n\n\n\n\n\n\n\nSession 2, Exercise 2\n\n\n\n\n\n\nLook up the help file for the “log” function\nCalculate the natural log of 1\nCalculate log base 10 of 5\n\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 2 Solution\n\n\n\n\n\n\n#1. \n?log\n\n\n#2. \nlog(1)\n\n[1] 0\n\n#3.\nlog10(5)\n\n[1] 0.69897\n\n# OR #\nlog(5, base = 10)\n\n[1] 0.69897\n\n# OR #\nlog(base = 10, x = 5)\n\n[1] 0.69897\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can write comments in your R code by starting a line with “#”. It is recommended to write a lot of verbal comments about what your R code is doing so that if you need to come back to it later, you will know what it was doing and why.\nFor example:\n\n# This R code file will demonstrate how to assign a value (on the right) to an object (on the left) using the \"&lt;-\" operator\n\n# Assign the numeric value 5 to the object x\nx &lt;- 5\n\n# Assign the character value a to the object y\ny &lt;- \"a\""
  },
  {
    "objectID": "tools-basic-programming.html#pipe-operator",
    "href": "tools-basic-programming.html#pipe-operator",
    "title": "Basic programming",
    "section": "",
    "text": "Before we go on, we need to learn about the pipe operator.\nWe will use the pipe operator to string multiple functions together seamlessly.\nThere are two forms of the pipe operator in R:\n\nThe “native” pipe operator “|&gt;”\nThe pipe operator from the {magrittr} package “%&gt;%”\n\nThey perform (almost) identically, but one is built in to base R and the other requires you to load a package.\nGo to Tools &gt; Global Options &gt; Code &gt; Editing and tick the box for “Use native pipe operator” to enable this in RStudio.\n\n\n\nYou can insert the pipe operator through the keyboard shortcut ctrl + shift + m.\nFor example, if we want generate 100 random numbers from the exponential distribution, take the log transformation, and then get the mean, we could nest the functions as follows:\n\nset.seed(123) # needed to make random number generation reproducible\nmean(log(rexp(100)))\n\n[1] -0.4802932\n\n\nOr we can connect them with the pipe operator:\n\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  log() |&gt; \n  mean()\n\n[1] -0.4802932\n\n\nThe value on the left hand side of the pipe operator is passed as the first argument to the function on the right hand side of the pipe operator.\nThis creates code that is very readable and concise, especially if you arrange your code vertically rather than horizontally.\nIt is also easy to comment out various parts if needed.\n\n# Horizontal pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt; rexp() |&gt;  log() |&gt;  mean()\n\n[1] -0.4802932\n\n\nWhat if I quickly want to see what the results would look like without the log transformation, but I don’t want to permanently delete that part of the code?\nI can comment that part out, and in the vertical setup this is easy:\n\n# Vertical pipes\nset.seed(123) # needed to make random number generation reproducible\n100 |&gt;\n  rexp() |&gt; \n  # log() |&gt; \n  mean()\n\n[1] 1.045719\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe keyboard shortcut ctrl + shift + c will insert a # (comment) at the beginning of the code line.\n\n\nWe’ll be using the pipe operator throughout the remaining R sessions in this course."
  },
  {
    "objectID": "tools-basic-programming.html#testing-for-equality",
    "href": "tools-basic-programming.html#testing-for-equality",
    "title": "Basic programming",
    "section": "",
    "text": "The == operator tests for equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nThis will be useful later when we subset data."
  },
  {
    "objectID": "tools-basic-programming.html#indexing",
    "href": "tools-basic-programming.html#indexing",
    "title": "Basic programming",
    "section": "",
    "text": "R has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest.\nTo use best practices from last class, create an R project for use in this course. Create it in the existing “mmedr” folder on your home directory.\nLoad the “breastcancer” data that we saved as a .csv to the “mmedr” folder on our home drive last class, and assign it to the object “df”.\nClean the names using the {janitor} package.\n\nlibrary(readr)\nlibrary(here)\nlibrary(janitor)\ndf &lt;- read_csv(here(\"breastcancer.csv\")) |&gt; \n  clean_names()\n\nFor example, to calculate the mean of the variable age_dx_yrs in the dataframe df:\n\nmean(df$age_dx_yrs)\n\n[1] 57.2952\n\n\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(df[[\"age_dx_yrs\"]])\n\n[1] 57.2952\n\n\n\n\n\n\n\n\nSession 2, Exercise 3\n\n\n\n\n\nUse the table() function to create a table of the values in “grade” in the breastcancer data.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 3 Solution\n\n\n\n\n\n\ntable(df$grade)\n\n\n   I   II  III \n 362 1310 1328"
  },
  {
    "objectID": "tools-basic-programming.html#subsets",
    "href": "tools-basic-programming.html#subsets",
    "title": "Basic programming",
    "section": "",
    "text": "Sometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with radiation therapy (i.e. rt has the value 1):\n\ndf_sub &lt;- df[df$rt == 1, ]\nnrow(df_sub)\n\n[1] 1772\n\n\nWe see that the new data subset has 1772 rows instead of the 3000 in the original dataset.\nAnd now there are only values of 1 for the variable “rt”:\n\ntable(df_sub$rt)\n\n\n   1 \n1772 \n\n\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with radiation therapy AND had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 & df$grade == \"III\", ]\nnrow(df_sub)\n\n[1] 851\n\n\nAnd we see that the new data subset has 851 rows instead of the 3000 in the original dataset.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with radiation therapy OR had grade 3 disease:\n\ndf_sub &lt;- df[df$rt == 1 | df$grade == \"III\", ]\nnrow(df_sub)\n\n[1] 2249\n\n\nAnd we see that our new data subset has 2249 rows instead of the 3000 in the original dataset.\nWe can also create a subset of our data based on columns, for example limiting to radiation therapy:\n\ndf_sub &lt;- df[ , c(\"rt\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the radiation column among patients with grade 3 disease:\n\ndf_sub &lt;- df[df$grade == \"III\", c(\"rt\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age_dx_yrs in the dataframe df, but only among those who were treated with radiation therapy:\n\nmean(df$age_dx_yrs[df$rt == 1])\n\n[1] 55.08356\n\n\nThis avoids creating additional datasets that may not be needed again.\n\n\n\n\n\n\nSession 2, Exercise 4\n\n\n\n\n\nSay we are only interested in the affect of radiation therapy in older adults. Create a subset of the breastcancer data in patients &gt;=65 years old, and then look at a table of rt among the older subset.\n\n\n\n\n\n\n\n\n\nSession 2, Exercise 4 Solution\n\n\n\n\n\n\ndf_sub &lt;- df[df$age_dx_yrs &gt;= 65, ]\ntable(df_sub$rt)\n\n\n  0   1 \n468 405"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R For Molecular Medicine",
    "section": "",
    "text": "This website hosts R teaching materials for the Cleveland Clinic Molecular Medicine PhD program. The material will be split across 5 1-hour sessions as part of the Tools course, followed by 2 2-hour sessions as part of the Biostatistics and Epidemiology course."
  },
  {
    "objectID": "index.html#tools-course",
    "href": "index.html#tools-course",
    "title": "R For Molecular Medicine",
    "section": "Tools course",
    "text": "Tools course\n\nSession 1\n\nIntroduction to the tools\n\nR\nRStudio\nPosit Workbench\n\nUsing RStudio\nInstalling and loading R packages\n\nCRAN\nGithub\nBioconductor\n\n\n\n\nSession 2\n\nLoading data\n\n.xlsx\n.csv\nOther formats\nVariable names (janitor)\n\nReproducibility\n\nRStudio projects\nProject workflow and organization\n{here} package\n\n\n\n\nSession 3\n\nBasic programming\n\nAssigning objects\nFunctions\nGetting help\nThe pipe operator\nTesting for equality\nIndexing\nSubsetting\n\n\n\n\nSession 4\n\nManipulate dataframes\n\nThe dplyr package\nRename columns\nAdd columns\nGroup a continuous variable\nRecategorize a categorical variable\nSort by row\n\n\n\n\nSession 5\n\nPut it all together"
  },
  {
    "objectID": "index.html#biostatistics-and-epidemiology",
    "href": "index.html#biostatistics-and-epidemiology",
    "title": "R For Molecular Medicine",
    "section": "Biostatistics and Epidemiology",
    "text": "Biostatistics and Epidemiology\n\nSession 1\n\nRefresher of the Tools course material\nVisualization\n\nScatterplot\nBar chart\nHistogram\nLine chart\nBoxplot\nCustomization\nFaceting\nSaving plots\n\nDescriptive statistics\n\nOne-way frequency table\nTwo-way contingency table\nSummary statistics\nSummary statistics by group\n\n\n\n\nSession 2\n\nAdjustment for multiple comparisons\nAdvanced programming\n\nWriting custom functions\nFor loops/apply/map\n\nStatistical tests\n\nFisher’s exact test\nChi-squared test\nWilcoxon rank sum test/Kruskal-Wallis test\nT-test\nANOVA\nWilcoxon signed rank test\nPaired t-test"
  },
  {
    "objectID": "bio-epi-statistical-tests.html",
    "href": "bio-epi-statistical-tests.html",
    "title": "Statistical tests",
    "section": "",
    "text": "In this session, we will introduce methods to adjust p-values to account for multiple testing, learn advanced programming techniques including for loops and writing custom functions, and cover basic statistical tests to conduct hypothesis testing for different combinations of continuous, categorical, and paired data.\n\n\nThere are two main tests for associations between two categorical variables: the chi-squared test and Fisher’s exact test.\nConduct these tests in R using the following functions:\n\nchisq.test()\nfisher.test()\n\nConduct a chi-squared test of the null hypothesis that there is no association between treatment and response versus the alternative hypothesis that there is an association between treatment and response.\n\nlibrary(gtsummary)\n\nchisq.test(x = trial$trt, y = trial$response)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  trial$trt and trial$response\nX-squared = 0.22329, df = 1, p-value = 0.6365\n\n\nThe chi-squared test statistic is 0.22329 with associated p-value 0.6365.\nDo not reject the null hypothesis since the p-value is greater than the traditional threshold for significance of 0.05.\nConduct a Fisher’s exact test (an alternative to the chi-squared test when any expected cell count is &lt;5):\n\nfisher.test(x = trial$trt, y = trial$response)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  trial$trt and trial$response\np-value = 0.5403\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6326222 2.3394994\nsample estimates:\nodds ratio \n  1.213605 \n\n\nThe p-value is 0.5403.\nDo not reject the null hypothesis of no association between treatment and response since the p-value is greater than the traditional threshold for significance of 0.05.\n\n\n\nThe most common statistical tests for the association between a continuous and a categorical variable are the non-parametric Kruskal-Wallis test and the parametric t-test.\nConduct these tests in R using the following functions:\n\nkruskal.test() (see also wilcox.test())\nt.test()\n\nNote that the Kruskal-Wallis test is also known as the Wilcoxon rank-sum test in the special case of a 2-level categorical variable.\n“Non-parametric” means that there is no parametric distribution assumption made on the continuous variable - i.e. the continuous variable does not need to be normally distributed.\nConduct a Kruskal-Wallis test to test the null hypothesis of no association between marker status and response versus the alternative hypothesis that there is an association between marker status and response.\n\nkruskal.test(marker ~ response, data = trial)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  marker by response\nKruskal-Wallis chi-squared = 2.727, df = 1, p-value = 0.09866\n\n\nSince “response” is a 2-level categorical variable, the Wilcoxon rank-sum test (without continuity correction) produces the same result:\n\nwilcox.test(marker ~ response, correct = FALSE, data = trial)\n\n\n    Wilcoxon rank sum test\n\ndata:  marker by response\nW = 3043, p-value = 0.09866\nalternative hypothesis: true location shift is not equal to 0\n\n\nWith a p-value of 0.099, do not reject the null hypothesis at the 0.05 significance level.\n“Parametric” means that the test assumes a parametric distirbution - in the case of the t-test, it relies on the assumption that the continuous variable is normally distributed.\nIf appropriate given the distribution of the continuous variable, conduct a t-test:\n\nt.test(marker ~ response, data = trial)\n\n\n    Welch Two Sample t-test\n\ndata:  marker by response\nt = -1.5851, df = 96.232, p-value = 0.1162\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.51378857  0.05753795\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8425238       1.0706491 \n\n\nThe p-value differs but the conclusion is the same: do not reject the null hypothesis that there is no association between marker and response.\nHowever, in this example the data are right-skewed so a t-test is not appropriate.\n\nlibrary(ggplot2)\n\nggplot(data = trial, aes(x = marker)) +\n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n\nTips:\n\nFor the preceding two tests we used the formula option to supply the information for the test\nA formula in R looks like LHS ~ RHS where the left-hand side (“LHS”) is typically an outcome variable or dependent variable and the right-hand side (“RHS”) is the independent variable.\nFor multivariable regression, you can specify formulas in the format Y ~ X1 + X2 + X3... when there is more than one independent variable.\nYou must also supply the name of the dataset to the data = argument so that R knows where to look to find the specified variables.\nSee the help files for alternative ways to supply the information for each test\n\nWhat if our categorical variables has more than 2 levels, but we want to do a parametric test? Then we will use ANOVA. ANOVA tests the null hypothesis of no association between marker and grade, which has more than two levels so a t-test is not appropriate, and relies on the assumption that the continuous variable is normally distributed.\n\nlm_mod &lt;- lm(marker ~ grade, data = trial)\nanova(lm_mod)\n\nAnalysis of Variance Table\n\nResponse: marker\n           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \ngrade       2   5.385 2.69264  3.7529 0.02523 *\nResiduals 187 134.168 0.71748                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnd here we would reject the null hypothesis of no association between marker and grade, at the 0.05 level.\n\n\n\nNext we consider the setting where we have paired data. Paired data are any data where a continuous variable is matched in a meaningful way between the two groups. Examples:\n\nPre vs post drug/surgery/test/etc on a single subject\nMeasurements on two eyes within subject\nSibling or spousal pairs\n\nWe will use the example data from the help page found by running ?wilcox.test. These are measurements of a continuous depression scale on 9 patients taken at the first (x) and second (y) visits after inititiation of a certain therapy. We want to test the null hypothesis that there is no difference in depression scale values between these two times.\n\nx &lt;- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)\ny &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)\n\nThe Wilcoxon signed-rank test is a non-parametric test for the association between paired continuous data. Note that this is the same function we used for the Wilcoxon rank-sum test previously, with non-paired data, only now we add the paired = TRUE argument.\n\nwilcox.test(x, y, paired = TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  x and y\nV = 40, p-value = 0.03906\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe reject the null hypothesis at the 0.05 level.\nFor demonstration purposes we also try the paired t-test, which requires data to be normally distributed, to test the null hypothesis that there is no difference in depression scale values between these two times. Again, note that this is the same function we used for the standard t-test previously, only now we have added the paired = TRUE argument.\n\nt.test(x, y, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  x and y\nt = 3.0354, df = 8, p-value = 0.01618\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1037787 0.7599991\nsample estimates:\nmean difference \n      0.4318889 \n\n\nAnd again we reject the null hypothesis at the 0.05 level."
  },
  {
    "objectID": "bio-epi-statistical-tests.html#two-categorical-variables",
    "href": "bio-epi-statistical-tests.html#two-categorical-variables",
    "title": "Statistical tests",
    "section": "",
    "text": "There are two main tests for associations between two categorical variables: the chi-squared test and Fisher’s exact test.\nConduct these tests in R using the following functions:\n\nchisq.test()\nfisher.test()\n\nConduct a chi-squared test of the null hypothesis that there is no association between treatment and response versus the alternative hypothesis that there is an association between treatment and response.\n\nlibrary(gtsummary)\n\nchisq.test(x = trial$trt, y = trial$response)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  trial$trt and trial$response\nX-squared = 0.22329, df = 1, p-value = 0.6365\n\n\nThe chi-squared test statistic is 0.22329 with associated p-value 0.6365.\nDo not reject the null hypothesis since the p-value is greater than the traditional threshold for significance of 0.05.\nConduct a Fisher’s exact test (an alternative to the chi-squared test when any expected cell count is &lt;5):\n\nfisher.test(x = trial$trt, y = trial$response)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  trial$trt and trial$response\np-value = 0.5403\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6326222 2.3394994\nsample estimates:\nodds ratio \n  1.213605 \n\n\nThe p-value is 0.5403.\nDo not reject the null hypothesis of no association between treatment and response since the p-value is greater than the traditional threshold for significance of 0.05."
  },
  {
    "objectID": "bio-epi-statistical-tests.html#one-continuous-one-categorical",
    "href": "bio-epi-statistical-tests.html#one-continuous-one-categorical",
    "title": "Statistical tests",
    "section": "",
    "text": "The most common statistical tests for the association between a continuous and a categorical variable are the non-parametric Kruskal-Wallis test and the parametric t-test.\nConduct these tests in R using the following functions:\n\nkruskal.test() (see also wilcox.test())\nt.test()\n\nNote that the Kruskal-Wallis test is also known as the Wilcoxon rank-sum test in the special case of a 2-level categorical variable.\n“Non-parametric” means that there is no parametric distribution assumption made on the continuous variable - i.e. the continuous variable does not need to be normally distributed.\nConduct a Kruskal-Wallis test to test the null hypothesis of no association between marker status and response versus the alternative hypothesis that there is an association between marker status and response.\n\nkruskal.test(marker ~ response, data = trial)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  marker by response\nKruskal-Wallis chi-squared = 2.727, df = 1, p-value = 0.09866\n\n\nSince “response” is a 2-level categorical variable, the Wilcoxon rank-sum test (without continuity correction) produces the same result:\n\nwilcox.test(marker ~ response, correct = FALSE, data = trial)\n\n\n    Wilcoxon rank sum test\n\ndata:  marker by response\nW = 3043, p-value = 0.09866\nalternative hypothesis: true location shift is not equal to 0\n\n\nWith a p-value of 0.099, do not reject the null hypothesis at the 0.05 significance level.\n“Parametric” means that the test assumes a parametric distirbution - in the case of the t-test, it relies on the assumption that the continuous variable is normally distributed.\nIf appropriate given the distribution of the continuous variable, conduct a t-test:\n\nt.test(marker ~ response, data = trial)\n\n\n    Welch Two Sample t-test\n\ndata:  marker by response\nt = -1.5851, df = 96.232, p-value = 0.1162\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.51378857  0.05753795\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8425238       1.0706491 \n\n\nThe p-value differs but the conclusion is the same: do not reject the null hypothesis that there is no association between marker and response.\nHowever, in this example the data are right-skewed so a t-test is not appropriate.\n\nlibrary(ggplot2)\n\nggplot(data = trial, aes(x = marker)) +\n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n\nTips:\n\nFor the preceding two tests we used the formula option to supply the information for the test\nA formula in R looks like LHS ~ RHS where the left-hand side (“LHS”) is typically an outcome variable or dependent variable and the right-hand side (“RHS”) is the independent variable.\nFor multivariable regression, you can specify formulas in the format Y ~ X1 + X2 + X3... when there is more than one independent variable.\nYou must also supply the name of the dataset to the data = argument so that R knows where to look to find the specified variables.\nSee the help files for alternative ways to supply the information for each test\n\nWhat if our categorical variables has more than 2 levels, but we want to do a parametric test? Then we will use ANOVA. ANOVA tests the null hypothesis of no association between marker and grade, which has more than two levels so a t-test is not appropriate, and relies on the assumption that the continuous variable is normally distributed.\n\nlm_mod &lt;- lm(marker ~ grade, data = trial)\nanova(lm_mod)\n\nAnalysis of Variance Table\n\nResponse: marker\n           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \ngrade       2   5.385 2.69264  3.7529 0.02523 *\nResiduals 187 134.168 0.71748                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnd here we would reject the null hypothesis of no association between marker and grade, at the 0.05 level."
  },
  {
    "objectID": "bio-epi-statistical-tests.html#paired-data",
    "href": "bio-epi-statistical-tests.html#paired-data",
    "title": "Statistical tests",
    "section": "",
    "text": "Next we consider the setting where we have paired data. Paired data are any data where a continuous variable is matched in a meaningful way between the two groups. Examples:\n\nPre vs post drug/surgery/test/etc on a single subject\nMeasurements on two eyes within subject\nSibling or spousal pairs\n\nWe will use the example data from the help page found by running ?wilcox.test. These are measurements of a continuous depression scale on 9 patients taken at the first (x) and second (y) visits after inititiation of a certain therapy. We want to test the null hypothesis that there is no difference in depression scale values between these two times.\n\nx &lt;- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)\ny &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)\n\nThe Wilcoxon signed-rank test is a non-parametric test for the association between paired continuous data. Note that this is the same function we used for the Wilcoxon rank-sum test previously, with non-paired data, only now we add the paired = TRUE argument.\n\nwilcox.test(x, y, paired = TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  x and y\nV = 40, p-value = 0.03906\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe reject the null hypothesis at the 0.05 level.\nFor demonstration purposes we also try the paired t-test, which requires data to be normally distributed, to test the null hypothesis that there is no difference in depression scale values between these two times. Again, note that this is the same function we used for the standard t-test previously, only now we have added the paired = TRUE argument.\n\nt.test(x, y, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  x and y\nt = 3.0354, df = 8, p-value = 0.01618\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1037787 0.7599991\nsample estimates:\nmean difference \n      0.4318889 \n\n\nAnd again we reject the null hypothesis at the 0.05 level."
  },
  {
    "objectID": "bio-epi-multiple-testing.html",
    "href": "bio-epi-multiple-testing.html",
    "title": "Adjustment for multiple comparisons",
    "section": "",
    "text": "Adjustment for multiple comparisons\nIn this session, we will introduce methods to adjust p-values to account for multiple testing, learn advanced programming techniques including for loops and writing custom functions, and cover basic statistical tests to conduct hypothesis testing for different combinations of continuous, categorical, and paired data.\nThe problem is referred to as multiple comparisons, multiple testing, or multiplicity, but they all mean the same thing.\nWhat do we mean by multiple comparisons, and what is the issue?\nWhen multiple statistical tests are conducted simultaneously, type I errors become more likely. Therefore, our standard type I error rate of 0.05 that is used to determine whether p-values are significant or not is no longer correct, because the type I error has been inflated due to the multiple testing.\nMultiple comparisons affects both p-values and confidence intervals.\nPrior to significance testing we need to identify a more strict p-value threshold or, alternatively, directly adjust our p-values.\nA number of corrections for multiple comparisons can be implemented with the R function p.adjust().\nConsider the setting where we have p-values for the association between 10 different gene mutations and treatment response:\n\nlibrary(tibble)\nlibrary(gt)\n\nptab &lt;-\n  tibble(\n  Gene = paste0(\"gene\", seq(1:10)),\n  `p-value` = c(0.001, 0.245, 0.784, 0.034, 0.004, 0.123, 0.089, 0.063, 0.228, \n                0.802)\n  ) \n\nptab |&gt; \n  gt() |&gt; \n  tab_header(\"Table of p-values for association with treatment response\")\n\n\n\n\n\n\n\nTable of p-values for association with treatment response\n\n\nGene\np-value\n\n\n\n\ngene1\n0.001\n\n\ngene2\n0.245\n\n\ngene3\n0.784\n\n\ngene4\n0.034\n\n\ngene5\n0.004\n\n\ngene6\n0.123\n\n\ngene7\n0.089\n\n\ngene8\n0.063\n\n\ngene9\n0.228\n\n\ngene10\n0.802\n\n\n\n\n\n\n\nFirst, adjust these for multiple testing using the false-discovery rate approach. Pass the vector of p-values to p.adjust() and specify method = \"fdr\":\n\np.adjust(\n  p = c(0.001, 0.245, 0.784, 0.034, 0.004, 0.123, 0.089, 0.063, 0.228, 0.802),\n  method = \"fdr\"\n)\n\n [1] 0.0100000 0.3062500 0.8020000 0.1133333 0.0200000 0.2050000 0.1780000\n [8] 0.1575000 0.3062500 0.8020000\n\n\nGet back a vector of the adjusted p-values, listed in the same order as the originally provided p-values.\nThe false-discovery rate is the expected proportion of false positives among all significant tests, and is an appropriate method to use when a study is viewed as exploratory and significant results will be followed up in an independent study.\nAlternatively, we could adjust the p-values for multiple testing using the family-wise error approach. Some options include the Bonferroni correction (most conservative, i.e. most difficult to achieve significance) (method = \"bonferroni\") and the Holm-Bonferroni correction (method = \"holm\").\n\np.adjust(\n  p = c(0.001, 0.245, 0.784, 0.034, 0.004, 0.123, 0.089, 0.063, 0.228, 0.802),\n  method = \"bonferroni\"\n)\n\n [1] 0.01 1.00 1.00 0.34 0.04 1.00 0.89 0.63 1.00 1.00\n\n\nAnd we see that using the Bonferroni method, the adjusted p-values are larger than when using the FDR method. The familywise error rate is the probability of making a type I error among a specified group (“family”) of tests.\nAfter adjusting the p-values, we can compare them to the standard 0.05 level of significance.\nWe can place the FDR-adjusted p-values into our table by directly applying the p.adjust() function to our column of p-values as follows:\n\nlibrary(dplyr)\n\nptab |&gt; \n  mutate(\n    `q-value` = p.adjust(`p-value`, method = \"fdr\")\n  ) |&gt; \n  gt() |&gt; \n  fmt_number(columns = `q-value`, decimals = 3) |&gt; \n  tab_header(\"Table of adjusted p-values for association with treatment response\")\n\n\n\n\n\n\n\nTable of adjusted p-values for association with treatment response\n\n\nGene\np-value\nq-value\n\n\n\n\ngene1\n0.001\n0.010\n\n\ngene2\n0.245\n0.306\n\n\ngene3\n0.784\n0.802\n\n\ngene4\n0.034\n0.113\n\n\ngene5\n0.004\n0.020\n\n\ngene6\n0.123\n0.205\n\n\ngene7\n0.089\n0.178\n\n\ngene8\n0.063\n0.158\n\n\ngene9\n0.228\n0.306\n\n\ngene10\n0.802\n0.802\n\n\n\n\n\n\n\nNote that “q-value” is a common term for p-values that have been adjusted for multiple comparisons."
  },
  {
    "objectID": "bio-epi-advanced.html",
    "href": "bio-epi-advanced.html",
    "title": "Advanced programming",
    "section": "",
    "text": "In this session, we will introduce methods to adjust p-values to account for multiple testing, learn advanced programming techniques including for loops and writing custom functions, and cover basic statistical tests to conduct hypothesis testing for different combinations of continuous, categorical, and paired data.\n\n\nWe have previously discussed the role of functions in R, and have seen examples of built-in R functions, such as mean() and p.adjust().\nBut sometimes we’ll want to do something that isn’t included in a built-in R function, or that simplifies use of existing functions.\nUser-defined functions are created using the function() function.\nBasic usage is:\n\nfunction(arguments) expression\n\nWhere arguments are arguments you supply to the function and expression is the expression you want to evaluate.\nFor more complicated procedures, you can wrap multiple expressions in curly brackets, and can also specify what value to return using the return() function:\n\nfunction(arguments) {\n  expression1\n  expression2\n  return(value)\n  }\n\nFor example, I always want to show NA values when I look at a contingency table, which means I have to type in the useNA = \"ifany\" arguement every time I use the table() function, since the default in that function is to exclude missing values.\nTo streamline things, I can create a custom function that includes this option:\n\ntabna &lt;- function(x) table(x, useNA = 'ifany')\n\nNow instead of typing:\n\nlibrary(gtsummary)\n\ntable(trial$response, useNA = 'ifany')\n\n\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nI can type:\n\ntabna(trial$response)\n\nx\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nThis gets particularly useful for long or complex procedures, but is also really useful for short procedures that will be repeated many times - I often use this function 10+ times in a day.\nTry writing a custom function based on the mean() function but including the option to remove NAs from the calculation.\n\n\n\nOften we will want to repeat a set of operations several times, and we can do so using a loop.\nThere are three main types of loops in R:\n\nfor loop\nwhile loop\nrepeat loop\n\nWe will focus on the for loop today.\nHere is a basic example using the print() function to repeatedly print a value:\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nHere are the steps of the execution:\n\nThe value of i is set to 1\nThe value of i is printed to the console (first iteration complete)\nThe value of i is set to 2 (the for loop loops back to the beginning)\nThe value of i is printed to the console\n\nAnd so on until we reach the last value of i, and the process is complete.\nSay you have a biomarker in your dataset but you know the machine that generated the data has a lower limit of detection of 0.2. You could choose to impute half the detection limit for any values that fall below 0.2 as follows:\n\ntrial$marker_corrected &lt;- trial$marker\n\nfor(i in 1:nrow(trial)) {\n  if (is.na(trial$marker[i])) {\n    trial$marker_corrected[i] &lt;- NA\n  } else if (trial$marker[i] &lt; 0.2) {\n    trial$marker_corrected[i] &lt;- 0.1\n  }\n}\n\nAnd we can see that our new variable has the value 0.1 for all cases where marker was &lt;0.2:\n\ntrial[trial$marker &lt; 0.2, c(\"marker\", \"marker_corrected\")]\n\n# A tibble: 54 × 2\n   marker marker_corrected\n    &lt;dbl&gt;            &lt;dbl&gt;\n 1  0.16               0.1\n 2  0.144              0.1\n 3  0.06               0.1\n 4  0.128              0.1\n 5  0.157              0.1\n 6  0.066              0.1\n 7  0.096              0.1\n 8  0.105              0.1\n 9  0.043              0.1\n10  0.105              0.1\n# ℹ 44 more rows"
  },
  {
    "objectID": "bio-epi-advanced.html#custom-functions",
    "href": "bio-epi-advanced.html#custom-functions",
    "title": "Advanced programming",
    "section": "",
    "text": "We have previously discussed the role of functions in R, and have seen examples of built-in R functions, such as mean() and p.adjust().\nBut sometimes we’ll want to do something that isn’t included in a built-in R function, or that simplifies use of existing functions.\nUser-defined functions are created using the function() function.\nBasic usage is:\n\nfunction(arguments) expression\n\nWhere arguments are arguments you supply to the function and expression is the expression you want to evaluate.\nFor more complicated procedures, you can wrap multiple expressions in curly brackets, and can also specify what value to return using the return() function:\n\nfunction(arguments) {\n  expression1\n  expression2\n  return(value)\n  }\n\nFor example, I always want to show NA values when I look at a contingency table, which means I have to type in the useNA = \"ifany\" arguement every time I use the table() function, since the default in that function is to exclude missing values.\nTo streamline things, I can create a custom function that includes this option:\n\ntabna &lt;- function(x) table(x, useNA = 'ifany')\n\nNow instead of typing:\n\nlibrary(gtsummary)\n\ntable(trial$response, useNA = 'ifany')\n\n\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nI can type:\n\ntabna(trial$response)\n\nx\n   0    1 &lt;NA&gt; \n 132   61    7 \n\n\nThis gets particularly useful for long or complex procedures, but is also really useful for short procedures that will be repeated many times - I often use this function 10+ times in a day.\nTry writing a custom function based on the mean() function but including the option to remove NAs from the calculation."
  },
  {
    "objectID": "bio-epi-advanced.html#loops",
    "href": "bio-epi-advanced.html#loops",
    "title": "Advanced programming",
    "section": "",
    "text": "Often we will want to repeat a set of operations several times, and we can do so using a loop.\nThere are three main types of loops in R:\n\nfor loop\nwhile loop\nrepeat loop\n\nWe will focus on the for loop today.\nHere is a basic example using the print() function to repeatedly print a value:\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nHere are the steps of the execution:\n\nThe value of i is set to 1\nThe value of i is printed to the console (first iteration complete)\nThe value of i is set to 2 (the for loop loops back to the beginning)\nThe value of i is printed to the console\n\nAnd so on until we reach the last value of i, and the process is complete.\nSay you have a biomarker in your dataset but you know the machine that generated the data has a lower limit of detection of 0.2. You could choose to impute half the detection limit for any values that fall below 0.2 as follows:\n\ntrial$marker_corrected &lt;- trial$marker\n\nfor(i in 1:nrow(trial)) {\n  if (is.na(trial$marker[i])) {\n    trial$marker_corrected[i] &lt;- NA\n  } else if (trial$marker[i] &lt; 0.2) {\n    trial$marker_corrected[i] &lt;- 0.1\n  }\n}\n\nAnd we can see that our new variable has the value 0.1 for all cases where marker was &lt;0.2:\n\ntrial[trial$marker &lt; 0.2, c(\"marker\", \"marker_corrected\")]\n\n# A tibble: 54 × 2\n   marker marker_corrected\n    &lt;dbl&gt;            &lt;dbl&gt;\n 1  0.16               0.1\n 2  0.144              0.1\n 3  0.06               0.1\n 4  0.128              0.1\n 5  0.157              0.1\n 6  0.066              0.1\n 7  0.096              0.1\n 8  0.105              0.1\n 9  0.043              0.1\n10  0.105              0.1\n# ℹ 44 more rows"
  },
  {
    "objectID": "2024-notes-for-next-year.html",
    "href": "2024-notes-for-next-year.html",
    "title": "R For Molecular Medicine",
    "section": "",
    "text": "Here are my notes on changes to make for next year:\n\nI already rearranged the outline to reflect the material we were able to get through each day this year and believe this is more realistic\nPut assigning objects (and what objects even ar) earlier - needs to be before installing packages - currently its in the basic programming session (note that I put a placeholder called Using RStudio for this, currently with no content)\nOne of my examples in session 2 has the wrong path to the data - it should point to the data folder where I told them to save the data\nIn general need to streamline where I told them to save files and what the folder structure should look like throughout\nAlso need to streamline which parts they should be working on along with me and which parts are lecture, right now it’s confusing\nadd the != operator to the section on operators/indexing\nshow how to arrange() in the opposite direction in the session on manipulating dataframes\nnote that the sesison on manipulating dataframes took &lt;1 hour so could potentially add to it a bit - got done about 15 mins early\nsession 3 exercise 1 comes too soon - haven’t introduced case_when() yet - the two exercises here are too similar"
  },
  {
    "objectID": "bio-epi-descriptive-statistics.html",
    "href": "bio-epi-descriptive-statistics.html",
    "title": "Descriptive statistics",
    "section": "",
    "text": "It will be common to want some basic tabulations of categorical variables and summaries of continuous variables, to examine our data and make sure they are in line with what we expect, and to report results for papers.\nIn this session, we will learn some basic descriptive statistics including one-way and two-way contingency tables, summary statistics for continuous variables, and summary statistics by group.\nIn this session, we will be using functions from the {janitor}, {dplyr}, and {readr} packages, which we have used previously, and we will also be introducing the {gt} package. First, make sure these packages are installed and loaded in your current R session.\nNote that all of these packages are already installed on Posit Workbench on the server\n\ninstall.packages(\"janitor\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"readr\")\ninstall.packages(\"gt\")\n\n\nlibrary(janitor)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(gt)\n\nThe {gt} package will be used to creeate nicely styled tables.\nAlso make sure the breastcancer data are loaded into your current R session, with names standardized using the clean_names() function from the {janitor} package.\n\ndf &lt;- read_csv(\"~folder/breastcancer.csv\") |&gt; \n  clean_names()\n\n\n\nWe can use the tabyl() function from the {janitor} package to make a basic one-way frequency table.\nLet’s say we want a table of grade:\n\ndf |&gt; \n  tabyl(grade)\n\n grade    n   percent\n     I  362 0.1206667\n    II 1310 0.4366667\n   III 1328 0.4426667\n\n\nThen we could additionally format the percentages using the adorn_pct_formatting() function:\n\ndf |&gt; \n  tabyl(grade) |&gt; \n  adorn_pct_formatting()\n\n grade    n percent\n     I  362   12.1%\n    II 1310   43.7%\n   III 1328   44.3%\n\n\nAnd with just three short lines of code, we have a basic one-way contingency table for our categorical variable of interest.\n\n\n\nWe can similarly use thetabyl() function from the {janitor} package to make two-way contingency tables by simply adding another variable name, separated by a comma. Let’s say we now want to see grade tabulated by rt:\n\ndf |&gt; \n  tabyl(grade, rt)\n\n grade   0   1\n     I 189 173\n    II 562 748\n   III 477 851\n\n\nAnd we get a basic two-way contingency table with counts of grade according to the value of rt.\nTo enhance the appearance of our table, we can use the {gt} package and it’s associated features to customize our two-way contingency table.\nSee the {gt} package website for many details and features.\nLet’s label the row variable and column variable, and add a title:\n\ndf |&gt; \n  tabyl(grade, rt) |&gt; \n  gt(\n    rowname_col = \"grade\" \n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Radiation therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Grade\" \n  ) |&gt; \n  tab_header(           \n    title = \"Grade according to radiation therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nGrade according to radiation therapy\n\n\nGrade\n\nRadiation therapy?\n\n\n\n0\n1\n\n\n\n\nI\n189\n173\n\n\nII\n562\n748\n\n\nIII\n477\n851\n\n\n\n\n\n\n\nAnd now you see we have a nicely styled html table with the frequencies of grade according to rt, with row and column headers and a title.\nAlternatively, we could display percentages in our table. Let’s say we are interested in row percentages, to see what percentage of subjects received radiation therapy within each level of grade.\n\ndf |&gt; \n  tabyl(grade, rt) |&gt; \n  adorn_percentages(denominator = \"row\") |&gt; \n  gt(\n    rowname_col = \"grade\" \n  ) |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Radiation therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Grade\" \n  ) |&gt; \n  tab_header(           \n    title = \"Grade according to radiation therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nGrade according to radiation therapy\n\n\nGrade\n\nRadiation therapy?\n\n\n\n0\n1\n\n\n\n\nI\n52.2%\n47.8%\n\n\nII\n42.9%\n57.1%\n\n\nIII\n35.9%\n64.1%\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 1\n\n\n\n\n\nCreate a table of n_ln_pos_3_vs_1or2 by optimal_systemic_therapy, with percentages of sujects who received optimal_systemic_therapy within each level of n_ln_pos_3_vs_1or2, and styled with row and column names and a descriptive title.\nNote that n_ln_pos_3_vs_1or2 is 1 if a subject had 3 positive lymph nodes and 0 if a subject had 1 or 2 positive lymph nodes\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 1 Solution\n\n\n\n\n\n\ndf |&gt; \n  tabyl(n_ln_pos_3_vs_1or2, optimal_systemic_therapy) |&gt; \n  adorn_percentages(denominator = \"row\") |&gt; \n  gt(\n    rowname_col = \"n_ln_pos_3_vs_1or2\"\n  ) |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Optimal systemic therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"No. positive lymph nodes\" \n  ) |&gt; \n  tab_header(           \n    title = \"No. positive lymph nodes according to optimal systemic therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nNo. positive lymph nodes according to optimal systemic therapy\n\n\nNo. positive lymph nodes\n\nOptimal systemic therapy?\n\n\n\n0\n1\n\n\n\n\n0\n11.9%\n88.1%\n\n\n1\n8.4%\n91.6%\n\n\n\n\n\n\n\nTo make the table look even nicer, we could use the case_match() function from the {dplyr} package, which works similarly to case_when() but only considering a single variable, and is useful for recoding the levels of a categorical variable. We may want to create more descriptive levels than the 1/0 indicators these variables currently contain.\n\ndf |&gt; \n  mutate(\n    n_ln_pos_3_vs_1or2 = case_match(\n      n_ln_pos_3_vs_1or2,\n      1 ~ \"3\",\n      0 ~ \"1 or 2\"\n    ),\n    optimal_systemic_therapy = case_match(\n      optimal_systemic_therapy,\n      1 ~ \"Yes\",\n      0 ~ \"No\"\n    )\n  ) |&gt; \n  tabyl(n_ln_pos_3_vs_1or2, optimal_systemic_therapy) |&gt; \n  adorn_percentages(denominator = \"row\") |&gt; \n  gt(\n    rowname_col = \"n_ln_pos_3_vs_1or2\"\n  ) |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Optimal systemic therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"No. positive lymph nodes\" \n  ) |&gt; \n  tab_header(           \n    title = \"No. positive lymph nodes according to optimal systemic therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nNo. positive lymph nodes according to optimal systemic therapy\n\n\nNo. positive lymph nodes\n\nOptimal systemic therapy?\n\n\n\nNo\nYes\n\n\n\n\n1 or 2\n11.9%\n88.1%\n\n\n3\n8.4%\n91.6%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe case_match() function from the {dplyr} package is useful for recoding the levels of a categorical variable to get more desriptive levels when making tables or presenting summaries, e.g. from 0 to “No” and 1 to “Yes”\n\n\n\n\n\nWe can use the summarize() function from the {dplyr} package to compute summary statistics.\nLet’s compute the mean and standard deviation of age_dx_yrs:\n\ndf |&gt; \n  summarize(\n    avg_age = mean(age_dx_yrs),\n    sd_age = sd(age_dx_yrs)\n  )\n\n# A tibble: 1 × 2\n  avg_age sd_age\n    &lt;dbl&gt;  &lt;dbl&gt;\n1    57.3   13.9\n\n\n\n\n\nAnd we can easily extend this code to generate summary statistics by group by using the group_by() function from the {dplyr} package prior to using summarize().\nLet’s get the same summary table for age_dx_yrs, according to rt:\n\ndf |&gt; \n  group_by(rt) |&gt; \n  summarize(\n    avg_age = mean(age_dx_yrs),\n    sd_age = sd(age_dx_yrs)\n  )\n\n# A tibble: 2 × 3\n     rt avg_age sd_age\n  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     0    60.5   13.7\n2     1    55.1   13.5\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe group_by() function is useful in many settings, and it takes an existing dataframe and converts it to a grouped dataframe where all following operations are done within the group.\nNote: It is best practice to ungroup() when group operations are complete, to avoid unintended results.\nFor example:\n\ndf |&gt; \n  group_by(rt) |&gt; \n  summarize(\n    avg_age = mean(age_dx_yrs),\n    sd_age = sd(age_dx_yrs)\n  ) |&gt; \n  ungroup()\n\n# A tibble: 2 × 3\n     rt avg_age sd_age\n  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     0    60.5   13.7\n2     1    55.1   13.5\n\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 2\n\n\n\n\n\nSummarize tumor_size_cm according to grade.\nNote that there are missing values in tumor_size_cm (i.e. NA entries) that must be accounted for by supplying the appropriate additional argument to the mean() and sd() functions. Look at the help files at ?mean or ?sd to see how.\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 2 Solution\n\n\n\n\n\n\ndf |&gt; \n  group_by(grade) |&gt; \n  summarize(\n    avg_size = mean(tumor_size_cm, na.rm = TRUE),\n    sd_size = sd(tumor_size_cm, na.rm = TRUE)\n  ) |&gt; \n  ungroup()\n\n# A tibble: 3 × 3\n  grade avg_size sd_size\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 I         2.40   0.937\n2 II        2.39   0.983\n3 III       2.38   0.999"
  },
  {
    "objectID": "bio-epi-descriptive-statistics.html#one-way-frequency-table",
    "href": "bio-epi-descriptive-statistics.html#one-way-frequency-table",
    "title": "Descriptive statistics",
    "section": "",
    "text": "We can use the tabyl() function from the {janitor} package to make a basic one-way frequency table.\nLet’s say we want a table of grade:\n\ndf |&gt; \n  tabyl(grade)\n\n grade    n   percent\n     I  362 0.1206667\n    II 1310 0.4366667\n   III 1328 0.4426667\n\n\nThen we could additionally format the percentages using the adorn_pct_formatting() function:\n\ndf |&gt; \n  tabyl(grade) |&gt; \n  adorn_pct_formatting()\n\n grade    n percent\n     I  362   12.1%\n    II 1310   43.7%\n   III 1328   44.3%\n\n\nAnd with just three short lines of code, we have a basic one-way contingency table for our categorical variable of interest."
  },
  {
    "objectID": "bio-epi-descriptive-statistics.html#two-way-contingency-table",
    "href": "bio-epi-descriptive-statistics.html#two-way-contingency-table",
    "title": "Descriptive statistics",
    "section": "",
    "text": "We can similarly use thetabyl() function from the {janitor} package to make two-way contingency tables by simply adding another variable name, separated by a comma. Let’s say we now want to see grade tabulated by rt:\n\ndf |&gt; \n  tabyl(grade, rt)\n\n grade   0   1\n     I 189 173\n    II 562 748\n   III 477 851\n\n\nAnd we get a basic two-way contingency table with counts of grade according to the value of rt.\nTo enhance the appearance of our table, we can use the {gt} package and it’s associated features to customize our two-way contingency table.\nSee the {gt} package website for many details and features.\nLet’s label the row variable and column variable, and add a title:\n\ndf |&gt; \n  tabyl(grade, rt) |&gt; \n  gt(\n    rowname_col = \"grade\" \n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Radiation therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Grade\" \n  ) |&gt; \n  tab_header(           \n    title = \"Grade according to radiation therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nGrade according to radiation therapy\n\n\nGrade\n\nRadiation therapy?\n\n\n\n0\n1\n\n\n\n\nI\n189\n173\n\n\nII\n562\n748\n\n\nIII\n477\n851\n\n\n\n\n\n\n\nAnd now you see we have a nicely styled html table with the frequencies of grade according to rt, with row and column headers and a title.\nAlternatively, we could display percentages in our table. Let’s say we are interested in row percentages, to see what percentage of subjects received radiation therapy within each level of grade.\n\ndf |&gt; \n  tabyl(grade, rt) |&gt; \n  adorn_percentages(denominator = \"row\") |&gt; \n  gt(\n    rowname_col = \"grade\" \n  ) |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Radiation therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"Grade\" \n  ) |&gt; \n  tab_header(           \n    title = \"Grade according to radiation therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nGrade according to radiation therapy\n\n\nGrade\n\nRadiation therapy?\n\n\n\n0\n1\n\n\n\n\nI\n52.2%\n47.8%\n\n\nII\n42.9%\n57.1%\n\n\nIII\n35.9%\n64.1%\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 1\n\n\n\n\n\nCreate a table of n_ln_pos_3_vs_1or2 by optimal_systemic_therapy, with percentages of sujects who received optimal_systemic_therapy within each level of n_ln_pos_3_vs_1or2, and styled with row and column names and a descriptive title.\nNote that n_ln_pos_3_vs_1or2 is 1 if a subject had 3 positive lymph nodes and 0 if a subject had 1 or 2 positive lymph nodes\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 1 Solution\n\n\n\n\n\n\ndf |&gt; \n  tabyl(n_ln_pos_3_vs_1or2, optimal_systemic_therapy) |&gt; \n  adorn_percentages(denominator = \"row\") |&gt; \n  gt(\n    rowname_col = \"n_ln_pos_3_vs_1or2\"\n  ) |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Optimal systemic therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"No. positive lymph nodes\" \n  ) |&gt; \n  tab_header(           \n    title = \"No. positive lymph nodes according to optimal systemic therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nNo. positive lymph nodes according to optimal systemic therapy\n\n\nNo. positive lymph nodes\n\nOptimal systemic therapy?\n\n\n\n0\n1\n\n\n\n\n0\n11.9%\n88.1%\n\n\n1\n8.4%\n91.6%\n\n\n\n\n\n\n\nTo make the table look even nicer, we could use the case_match() function from the {dplyr} package, which works similarly to case_when() but only considering a single variable, and is useful for recoding the levels of a categorical variable. We may want to create more descriptive levels than the 1/0 indicators these variables currently contain.\n\ndf |&gt; \n  mutate(\n    n_ln_pos_3_vs_1or2 = case_match(\n      n_ln_pos_3_vs_1or2,\n      1 ~ \"3\",\n      0 ~ \"1 or 2\"\n    ),\n    optimal_systemic_therapy = case_match(\n      optimal_systemic_therapy,\n      1 ~ \"Yes\",\n      0 ~ \"No\"\n    )\n  ) |&gt; \n  tabyl(n_ln_pos_3_vs_1or2, optimal_systemic_therapy) |&gt; \n  adorn_percentages(denominator = \"row\") |&gt; \n  gt(\n    rowname_col = \"n_ln_pos_3_vs_1or2\"\n  ) |&gt; \n  fmt_percent(\n    columns = -1,\n    decimals = 1\n  ) |&gt; \n  tab_spanner(          \n    columns = 2:3,\n    label = \"Optimal systemic therapy?\"\n  ) |&gt; \n  tab_stubhead(         \n    label = \"No. positive lymph nodes\" \n  ) |&gt; \n  tab_header(           \n    title = \"No. positive lymph nodes according to optimal systemic therapy\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nNo. positive lymph nodes according to optimal systemic therapy\n\n\nNo. positive lymph nodes\n\nOptimal systemic therapy?\n\n\n\nNo\nYes\n\n\n\n\n1 or 2\n11.9%\n88.1%\n\n\n3\n8.4%\n91.6%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe case_match() function from the {dplyr} package is useful for recoding the levels of a categorical variable to get more desriptive levels when making tables or presenting summaries, e.g. from 0 to “No” and 1 to “Yes”"
  },
  {
    "objectID": "bio-epi-descriptive-statistics.html#summary-statistics",
    "href": "bio-epi-descriptive-statistics.html#summary-statistics",
    "title": "Descriptive statistics",
    "section": "",
    "text": "We can use the summarize() function from the {dplyr} package to compute summary statistics.\nLet’s compute the mean and standard deviation of age_dx_yrs:\n\ndf |&gt; \n  summarize(\n    avg_age = mean(age_dx_yrs),\n    sd_age = sd(age_dx_yrs)\n  )\n\n# A tibble: 1 × 2\n  avg_age sd_age\n    &lt;dbl&gt;  &lt;dbl&gt;\n1    57.3   13.9"
  },
  {
    "objectID": "bio-epi-descriptive-statistics.html#summary-statistics-by-group",
    "href": "bio-epi-descriptive-statistics.html#summary-statistics-by-group",
    "title": "Descriptive statistics",
    "section": "",
    "text": "And we can easily extend this code to generate summary statistics by group by using the group_by() function from the {dplyr} package prior to using summarize().\nLet’s get the same summary table for age_dx_yrs, according to rt:\n\ndf |&gt; \n  group_by(rt) |&gt; \n  summarize(\n    avg_age = mean(age_dx_yrs),\n    sd_age = sd(age_dx_yrs)\n  )\n\n# A tibble: 2 × 3\n     rt avg_age sd_age\n  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     0    60.5   13.7\n2     1    55.1   13.5\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe group_by() function is useful in many settings, and it takes an existing dataframe and converts it to a grouped dataframe where all following operations are done within the group.\nNote: It is best practice to ungroup() when group operations are complete, to avoid unintended results.\nFor example:\n\ndf |&gt; \n  group_by(rt) |&gt; \n  summarize(\n    avg_age = mean(age_dx_yrs),\n    sd_age = sd(age_dx_yrs)\n  ) |&gt; \n  ungroup()\n\n# A tibble: 2 × 3\n     rt avg_age sd_age\n  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     0    60.5   13.7\n2     1    55.1   13.5\n\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 2\n\n\n\n\n\nSummarize tumor_size_cm according to grade.\nNote that there are missing values in tumor_size_cm (i.e. NA entries) that must be accounted for by supplying the appropriate additional argument to the mean() and sd() functions. Look at the help files at ?mean or ?sd to see how.\n\n\n\n\n\n\n\n\n\nSession 4, Exercise 2 Solution\n\n\n\n\n\n\ndf |&gt; \n  group_by(grade) |&gt; \n  summarize(\n    avg_size = mean(tumor_size_cm, na.rm = TRUE),\n    sd_size = sd(tumor_size_cm, na.rm = TRUE)\n  ) |&gt; \n  ungroup()\n\n# A tibble: 3 × 3\n  grade avg_size sd_size\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 I         2.40   0.937\n2 II        2.39   0.983\n3 III       2.38   0.999"
  },
  {
    "objectID": "bio-epi-refresher.html",
    "href": "bio-epi-refresher.html",
    "title": "Refresher of the Tools course material",
    "section": "",
    "text": "In this session, we will review the basics of R and generating descriptive statistics in R, which were introduced in the Tools course. Then we will learn about data visualization, including creating scatterplots, bar charts, histograms, line charts, and boxplots. We’ll discuss plot customization, faceting, and saving plots. Both univariate and bivariable plotting will be covered.\n\n\nFirst, we’ll review the basics of R and R programming.\n\n\n\n\n\n\nR is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\n\n\n\n\n\n\n\n\nRStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download and provide simple instructions to follow\n\n\n\n\n\n\n\n\nWe will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\nWhen you first open RStudio you will see a number of panes:\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout.\nPanes:\n\nText editor - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will disply\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\n\n\n\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R script\nTo save the file go to: File &gt; Save\n\n\n\n\nNavigate to https://lri-r07.lerner.ccf.org/auth-sign-in, log in, and run some example code.\nDemonstrate how to:\n\nCreate a new R script\nAdd some code to it\nRun the code\nView help files\nSave the R script\n\n\nx &lt;- c(1, 2, 3, 4)\nmean(x)\nhist(rnorm(100))\n?rnorm\n\n\n\n\nTo send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight all three lines of code and use one of the previous options\n\n\n\n\nGet help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n\n\nAfter we have run all three lines of code, we see the results of our mean computation in the Console pane.\nAnd we see the resulting histogram in the Plots pane.\n\n\n\n\n\n\n\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nGitHub is a common repository for packages that are in development.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nThen, install the GitHub package of interest using install_github(\"username/repository\"). For example, to install the emo repository from the GitHub username hadley, use:\n\nlibrary(remotes)\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {GenomicFeatures} package using the install function:\n\nBiocManager::install(\"GenomicFeatures\")\n\nInstallation is the first step. Only needs to be done once.\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)\n\n\n\n\nThe primary dataset used throughout this course is stored in this folder. We need to download it from GitHub onto our personal computers.\n\nNavigate to the above location and left click on breastcancer.xlsx.\nFor a .xlsx file like this, you won’t see a preview of the data. Now right click on “Raw” and then select “Save link as…”\n\n\n\n\n\nNavigate to the “mmedr” folder we created earlier on your home directory, and save the file there as “breastcancer.xlsx”.\n\n\n\n\nThe most common data format we work with are data from Excel.\nData should be:\n\nOne dataset per file\nA single row of column headers across the top\nSimple column names are better - they will get transformed into variable names by R\nTypically one row per patient/sample is ideal\n\nWe will look at options to:\n\nRead in Excel files with {readxl}\nRead in Excel files by converting to .csv first\nRead in other file formats\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package:\n\ninstall.packages(\"readxl\")\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\"~/folder/filename.xlsx\")\n\nNote that R treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\nAlso note that on the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and select “CSV (Comma delimited)” from the “Save as type” drop down and save the file to the same location as “trial-csv.csv”\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- read.csv(\"~/folder/filename.csv\") \n\nNote that this is the approach I always use myself and will form the basis of all of my examples\nMany other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places\n\nRecall that we can clean up the names of the variables in our dataset using the clean_names() function from the {janitor} package:\n\nmycsv &lt;- \n  mycsv |&gt; \n  janitor::clean_names()\n\n\n\n\nUse the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns values on the right, to objects on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nFunctions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\nb &lt;- seq(from = 0, to = 100, by = 10)\nb &lt;- seq(0, 100, 10)\nb &lt;- seq(by = 10, to = 100, from = 0)\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order. The above three assignments to b yield the same results.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nR is case sensitive:\n\ni.e. age is not the same as Age.\nVariable names with spaces are problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in backticks: `Patient Age`\nOne option is to use the clean_names() function from the {janitor} package to convert all variable names to snake case (or alternatives):\n\n\n\ninstall.packages(\"janitor\")\njanitor::clean_names(df)\n\nThe == operator tests equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nWe’ll need this later when we subset data.\nR has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest\nFor example, to calculate the mean of the variable age_dx_years in the dataframe mycsv:\n\nmean(mycsv$age_dx_yrs, na.rm = TRUE)\n\n[1] 57.2952\n\n\nNote that we need to add the argument na.rm = TRUE to remove missing values from the calculation of the mean, otherwise NA will be returned if missing values are present\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(mycsv[[\"age_dx_yrs\"]], na.rm = TRUE)\n\n[1] 57.2952\n\n\nSometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with optimal systemic therapy:\n\ndf_sub &lt;- mycsv[mycsv$optimal_systemic_therapy == 1, ]\nnrow(df_sub)\n\n[1] 2660\n\n\nWe see that the new data subset has 2660 rows.\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with optimal systemic therapy AND are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$optimal_systemic_therapy == 1 & mycsv$age_dx_yrs &gt; 45, ]\nnrow(df_sub)\n\n[1] 2166\n\n\nAnd we see that the new data subset has 2166 rows.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with optimal systemic therapy OR are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$optimal_systemic_therapy == 1 | mycsv$age_dx_yrs &gt; 45, ]\nnrow(df_sub)\n\n[1] 2944\n\n\nAnd we see that our new datasubset has 2944 rows.\nWe can also create a subset of our data based on columns, for example limiting to optimal_systemic_therapy:\n\ndf_sub &lt;- mycsv[ , c(\"optimal_systemic_therapy\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the optimal_systemic_therapy column among patients with age greater than 45:\n\ndf_sub &lt;- mycsv[mycsv$age_dx_yrs &gt; 45, c(\"optimal_systemic_therapy\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age_dx_yrs in the dataframe mycsv, but only among those who were treated with optimal systemic therapy:\n\nmean(mycsv$age_dx_yrs[mycsv$optimal_systemic_therapy == 1], na.rm = TRUE)\n\n[1] 57.31611\n\n\nThis avoids creating additional datasets that may not be needed again."
  },
  {
    "objectID": "bio-epi-refresher.html#r-basics",
    "href": "bio-epi-refresher.html#r-basics",
    "title": "Refresher of the Tools course material",
    "section": "",
    "text": "First, we’ll review the basics of R and R programming.\n\n\n\n\n\n\nR is a free, open-source software environment for statistical computing and graphics\nMany of the functions you may wish to use will be contributed by other users as packages and available through repositories such as CRAN, GitHub, or Bioconductor, among others\nIt is your responsibility to vet the quality and accuracy of any user-contributed packages\nThe functions available with the initial installation of R, known as base R, can be considered trustworthy\n\n\n\n\n\nGo to the website for The Comprehensive R Archive Network.\nThe top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\n\n\n\n\n\n\n\n\nRStudio is an Integrated Development Environment (IDE).\nIt runs R and allows users to develop and edit programs and offers higher quality graphics and a more user-friendly interface.\nNote that RStudio is not a standalone program, you must have a separate installation of R\n\n\n\n\n\nGo to the website for RStudio\nSelect “Download RStudio Desktop” under “Open Source Edition”\nClick the button for “Download RStudio”\nScroll down and select the appropriate version for your operating system\nAn installer will download and provide simple instructions to follow\n\n\n\n\n\n\n\n\nWe will primarily use Posit Workbench on the servers, where the R version and many R packages are updated regularly\nSee the wiki for details: http://jjnb-wiki-v-00.bio.ri.ccf.org/index.php/Running_R\nLogin in using your Linux credentials at one of the links, for example lri-r07: https://lri-r07.lerner.ccf.org/auth-sign-in\n\n\n\n\nWhen you first open RStudio you will see a number of panes:\n\n\n\nThe layout of the panes can be customized by going to Tools &gt; Global Options &gt; Pane Layout.\nPanes:\n\nText editor - this is where you will type your code, and you will save this file to a project folder for reproducibility\nConsole - this is where the code will be executed\nOther panes will contain a variety of tabs. Some to note include:\n\nEnvironment: where you can see objects and data files that are available in your current session\nFiles: here you should be able to access all folders and files on your home drive\nPlots: this is where plots will disply\nHelp: this is where you will get help files for R functions\nViewer: this is where you would preview any html output like a gt table or Quarto document\n\n\n\n\n\nAlways use a text editor to type code so that it can be saved for reproducibility purposes.\nHow to open a text editor window:\n\nTo open a new text editor window go to: File &gt; New File &gt; R script\nTo save the file go to: File &gt; Save\n\n\n\n\nNavigate to https://lri-r07.lerner.ccf.org/auth-sign-in, log in, and run some example code.\nDemonstrate how to:\n\nCreate a new R script\nAdd some code to it\nRun the code\nView help files\nSave the R script\n\n\nx &lt;- c(1, 2, 3, 4)\nmean(x)\nhist(rnorm(100))\n?rnorm\n\n\n\n\nTo send this to the console to be executed, you can do one of the following:\n\nPlace your cursor next to the line you want to run and hit Ctrl+Enter on your keyboard\nPlace your cursor next to the line you want to run and hit the “Run” button\nHighlight all three lines of code and use one of the previous options\n\n\n\n\nGet help by typing ?fnname where fnname is the name of the function of interest.\n\ne.g. to see the help file for the mean function, type ?mean in the console\n??fnname can be used if you aren’t sure of the exact function name - it will return any keyword matches\n\n\n\n\nAfter we have run all three lines of code, we see the results of our mean computation in the Console pane.\nAnd we see the resulting histogram in the Plots pane.\n\n\n\n\n\n\n\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nGitHub is a common repository for packages that are in development.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nThen, install the GitHub package of interest using install_github(\"username/repository\"). For example, to install the emo repository from the GitHub username hadley, use:\n\nlibrary(remotes)\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {GenomicFeatures} package using the install function:\n\nBiocManager::install(\"GenomicFeatures\")\n\nInstallation is the first step. Only needs to be done once.\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)\n\n\n\n\nThe primary dataset used throughout this course is stored in this folder. We need to download it from GitHub onto our personal computers.\n\nNavigate to the above location and left click on breastcancer.xlsx.\nFor a .xlsx file like this, you won’t see a preview of the data. Now right click on “Raw” and then select “Save link as…”\n\n\n\n\n\nNavigate to the “mmedr” folder we created earlier on your home directory, and save the file there as “breastcancer.xlsx”.\n\n\n\n\nThe most common data format we work with are data from Excel.\nData should be:\n\nOne dataset per file\nA single row of column headers across the top\nSimple column names are better - they will get transformed into variable names by R\nTypically one row per patient/sample is ideal\n\nWe will look at options to:\n\nRead in Excel files with {readxl}\nRead in Excel files by converting to .csv first\nRead in other file formats\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package:\n\ninstall.packages(\"readxl\")\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\"~/folder/filename.xlsx\")\n\nNote that R treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\nAlso note that on the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and select “CSV (Comma delimited)” from the “Save as type” drop down and save the file to the same location as “trial-csv.csv”\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- read.csv(\"~/folder/filename.csv\") \n\nNote that this is the approach I always use myself and will form the basis of all of my examples\nMany other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places\n\nRecall that we can clean up the names of the variables in our dataset using the clean_names() function from the {janitor} package:\n\nmycsv &lt;- \n  mycsv |&gt; \n  janitor::clean_names()\n\n\n\n\nUse the assignment operator &lt;- to assign values to objects\n\n&lt;- assigns values on the right, to objects on the left\nKeyboard shortcut “Alt” + “-” will insert the assignment operator\n\n\nx &lt;- 55\nx\n\n[1] 55\n\n\nFunctions are pre-packaged scripts that automate more complicated procedures. They are executed by typing the name of the function followed by round brackets. Inside the round brackets we can provide one or more parameters, or arguments:\n\nx &lt;- 144\nsqrt(x)\n\n[1] 12\n\ny &lt;- 123.225\nround(y)\n\n[1] 123\n\nround(y, digits = 1)\n\n[1] 123.2\n\n\nUse c() to create a vector of values or seq() to create a sequence of values:\n\na &lt;- c(1, 2, 3, 4)\nb &lt;- seq(from = 0, to = 100, by = 10)\nb &lt;- seq(0, 100, 10)\nb &lt;- seq(by = 10, to = 100, from = 0)\n\nNote: when we supply the arguments to a function in the order in which they are listed in the documentation, we do not need to name them. If we name them, we can supply them in any order. The above three assignments to b yield the same results.\nHere are all of the possible arguments to the seq() function:\n\nseq(from = 1, to = 1, by = ((to - from)/(length.out - 1)),\n    length.out = NULL, along.with = NULL, ...)\n\nR is case sensitive:\n\ni.e. age is not the same as Age.\nVariable names with spaces are problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in backticks: `Patient Age`\nOne option is to use the clean_names() function from the {janitor} package to convert all variable names to snake case (or alternatives):\n\n\n\ninstall.packages(\"janitor\")\njanitor::clean_names(df)\n\nThe == operator tests equality between two values:\n\n5 == 5\n\n[1] TRUE\n\n5 == 9\n\n[1] FALSE\n\n\nThe first returns TRUE because 5 does in fact equal 5.\nThe second returns FALSE because 5 is not equal to 9.\nWe’ll need this later when we subset data.\nR has three main indexing operators:\n\nDollar sign: $\nDouble brackets: [[ ]]\nSingle brackets: [ ]\n\nTo access specific variables, use the $ operator in the form dataframe$varname, where dataframe is the name of the object to which we assigned our data set, and varname is the name of the variable of interest\nFor example, to calculate the mean of the variable age_dx_years in the dataframe mycsv:\n\nmean(mycsv$age_dx_yrs, na.rm = TRUE)\n\n[1] 57.2952\n\n\nNote that we need to add the argument na.rm = TRUE to remove missing values from the calculation of the mean, otherwise NA will be returned if missing values are present\nAlternatively, use double brackets in the form dataframe[[\"varname\"]]\n\nmean(mycsv[[\"age_dx_yrs\"]], na.rm = TRUE)\n\n[1] 57.2952\n\n\nSometimes we may want to create a subset of our data, or access a value based on more than one dimension.\nDatasets typically have two dimensions: columns and rows\nFor dataframe df, let i index the row and j index the column.\nThen we can access any single cell in the dataframe using the syntax:\n\ndf[i, j]\n\nWe can use this concept to create subsets of our data as well.\nWe can create a subset of our data based on the values in a row, for example limiting to patients who were treated with optimal systemic therapy:\n\ndf_sub &lt;- mycsv[mycsv$optimal_systemic_therapy == 1, ]\nnrow(df_sub)\n\n[1] 2660\n\n\nWe see that the new data subset has 2660 rows.\nThe & operator signifies “and”.\nSo for example we could subset based on patients who were treated with optimal systemic therapy AND are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$optimal_systemic_therapy == 1 & mycsv$age_dx_yrs &gt; 45, ]\nnrow(df_sub)\n\n[1] 2166\n\n\nAnd we see that the new data subset has 2166 rows.\nThe | operator signifies “or”.\nSo for example we could subset based on patients who were treated with optimal systemic therapy OR are over 45 years old:\n\ndf_sub &lt;- mycsv[mycsv$optimal_systemic_therapy == 1 | mycsv$age_dx_yrs &gt; 45, ]\nnrow(df_sub)\n\n[1] 2944\n\n\nAnd we see that our new datasubset has 2944 rows.\nWe can also create a subset of our data based on columns, for example limiting to optimal_systemic_therapy:\n\ndf_sub &lt;- mycsv[ , c(\"optimal_systemic_therapy\")]\n\nOr we can simultaneously subset based on rows and columns, for example limiting to the optimal_systemic_therapy column among patients with age greater than 45:\n\ndf_sub &lt;- mycsv[mycsv$age_dx_yrs &gt; 45, c(\"optimal_systemic_therapy\")]\n\nWe can also subset directly within functions. Suppose we want to calculate the mean of the variable age_dx_yrs in the dataframe mycsv, but only among those who were treated with optimal systemic therapy:\n\nmean(mycsv$age_dx_yrs[mycsv$optimal_systemic_therapy == 1], na.rm = TRUE)\n\n[1] 57.31611\n\n\nThis avoids creating additional datasets that may not be needed again."
  },
  {
    "objectID": "bio-epi-visualization.html",
    "href": "bio-epi-visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "In this session, we will review the basics of R and generating descriptive statistics in R, which were introduced in the Tools course. Then we will learn about data visualization, including creating scatterplots, bar charts, histograms, line charts, and boxplots. We’ll discuss plot customization, faceting, and saving plots. Both univariate and bivariable plotting will be covered.\nPlotting features are available in base R, but a very popular package for plotting in R is the {ggplot2} package, which will be the focus in this course.\n\n\n\n\ninstall.packages(\"ggplot2\")\n\n\nlibrary(ggplot2)\n\nMake sure the breastcancer dataset is loaded in your current R session, with names cleaned up using clean_names() from the {janitor} package:\n\nmycsv &lt;- read.csv(\"~/folder/breastcancer.csv\") |&gt; \n  clean_names()\n\n\n\nScatterplots display the joint distribution of two continuous variables. For example, what if we wanted to see a plot of “tumor_size_cm” by “age_dx__yrs”. Put age on the x-axis and tumor size on the y-axis.\nThe first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm))\n\nThen the scatterplot is created by adding a layer with geom_point() using the + operator:\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm)) + \n  geom_point()\n\n\n\n\n\n\n\n\nLook for increasing or decreasing trends, or clusters of points.\n\n\n\nWe can also look at the association between two continuous variables using a line chart.\nThe first layer of the plot specifies the dataset along with the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm))\n\nThen the line chart is created by adding a layer with geom_line() using the + operator.\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm)) + \n  geom_line()\n\n\n\n\n\n\n\n\nThere is no discernible pattern in this example, but we would look for increasing or decreasing trends in the line.\n\n\n\nA bar chart can be used to visualize the distribution of a categorical variable.\nThe first layer of the plot specifies the dataset and the x-axis variable:\n\nggplot(data = mycsv, aes(x = grade))\n\nThen the bar chart is created by adding a layer with geom_bar() using the + operator:\n\nggplot(data = mycsv, aes(x = grade)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe height of the bar is the number of observations in that category.\n\n\n\nIt is common to want to describe a continuous variable using a histogram, particularly to examine whether the distribution appears approximately normal.\nLet’s look at a histogram of tumor size The first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis variable:\n\nggplot(data = mycsv, aes(x = tumor_size_cm))\n\nCreate the histogram by adding a layer with geom_histogram() using the + operator:\n\nggplot(data = mycsv, aes(x = tumor_size_cm)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote that we received a message along with our output, regarding the number of bins being used in our histogram. This is prompting you to examine whether the default of 30 bins is appropriate for your given sample size and distribution - it usually isn’t\nIn this case, we will specify a smaller number of bins for the histogram using the bins = argument to geom_histogram():\n\nggplot(data = mycsv, aes(x = tumor_size_cm)) + \n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\n\nWe find that the distribution is aproximately normal.\n\n\n\nBoxplots are another common way of examining continuous variables. The continuous variable is on the y-axis, and there is no variable on the x-axis:\n\nggplot(data = mycsv, aes(y = marker))\n\nAnd the boxplot is created by adding a layer with geom_boxplot() using the + operator:\n\nggplot(data = mycsv, aes(y = tumor_size_cm)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe top and bottom of the box are the 25th and 75th quantiles, the center line is the median, and the whiskers extend to 1.5xIQR.\nWe may also want to make a boxplot according to a categorical variables. Say we are interested in the distribution of marker according to disease grade. We can add an argument to the x-axis of the first layer aesthetics to get separate boxes by grade:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nThere are many customizations available.\nFor example, we can change the x-axis and y-axis labels:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\"\n  )\n\n\n\n\n\n\n\n\nWe can add titles:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  )\n\n\n\n\n\n\n\n\nWe can set axis limits:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 6))\n\n\n\n\n\n\n\n\nWe can change the style of the plot using theme elements:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 6)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nAnd we can add color, in this case fill in the boxes:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade, fill = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 6)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nThere are many other customizations available, see the ggplot2 website for details and for a helpful cheatsheet of plotting options.\n\n\n\nWhat if it was of interest to see the distribution of tumor size according to disease grade?\nAdd a layer to our histogram using facet_grid() to get panels for each level of the disease grade variable “grade”.\nNote that by default the y-axis and x-axis limits are fixed across all plots, so we can directly compare the distributions. It is possible to control this with the scales argument to facet_grid(), see ?facet_grid for details.\n\nggplot(data = mycsv, aes(x = tumor_size_cm)) + \n  geom_histogram(bins = 10) +\n  facet_grid(cols = vars(grade))\n\n\n\n\n\n\n\n\n\n\n\nWe will often want to save plots to an external file to insert into a later document. There are several options:\n\nUse the interactive plot window to export your created plot.\nUse code to save your plot to an external location. There is a function called ggsave() specifically for saving results of ggplot(). By default it will save the last created plot, or you can save your plot to an object and specify it directly using the plot argument to ggsave(). You will specify the file format by including an extension, here “.png” on your filename. ]\n\n\n\nCreate your plot. Click on “Export” then select the option… 1. “Copy to Clipboard”. This will open a pop-up window where you could rescale the plot, if desired, and then click “Copy Plot” to copy the plot to your clipboard so that you can paste it into any external document. 2. “Save as Image…”. Here you can change the directory location where you want to save the plot to the same location where you have your code and data files for this class saved so far. You can select from a variety of file formats. Save it as “my-histogram” in PNG format. You can then insert this file into other documents as needed. 3. “Save as PDF…” and follow the same instructions as in B to save a .pdf version of your image.\n\n\n\n\np &lt;- ggplot(data = mycsv, aes(y = tumor_size_cv)) + \n  geom_boxplot() + \n  facet_grid(cols = vars(grade))\n    \nggsave(filename = \"~/folder/filename.png\", plot = p)\n\nAdjust the width and height using the width and/or height arguments to the ggsave() function, or save as different formats by using an alternate extension like .jpg, .tiff, .eps, etc"
  },
  {
    "objectID": "bio-epi-visualization.html#scatterplot",
    "href": "bio-epi-visualization.html#scatterplot",
    "title": "Visualization",
    "section": "",
    "text": "Scatterplots display the joint distribution of two continuous variables. For example, what if we wanted to see a plot of “tumor_size_cm” by “age_dx__yrs”. Put age on the x-axis and tumor size on the y-axis.\nThe first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm))\n\nThen the scatterplot is created by adding a layer with geom_point() using the + operator:\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm)) + \n  geom_point()\n\n\n\n\n\n\n\n\nLook for increasing or decreasing trends, or clusters of points."
  },
  {
    "objectID": "bio-epi-visualization.html#line-chart",
    "href": "bio-epi-visualization.html#line-chart",
    "title": "Visualization",
    "section": "",
    "text": "We can also look at the association between two continuous variables using a line chart.\nThe first layer of the plot specifies the dataset along with the x-axis and y-axis variables:\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm))\n\nThen the line chart is created by adding a layer with geom_line() using the + operator.\n\nggplot(data = mycsv, aes(x = age_dx_yrs, y = tumor_size_cm)) + \n  geom_line()\n\n\n\n\n\n\n\n\nThere is no discernible pattern in this example, but we would look for increasing or decreasing trends in the line."
  },
  {
    "objectID": "bio-epi-visualization.html#bar-charts",
    "href": "bio-epi-visualization.html#bar-charts",
    "title": "Visualization",
    "section": "",
    "text": "A bar chart can be used to visualize the distribution of a categorical variable.\nThe first layer of the plot specifies the dataset and the x-axis variable:\n\nggplot(data = mycsv, aes(x = grade))\n\nThen the bar chart is created by adding a layer with geom_bar() using the + operator:\n\nggplot(data = mycsv, aes(x = grade)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe height of the bar is the number of observations in that category."
  },
  {
    "objectID": "bio-epi-visualization.html#histogram",
    "href": "bio-epi-visualization.html#histogram",
    "title": "Visualization",
    "section": "",
    "text": "It is common to want to describe a continuous variable using a histogram, particularly to examine whether the distribution appears approximately normal.\nLet’s look at a histogram of tumor size The first layer of the plot simply specifies the dataset and the basic aesthetics, in this case just the x-axis variable:\n\nggplot(data = mycsv, aes(x = tumor_size_cm))\n\nCreate the histogram by adding a layer with geom_histogram() using the + operator:\n\nggplot(data = mycsv, aes(x = tumor_size_cm)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote that we received a message along with our output, regarding the number of bins being used in our histogram. This is prompting you to examine whether the default of 30 bins is appropriate for your given sample size and distribution - it usually isn’t\nIn this case, we will specify a smaller number of bins for the histogram using the bins = argument to geom_histogram():\n\nggplot(data = mycsv, aes(x = tumor_size_cm)) + \n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\n\nWe find that the distribution is aproximately normal."
  },
  {
    "objectID": "bio-epi-visualization.html#boxplot",
    "href": "bio-epi-visualization.html#boxplot",
    "title": "Visualization",
    "section": "",
    "text": "Boxplots are another common way of examining continuous variables. The continuous variable is on the y-axis, and there is no variable on the x-axis:\n\nggplot(data = mycsv, aes(y = marker))\n\nAnd the boxplot is created by adding a layer with geom_boxplot() using the + operator:\n\nggplot(data = mycsv, aes(y = tumor_size_cm)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe top and bottom of the box are the 25th and 75th quantiles, the center line is the median, and the whiskers extend to 1.5xIQR.\nWe may also want to make a boxplot according to a categorical variables. Say we are interested in the distribution of marker according to disease grade. We can add an argument to the x-axis of the first layer aesthetics to get separate boxes by grade:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot()"
  },
  {
    "objectID": "bio-epi-visualization.html#customization",
    "href": "bio-epi-visualization.html#customization",
    "title": "Visualization",
    "section": "",
    "text": "There are many customizations available.\nFor example, we can change the x-axis and y-axis labels:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\"\n  )\n\n\n\n\n\n\n\n\nWe can add titles:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  )\n\n\n\n\n\n\n\n\nWe can set axis limits:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 6))\n\n\n\n\n\n\n\n\nWe can change the style of the plot using theme elements:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 6)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nAnd we can add color, in this case fill in the boxes:\n\nggplot(data = mycsv, aes(y = tumor_size_cm, x = grade, fill = grade)) + \n  geom_boxplot() + \n  labs(\n    x = \"Disease grade\",\n    y = \"Tumor size (cm)\",\n    title = \"Boxplot of marker level by disease grade\"\n  ) + \n  ylim(c(0, 6)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nThere are many other customizations available, see the ggplot2 website for details and for a helpful cheatsheet of plotting options."
  },
  {
    "objectID": "bio-epi-visualization.html#faceting",
    "href": "bio-epi-visualization.html#faceting",
    "title": "Visualization",
    "section": "",
    "text": "What if it was of interest to see the distribution of tumor size according to disease grade?\nAdd a layer to our histogram using facet_grid() to get panels for each level of the disease grade variable “grade”.\nNote that by default the y-axis and x-axis limits are fixed across all plots, so we can directly compare the distributions. It is possible to control this with the scales argument to facet_grid(), see ?facet_grid for details.\n\nggplot(data = mycsv, aes(x = tumor_size_cm)) + \n  geom_histogram(bins = 10) +\n  facet_grid(cols = vars(grade))"
  },
  {
    "objectID": "bio-epi-visualization.html#saving-plots",
    "href": "bio-epi-visualization.html#saving-plots",
    "title": "Visualization",
    "section": "",
    "text": "We will often want to save plots to an external file to insert into a later document. There are several options:\n\nUse the interactive plot window to export your created plot.\nUse code to save your plot to an external location. There is a function called ggsave() specifically for saving results of ggplot(). By default it will save the last created plot, or you can save your plot to an object and specify it directly using the plot argument to ggsave(). You will specify the file format by including an extension, here “.png” on your filename. ]\n\n\n\nCreate your plot. Click on “Export” then select the option… 1. “Copy to Clipboard”. This will open a pop-up window where you could rescale the plot, if desired, and then click “Copy Plot” to copy the plot to your clipboard so that you can paste it into any external document. 2. “Save as Image…”. Here you can change the directory location where you want to save the plot to the same location where you have your code and data files for this class saved so far. You can select from a variety of file formats. Save it as “my-histogram” in PNG format. You can then insert this file into other documents as needed. 3. “Save as PDF…” and follow the same instructions as in B to save a .pdf version of your image.\n\n\n\n\np &lt;- ggplot(data = mycsv, aes(y = tumor_size_cv)) + \n  geom_boxplot() + \n  facet_grid(cols = vars(grade))\n    \nggsave(filename = \"~/folder/filename.png\", plot = p)\n\nAdjust the width and height using the width and/or height arguments to the ggsave() function, or save as different formats by using an alternate extension like .jpg, .tiff, .eps, etc"
  },
  {
    "objectID": "r-awesome.html",
    "href": "r-awesome.html",
    "title": "Websites in R",
    "section": "",
    "text": "Before we begin with any formal instruction, why R?\nBecause R is awesome.\nIn addition to being a great statistical programming software for basic data manipulation, plotting, and statistical analyses, R has a lot of other cool tools.\nLet’s see some examples.\n\nWebsites in R\nThis entire course website is written in R!\nYou can see the source code on GitHub: https://github.com/zabore/mmedr\n\n\nR Shiny"
  },
  {
    "objectID": "tools-install-packages.html",
    "href": "tools-install-packages.html",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "In the next part of Session 1, we will learn how to install and load R packages.\n\n\n\n\n\n\n\n\nR package\n\n\n\nAn R package is a collection of code, data, documentation, and tests.\nR packages are developed by the community.\nR packages add functionality to what comes in base R.\nTo use R packages, there are two steps:\n\nInstall\nLoad\n\n\n\n\n\n\nWe will cover the second step first, because it is the same for all methods of installing packages and we will reference this in covering some of the methods of installation.\nInstallation is the first step. Only needs to be done once. (Though needs to be repeated if you get a new version of R)\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)\n\n\n\n\nThere are three main repositories for R packages: CRAN, GitHub, and Bioconductor\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nThis package has comprehensive functionality for survival analyses.\n\n\n\nGitHub is a common repository for packages that are still in development, or have not been developed thoroughly enough to be accepted onto CRAN.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nNext load the {remotes} package using a call to library():\n\nlibrary(remotes)\n\nThen install the GitHub package of interest using install_github(\"username/repository\"), where “username” is the name of the GitHub user and “repository” is the name of the repository under the user’s account. For example, to install the emo repository from the GitHub user with username hadley, use:\n\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nThis package will let you put emojis in your documents 😄\n\n\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {ggtree} package with the install function, using either the library::function() syntax:\n\nBiocManager::install(\"ggtree\")\n\nOr using a call to library() followed by a separate call to install():\n\nlibrary(BiocManager)\ninstall(\"ggtree\")\n\nThis package is designed for visualization and annotation of phylogentic trees.\n\n\n\n\n\n\nImportant\n\n\n\nNote that when you are loading packages, there are no quotes around the package name inside library(), e.g. library(survival).\nBut when you are installing packages, using any of the three repositories described above, there are quotes around the package name, e.g. install.packages(\"survival\").\n\n\n\n\n\n\n\n\nR is case sensitive\n\n\n\n\ni.e. age is not the same as Age\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen using Posit Workbench, many commonly used packages have already been installed for the current version of R by the system administrator.\nAlways start by trying to load a package of interest first to see if it is available.\n\n\n\n\n\n\n\n\nTip\n\n\n\nR scripts are used for programming and saved with other project-related documents for reproducibility purposes.\nIt is important to include statements to load the packages used in any analysis in the R script.\nHowever, I do not think it is necessary to include statements to install the packages in the R script. I personally type these statements directly into the console since they do not need to be run every time and therefore are not part of the reproducibility pipeline.\n\n\n\n\n\n\n\n\nSession 1, Exercise 2\n\n\n\n\n\n\nOpen the R script we created earlier named “session1-exercies.R”\nLoad packages we will need in the rest of today’s session, including: janitor, here, readr, readxl\n\nNote that these packages are already available on the Posit Workbench servers. If you are using RStudio on your personal computer instead, you will need to install them if you have not done so already.\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 2 Solution\n\n\n\n\n\nIf using Posit Workbench where the packages are already installed:\n\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)\n\nIf using a personal computer where you have not previously installed these packages:\n\ninstall.packages(\"janitor\")\ninstall.packages(\"here\")\ninstall.packages(\"readr\")\ninstall.packages(\"readxl\")\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)"
  },
  {
    "objectID": "tools-install-packages.html#what-is-an-r-package",
    "href": "tools-install-packages.html#what-is-an-r-package",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "R package\n\n\n\nAn R package is a collection of code, data, documentation, and tests.\nR packages are developed by the community.\nR packages add functionality to what comes in base R.\nTo use R packages, there are two steps:\n\nInstall\nLoad"
  },
  {
    "objectID": "tools-install-packages.html#loading-r-packages",
    "href": "tools-install-packages.html#loading-r-packages",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "We will cover the second step first, because it is the same for all methods of installing packages and we will reference this in covering some of the methods of installation.\nInstallation is the first step. Only needs to be done once. (Though needs to be repeated if you get a new version of R)\nLoading is the next step. Must be done every time you open a new R session in which you need to use the package.\nThere are two methods for loading R packages:\n\nA call to library() loads the package for your entire R session.\n\n\nlibrary(survival)\nsurvfit(formula, ...)\n\n\nUsing :: accesses the package only for a single function.\n\n\nsurvival::survfit(formula, ...)"
  },
  {
    "objectID": "tools-install-packages.html#installing-r-packages",
    "href": "tools-install-packages.html#installing-r-packages",
    "title": "Installing and loading R packages",
    "section": "",
    "text": "There are three main repositories for R packages: CRAN, GitHub, and Bioconductor\n\n\nCRAN is the primary repository for user-contributed R packages.\nPackages that are on CRAN can be installed using the install.packages() function.\nFor example, we can install the {survival} package from CRAN using:\n\ninstall.packages(\"survival\")\n\nThis package has comprehensive functionality for survival analyses.\n\n\n\nGitHub is a common repository for packages that are still in development, or have not been developed thoroughly enough to be accepted onto CRAN.\nTo install packages from GitHub, first install the {remotes} package from CRAN:\n\ninstall.packages(\"remotes\")\n\nNext load the {remotes} package using a call to library():\n\nlibrary(remotes)\n\nThen install the GitHub package of interest using install_github(\"username/repository\"), where “username” is the name of the GitHub user and “repository” is the name of the repository under the user’s account. For example, to install the emo repository from the GitHub user with username hadley, use:\n\ninstall_github(\"hadley/emo\")\n\nOr, avoid a call to the library() function by using the syntax library::function():\n\nremotes::install_github(\"hadley/emo\")\n\nThis package will let you put emojis in your documents 😄\n\n\n\nBioconductor is a repository for open source code related to biological data. To install packages from Bioconductor, first install the {BiocManager} package from CRAN:\n\ninstall.packages(\"BiocManager\")\n\nThen install, for example, the {ggtree} package with the install function, using either the library::function() syntax:\n\nBiocManager::install(\"ggtree\")\n\nOr using a call to library() followed by a separate call to install():\n\nlibrary(BiocManager)\ninstall(\"ggtree\")\n\nThis package is designed for visualization and annotation of phylogentic trees.\n\n\n\n\n\n\nImportant\n\n\n\nNote that when you are loading packages, there are no quotes around the package name inside library(), e.g. library(survival).\nBut when you are installing packages, using any of the three repositories described above, there are quotes around the package name, e.g. install.packages(\"survival\").\n\n\n\n\n\n\n\n\nR is case sensitive\n\n\n\n\ni.e. age is not the same as Age\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen using Posit Workbench, many commonly used packages have already been installed for the current version of R by the system administrator.\nAlways start by trying to load a package of interest first to see if it is available.\n\n\n\n\n\n\n\n\nTip\n\n\n\nR scripts are used for programming and saved with other project-related documents for reproducibility purposes.\nIt is important to include statements to load the packages used in any analysis in the R script.\nHowever, I do not think it is necessary to include statements to install the packages in the R script. I personally type these statements directly into the console since they do not need to be run every time and therefore are not part of the reproducibility pipeline.\n\n\n\n\n\n\n\n\nSession 1, Exercise 2\n\n\n\n\n\n\nOpen the R script we created earlier named “session1-exercies.R”\nLoad packages we will need in the rest of today’s session, including: janitor, here, readr, readxl\n\nNote that these packages are already available on the Posit Workbench servers. If you are using RStudio on your personal computer instead, you will need to install them if you have not done so already.\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 2 Solution\n\n\n\n\n\nIf using Posit Workbench where the packages are already installed:\n\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)\n\nIf using a personal computer where you have not previously installed these packages:\n\ninstall.packages(\"janitor\")\ninstall.packages(\"here\")\ninstall.packages(\"readr\")\ninstall.packages(\"readxl\")\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(readxl)"
  },
  {
    "objectID": "tools-loading-data.html",
    "href": "tools-loading-data.html",
    "title": "Loading data",
    "section": "",
    "text": "In this part of Session 1, we will learn how to load external data into R.\nMany R packages come with data bundled into them. These datasets are available for use as soon as the package is loaded.\nHowever, we often need to load external data that we’ve generated in our lab or from a clinical study.\n\n\n\n\n\n\nFormatting data for use in R\n\n\n\nIf you are creating your own datasets for future analysis in R, or advising someone else about how best to do so, here are some tips:\n\nOne row per patient/subject\nColumn with a unique identifier for each subject (i.e. a patient ID)\n\nOR, if you have longitudinal or other repeated measures data, have another column identifying the repeat instance and then there can be multiple rows per patient for each repeat instance\n\nOne row of column labels (i.e. avoid a second row of headers where some cells are merged, etc)\nOne measurement with one column name in each column (i.e. avoid separating multiple pieces of data by commas, semicolons, etc within a cell)\nSimple variable names for each column - avoid long names and special characters\nNo color coding or other special formatting - will be stripped away on loading into R\n\n\n\n\n\nThe primary dataset used throughout this course is stored in this folder. We need to download it from GitHub onto our personal computers.\n\nNavigate to the above location and left click on breastcancer.xlsx.\nFor a .xlsx file like this, you won’t see a preview of the data. Now right click on “Raw” and then select “Save link as…”\n\n\n\n\n\nNavigate to the “mmedr” folder we created earlier on your home directory, and save the file there as “breastcancer.xlsx”.\n\n\n\n\nThe most common data format we work with are data from Excel. We will learn three ways to load Excel datasets into R, and then will introduce some options for alternative file types.\nWe will look at options to:\n\nRead in Excel files with the {readxl} package\nRead in Excel files by converting to .csv first\nRead in Excel files by converting to .csv first and using the {readr} package\n\n\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readxl\") # Already installed on Posit Workbench\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\"~/folder/filename.xlsx\")\n\n\n\n\n\n\n\nTip\n\n\n\nR treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\n\n\n\n\n\n\n\n\nTip\n\n\n\nOn the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\n\n\n\n\n\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and navigate to the folder where you want to save the data, if you are not already there\nSelect “CSV (Comma delimited)” from the “Save as type” drop down and save the file with the desired name\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- read.csv(\"~/folder/filename.csv\") \n\n\n\n\nUsing the same approach as above to first save the Excel file into .csv format, we can alternatively use the read_csv() function from the {readr} package to read in the data, instead of read.csv().\nFirst, install the {readr} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readr\") # Already installed on Posit Workbench\nlibrary(readr)\n\nThen read in the data using the read_csv() function with the appropriate filepath and create an object called “mycsv2”\n\nmycsv2 &lt;- read_csv(\"~/folder/filename.csv\") \n\n\n\n\n\n\n\nTip\n\n\n\nThe read.csv() function reads a file into a data.frame object whereas the read_csv() function reads a file into a tibble object.\nThe tibble objects have some advantages over data.frame objects such as faster loading and ability to handle non-standard column names.\n\n\nNote that the third approach is the one I use, and will form the basis of my examples in the rest of this course.\n\n\n\n\nMany other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places\n\n\n\n\n\n\n\n\n\n\nRecall: R is case sensitive\n\n\n\n\ni.e. age is not the same as Age.\n\n\n\n\nVariable names with spaces and special characters can be problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in all code using backticks: `Patient Age`\nOne alternative is to use the clean_names() function from the {janitor} package to convert all variable names to a standard format, such as snake case\n\n\nFirst, install the {janitor} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"janitor\") # Already installed on Posit Workbench\nlibrary(janitor)\n\nThen use the clean_names() function to convert all variable names to snake case (default):\n\nmycsv2 &lt;- clean_names(mycsv2)\n\nSnake case is all lowercase letters, with underscores separating any individual words.\n\n\n\n\n\n\nSession 1, Exercise 3\n\n\n\n\n\n\nSave the “breastcancer.xlsx” file to .csv format\nUse the third method presented in this section to load the breastcancer data using the read_csv() function from the {readr} package, to an object called “df”\nRun names(df) to see the original variable names\nUse the clean_names() function from the janitor package to convert the column names to snake case\nAgain run names(df) to see the original variable names\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 3 Solution\n\n\n\n\n\nGo to File &gt; Save as. Navigate to the “mmedr” folder on your home directory. Select “CSV” from the drop down. Save as “breastcancer.csv”\n\n\n\nThen read the data into R:\n\nlibrary(readr)\ndf &lt;- read_csv(\"~/mmedr/breastcancer.csv\")\n\n\n\nRows: 3000 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Grade\ndbl (12): Time, Event, RT, Age dx (yrs), Tumor size (cm), N LN pos 3 vs 1or2...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou will see that you get a message printed out with some details about the file you read in.\nLet’s look at the names when we first read it in the data, using the names() function:\n\nnames(df)\n\n [1] \"Time\"                     \"Event\"                   \n [3] \"RT\"                       \"Age dx (yrs)\"            \n [5] \"Tumor size (cm)\"          \"Grade\"                   \n [7] \"N LN pos 3 vs 1or2\"       \"Nodal ratio\"             \n [9] \"LVI\"                      \"ER or PR pos\"            \n[11] \"HER2 pos\"                 \"Quadrant: inner vs upper\"\n[13] \"Optimal systemic therapy\"\n\n\nWe see these names contain a mix of uppercase and lowercase, spaces, and special characters. They would be hard to work with in R code.\nNow standardize the names:\n\nlibrary(janitor)\ndf &lt;- clean_names(df)\n\nAnd look again at the variable names:\n\nnames(df)\n\n [1] \"time\"                     \"event\"                   \n [3] \"rt\"                       \"age_dx_yrs\"              \n [5] \"tumor_size_cm\"            \"grade\"                   \n [7] \"n_ln_pos_3_vs_1or2\"       \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_upper\" \n[13] \"optimal_systemic_therapy\"\n\n\nNow we see that the variable names are all lowercase, with “_” (underscore) in place of any spaces and special characters have been removed."
  },
  {
    "objectID": "tools-loading-data.html#dataset-for-use-in-this-class",
    "href": "tools-loading-data.html#dataset-for-use-in-this-class",
    "title": "Loading data",
    "section": "",
    "text": "The primary dataset used throughout this course is stored in this folder. We need to download it from GitHub onto our personal computers.\n\nNavigate to the above location and left click on breastcancer.xlsx.\nFor a .xlsx file like this, you won’t see a preview of the data. Now right click on “Raw” and then select “Save link as…”\n\n\n\n\n\nNavigate to the “mmedr” folder we created earlier on your home directory, and save the file there as “breastcancer.xlsx”."
  },
  {
    "objectID": "tools-loading-data.html#loading-excel-data",
    "href": "tools-loading-data.html#loading-excel-data",
    "title": "Loading data",
    "section": "",
    "text": "The most common data format we work with are data from Excel. We will learn three ways to load Excel datasets into R, and then will introduce some options for alternative file types.\nWe will look at options to:\n\nRead in Excel files with the {readxl} package\nRead in Excel files by converting to .csv first\nRead in Excel files by converting to .csv first and using the {readr} package\n\n\n\nFirst, install the {readxl} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readxl\") # Already installed on Posit Workbench\nlibrary(readxl)\n\nThen use the read_excel() function with the appropriate filepath to read in the data and create an object called “mydf”:\n\nmydf &lt;- read_excel(\"~/folder/filename.xlsx\")\n\n\n\n\n\n\n\nTip\n\n\n\nR treats the \\ as a special character so you either need to use / or \\(\\backslash \\backslash\\) in file paths.\n\n\n\n\n\n\n\n\nTip\n\n\n\nOn the Linux server (i.e. on Rstudio Pro via Posit Workbench), the path starts at /home/username, so filepaths relative to your directory can start “~/” followed by the folder where the file is located.\n\n\n\n\n\nAlternatively, we can convert the file from .xlsx format to .csv format first, and then read it in.\nAdvantages: removes some of the possible formatting pitfalls associated with Excel files, and you don’t need any special packages to read this format.\n\nOpen the Excel file.\nGo to File &gt; Save As and navigate to the folder where you want to save the data, if you are not already there\nSelect “CSV (Comma delimited)” from the “Save as type” drop down and save the file with the desired name\nUse the read.csv() function with the appropriate file path to read in the data and create an object called “mycsv”\n\n\nmycsv &lt;- read.csv(\"~/folder/filename.csv\") \n\n\n\n\nUsing the same approach as above to first save the Excel file into .csv format, we can alternatively use the read_csv() function from the {readr} package to read in the data, instead of read.csv().\nFirst, install the {readr} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"readr\") # Already installed on Posit Workbench\nlibrary(readr)\n\nThen read in the data using the read_csv() function with the appropriate filepath and create an object called “mycsv2”\n\nmycsv2 &lt;- read_csv(\"~/folder/filename.csv\") \n\n\n\n\n\n\n\nTip\n\n\n\nThe read.csv() function reads a file into a data.frame object whereas the read_csv() function reads a file into a tibble object.\nThe tibble objects have some advantages over data.frame objects such as faster loading and ability to handle non-standard column names.\n\n\nNote that the third approach is the one I use, and will form the basis of my examples in the rest of this course."
  },
  {
    "objectID": "tools-loading-data.html#loading-other-file-formats",
    "href": "tools-loading-data.html#loading-other-file-formats",
    "title": "Loading data",
    "section": "",
    "text": "Many other file formats exist, and here is a non-comprehensive list of functions for loading some of them:\n\nread.table() is the most generic function and can read many file types\nread.csv() is a special case with fixed defaults for comma-separated files\nread.csv2() is a special case with fixed defaults for comma-separated files that were created in a country where commas are used in place of decimal places\nread.delim() is a special case with fixed defaults for tab-delimited files\nread.delim2() is a special case with fixed defaults for tab-delimited files that were created in a country where commas are used in place of decimal places"
  },
  {
    "objectID": "tools-loading-data.html#variable-names-with-the-janitor-package",
    "href": "tools-loading-data.html#variable-names-with-the-janitor-package",
    "title": "Loading data",
    "section": "",
    "text": "Recall: R is case sensitive\n\n\n\n\ni.e. age is not the same as Age.\n\n\n\n\nVariable names with spaces and special characters can be problematic:\n\nDepending on how you read your data in, R may or may not automatically reformat variable names\nIf you end up with a variable called, e.g. “Patient Age” you would need to reference it in all code using backticks: `Patient Age`\nOne alternative is to use the clean_names() function from the {janitor} package to convert all variable names to a standard format, such as snake case\n\n\nFirst, install the {janitor} package from CRAN, then load the newly installed package. This should have been completed in Session 1, Exercise 2.\n\ninstall.packages(\"janitor\") # Already installed on Posit Workbench\nlibrary(janitor)\n\nThen use the clean_names() function to convert all variable names to snake case (default):\n\nmycsv2 &lt;- clean_names(mycsv2)\n\nSnake case is all lowercase letters, with underscores separating any individual words.\n\n\n\n\n\n\nSession 1, Exercise 3\n\n\n\n\n\n\nSave the “breastcancer.xlsx” file to .csv format\nUse the third method presented in this section to load the breastcancer data using the read_csv() function from the {readr} package, to an object called “df”\nRun names(df) to see the original variable names\nUse the clean_names() function from the janitor package to convert the column names to snake case\nAgain run names(df) to see the original variable names\n\n\n\n\n\n\n\n\n\n\nSession 1, Exercise 3 Solution\n\n\n\n\n\nGo to File &gt; Save as. Navigate to the “mmedr” folder on your home directory. Select “CSV” from the drop down. Save as “breastcancer.csv”\n\n\n\nThen read the data into R:\n\nlibrary(readr)\ndf &lt;- read_csv(\"~/mmedr/breastcancer.csv\")\n\n\n\nRows: 3000 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Grade\ndbl (12): Time, Event, RT, Age dx (yrs), Tumor size (cm), N LN pos 3 vs 1or2...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou will see that you get a message printed out with some details about the file you read in.\nLet’s look at the names when we first read it in the data, using the names() function:\n\nnames(df)\n\n [1] \"Time\"                     \"Event\"                   \n [3] \"RT\"                       \"Age dx (yrs)\"            \n [5] \"Tumor size (cm)\"          \"Grade\"                   \n [7] \"N LN pos 3 vs 1or2\"       \"Nodal ratio\"             \n [9] \"LVI\"                      \"ER or PR pos\"            \n[11] \"HER2 pos\"                 \"Quadrant: inner vs upper\"\n[13] \"Optimal systemic therapy\"\n\n\nWe see these names contain a mix of uppercase and lowercase, spaces, and special characters. They would be hard to work with in R code.\nNow standardize the names:\n\nlibrary(janitor)\ndf &lt;- clean_names(df)\n\nAnd look again at the variable names:\n\nnames(df)\n\n [1] \"time\"                     \"event\"                   \n [3] \"rt\"                       \"age_dx_yrs\"              \n [5] \"tumor_size_cm\"            \"grade\"                   \n [7] \"n_ln_pos_3_vs_1or2\"       \"nodal_ratio\"             \n [9] \"lvi\"                      \"er_or_pr_pos\"            \n[11] \"her2_pos\"                 \"quadrant_inner_vs_upper\" \n[13] \"optimal_systemic_therapy\"\n\n\nNow we see that the variable names are all lowercase, with “_” (underscore) in place of any spaces and special characters have been removed."
  },
  {
    "objectID": "tools-reproducibility.html",
    "href": "tools-reproducibility.html",
    "title": "Reproducility",
    "section": "",
    "text": "In this part of Session 1, we will discuss the importance of reproducibility in statistical programming, and tools available in R to promote reproducible research.\nWe can make the statistical analysis components of our scientific research more reproducible using a variety of tools in R.\n\n\nOne challenge in scientific research is organization. Keeping track of data, code, sources of information, connections between data sets and images, connections between lab equipment and the data they produce, and even basic file organization. We can’t tackle all of these issues in R, but we can address some of them.\nThe first area we can focus on is starting with a project oriented workflow.\nFirst, create a folder where everything related to one project will be stored. In this case, let’s consider a “project” to be a single scientific question of interest. Every document related to this question of interest, from lab notes to plots to code for statistical analyses, manuscript drafts, and references will be stored in this one folder. The folder should be created in a backed-up location on your computer.\nNext, give the folder a meaningful name. This will be unique to everone’s line of work, but you should consider devising a system that you will use for all of your projects. For example, in my collaborative work I always name my project folders with PILastName-FellowLastName-TwoToThreeWordDescription. In this way I always know what pattern to look for when I’m trying to locate a specific project folder in the future.\nLet’s say I’m doing a project for this class with an investigator named Jane Doe with a fellow named Bob Clark about breast cancer outcomes, I may create a project folder named “Doe-Clark-breast-cancer-outcomes” under my “mmedr” folder on my home network drive.\n\n\n\nThen, create an RStudio project in this location. An RStudio project is an easy way to divide your work into multiple contexts, each with their own working directory and source documents.\nTo create an RStudio project in an existing directory, in RStudio go to File &gt; New Project.\n\n\n\nSelect “Existing directory” from the pop-up box.\n\n\n\nThen use “Browse” to navigate to the desired folder, and select “Create Project”.\n\n\n\nYour RStudio session will then automatically switch to your new R project.\nYou will notice two things.\n\nThere is a new .Rproj file in your project folder with the same name as the folder.\n\n\n\n\n\nNow you have a fresh RStudio session, with the name of the project indicated in the top right corner.\n\n\n\n\n\n\n\nNow every time you want to work on an analysis for this project, you will first open the RStudio project.\nYou can do this in one of several ways.\n\nOn Posit Workbench or your personal computer, in RStudio go to File &gt; Open Project\n\n\n\n\n\nOn Posit Workbench or your personal computer, in RStudio click on the arrow next to the project name in the top right corner and either select “Open Project” or choose from the list of recently opened project names.\n\n\n\n\n\nOn your personal computer, double click on the R project file in your project folder, which will open a new RStudio session.\n\n\n\n\nBenefits of working inside an RStudio project include:\n\nStarting a fresh R session every time the project is opened\nThe current working directory is set to the project directory\nPreviously open R scripts are restored at project startup\nOther RStudio settings are restored\nMultiple RStudio sessions can be open at one time, running independently in different RStudio projects\n\nIt is beneficial to create a standard set of sub-folders using standard naming conventions across projects. This will depend on the type of materials you typically have, but here is an example of my personal structure:\n\n\n\n\ncode: contains all of my R code files\ndata: contains all of my datasets\nmanuscript: contains all manuscript drafts\nmeeting-notes: contains any notes from meetings\nreferences: contains PDFs of references as well as any reference manager files\n\nThen I will name documents in standard ways and manage versions over time by appending the date in yyyy-mm-dd format so that they sort appropriately. I use caution to name files in standard ways using all lowercase letters, dashes between words, and letters or numbers to keep files in order if they need to be used in a certain order. File and folder names with spaces are not readable by all computers, and should be avoided.\n\n\n\nWhile use of an RStudio project does automatically set the working directory to the project directory, the relative file paths will still not be completely portable. For example, if I were to move the entire project folder “Doe-Clark-breast-cancer-outcomes” to a different location on my computer, any file paths that were relative to the previous location would be broken.\nFor example, the location of my project folder is: /home/zabore2/mmedr/Doe-Clark-breast-Cancer-Outcomes\nUnder that project folder, I have a folder called “data”. I have copied “breastcancer.csv” into this sub-folder.\nTo read in the data in the RStudio project, use:\n\nlibrary(readr)\ndf &lt;- read_csv(\"./data/breastcancer.csv\")\n\nThis is a relative filepath to the full filepath “/home/zabore2/mmedr/Doe-Clark-breast-cancer-outcomes/data/breastcancer.csv”. The code file I’m working from is in a parallel sub-folder named “code”, so I have to go up one level to the main project folder (“.”) then back down into the data folder (“/data”) and then reference the file name (“/breastcancer.csv”). This is a nice short relative file path, but if I were to move this project off my home directory and onto a shared network drive, for example, any such relative filepaths would then be broken. Also, coding conventions are not the same across different operating systems, so these relative paths used in Linux will not work on Windows, for example.\nTo avoid this, we can take advantage of the {here} package.\nFirst, install and load the {here} package.\n\ninstall.packages(\"here\") # Already installed on Posit Workbench\nlibrary(here)\n\nWhen you run library(here) in your RStudio project, you will automatically see the location where “here” starts in the console:\n\n\n\nAnd you can now refer to the same filepath relative to the main project folder, separating as many levels of sub-folder names as needed by commas, as follows:\n\ndf &lt;- read_csv(here(\"data\", \"breastcancer.csv\"))\n\nNow this code would work both across computers with different operating systems, and also if the project folder is moved to any other location.\nThis avoids issues of reproducibility related to file paths.\n\n\n\n\n\n\nSession 1, Exercise 4\n\n\n\n\n\n\nCreate a project folder for our fake project under your “mmedr” folder.\nCreate an RStudio project in this folder location\nCreate sub-folders named “code” and “data”\nCopy the breastcancer.csv file into the “code” folder\nCreate a new R script called “session1-exercise4.R” saved to the code folder\nIn the R script, load the {here} package and use it to read in the breastcancer.csv data"
  },
  {
    "objectID": "tools-reproducibility.html#r-projects",
    "href": "tools-reproducibility.html#r-projects",
    "title": "Reproducility",
    "section": "",
    "text": "One challenge in scientific research is organization. Keeping track of data, code, sources of information, connections between data sets and images, connections between lab equipment and the data they produce, and even basic file organization. We can’t tackle all of these issues in R, but we can address some of them.\nThe first area we can focus on is starting with a project oriented workflow.\nFirst, create a folder where everything related to one project will be stored. In this case, let’s consider a “project” to be a single scientific question of interest. Every document related to this question of interest, from lab notes to plots to code for statistical analyses, manuscript drafts, and references will be stored in this one folder. The folder should be created in a backed-up location on your computer.\nNext, give the folder a meaningful name. This will be unique to everone’s line of work, but you should consider devising a system that you will use for all of your projects. For example, in my collaborative work I always name my project folders with PILastName-FellowLastName-TwoToThreeWordDescription. In this way I always know what pattern to look for when I’m trying to locate a specific project folder in the future.\nLet’s say I’m doing a project for this class with an investigator named Jane Doe with a fellow named Bob Clark about breast cancer outcomes, I may create a project folder named “Doe-Clark-breast-cancer-outcomes” under my “mmedr” folder on my home network drive.\n\n\n\nThen, create an RStudio project in this location. An RStudio project is an easy way to divide your work into multiple contexts, each with their own working directory and source documents.\nTo create an RStudio project in an existing directory, in RStudio go to File &gt; New Project.\n\n\n\nSelect “Existing directory” from the pop-up box.\n\n\n\nThen use “Browse” to navigate to the desired folder, and select “Create Project”.\n\n\n\nYour RStudio session will then automatically switch to your new R project.\nYou will notice two things.\n\nThere is a new .Rproj file in your project folder with the same name as the folder.\n\n\n\n\n\nNow you have a fresh RStudio session, with the name of the project indicated in the top right corner."
  },
  {
    "objectID": "tools-reproducibility.html#project-workflow-and-organization",
    "href": "tools-reproducibility.html#project-workflow-and-organization",
    "title": "Reproducility",
    "section": "",
    "text": "Now every time you want to work on an analysis for this project, you will first open the RStudio project.\nYou can do this in one of several ways.\n\nOn Posit Workbench or your personal computer, in RStudio go to File &gt; Open Project\n\n\n\n\n\nOn Posit Workbench or your personal computer, in RStudio click on the arrow next to the project name in the top right corner and either select “Open Project” or choose from the list of recently opened project names.\n\n\n\n\n\nOn your personal computer, double click on the R project file in your project folder, which will open a new RStudio session.\n\n\n\n\nBenefits of working inside an RStudio project include:\n\nStarting a fresh R session every time the project is opened\nThe current working directory is set to the project directory\nPreviously open R scripts are restored at project startup\nOther RStudio settings are restored\nMultiple RStudio sessions can be open at one time, running independently in different RStudio projects\n\nIt is beneficial to create a standard set of sub-folders using standard naming conventions across projects. This will depend on the type of materials you typically have, but here is an example of my personal structure:\n\n\n\n\ncode: contains all of my R code files\ndata: contains all of my datasets\nmanuscript: contains all manuscript drafts\nmeeting-notes: contains any notes from meetings\nreferences: contains PDFs of references as well as any reference manager files\n\nThen I will name documents in standard ways and manage versions over time by appending the date in yyyy-mm-dd format so that they sort appropriately. I use caution to name files in standard ways using all lowercase letters, dashes between words, and letters or numbers to keep files in order if they need to be used in a certain order. File and folder names with spaces are not readable by all computers, and should be avoided."
  },
  {
    "objectID": "tools-reproducibility.html#here-package",
    "href": "tools-reproducibility.html#here-package",
    "title": "Reproducility",
    "section": "",
    "text": "While use of an RStudio project does automatically set the working directory to the project directory, the relative file paths will still not be completely portable. For example, if I were to move the entire project folder “Doe-Clark-breast-cancer-outcomes” to a different location on my computer, any file paths that were relative to the previous location would be broken.\nFor example, the location of my project folder is: /home/zabore2/mmedr/Doe-Clark-breast-Cancer-Outcomes\nUnder that project folder, I have a folder called “data”. I have copied “breastcancer.csv” into this sub-folder.\nTo read in the data in the RStudio project, use:\n\nlibrary(readr)\ndf &lt;- read_csv(\"./data/breastcancer.csv\")\n\nThis is a relative filepath to the full filepath “/home/zabore2/mmedr/Doe-Clark-breast-cancer-outcomes/data/breastcancer.csv”. The code file I’m working from is in a parallel sub-folder named “code”, so I have to go up one level to the main project folder (“.”) then back down into the data folder (“/data”) and then reference the file name (“/breastcancer.csv”). This is a nice short relative file path, but if I were to move this project off my home directory and onto a shared network drive, for example, any such relative filepaths would then be broken. Also, coding conventions are not the same across different operating systems, so these relative paths used in Linux will not work on Windows, for example.\nTo avoid this, we can take advantage of the {here} package.\nFirst, install and load the {here} package.\n\ninstall.packages(\"here\") # Already installed on Posit Workbench\nlibrary(here)\n\nWhen you run library(here) in your RStudio project, you will automatically see the location where “here” starts in the console:\n\n\n\nAnd you can now refer to the same filepath relative to the main project folder, separating as many levels of sub-folder names as needed by commas, as follows:\n\ndf &lt;- read_csv(here(\"data\", \"breastcancer.csv\"))\n\nNow this code would work both across computers with different operating systems, and also if the project folder is moved to any other location.\nThis avoids issues of reproducibility related to file paths.\n\n\n\n\n\n\nSession 1, Exercise 4\n\n\n\n\n\n\nCreate a project folder for our fake project under your “mmedr” folder.\nCreate an RStudio project in this folder location\nCreate sub-folders named “code” and “data”\nCopy the breastcancer.csv file into the “code” folder\nCreate a new R script called “session1-exercise4.R” saved to the code folder\nIn the R script, load the {here} package and use it to read in the breastcancer.csv data"
  }
]